//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-30300941
// Cuda compilation tools, release 11.4, V11.4.120
// Based on NVVM 7.0.1
//

.version 7.4
.target sm_52
.address_size 64

.const .align 4 .b8 matYuv2Rgb[36];
.const .align 4 .b8 matRgb2Yuv[36];

.entry _Z14RgbToYuvKernelI7ushort26BGRA6410ulonglong2EvPhiS3_iii(
	.param .u64 _Z14RgbToYuvKernelI7ushort26BGRA6410ulonglong2EvPhiS3_iii_param_0,
	.param .u32 _Z14RgbToYuvKernelI7ushort26BGRA6410ulonglong2EvPhiS3_iii_param_1,
	.param .u64 _Z14RgbToYuvKernelI7ushort26BGRA6410ulonglong2EvPhiS3_iii_param_2,
	.param .u32 _Z14RgbToYuvKernelI7ushort26BGRA6410ulonglong2EvPhiS3_iii_param_3,
	.param .u32 _Z14RgbToYuvKernelI7ushort26BGRA6410ulonglong2EvPhiS3_iii_param_4,
	.param .u32 _Z14RgbToYuvKernelI7ushort26BGRA6410ulonglong2EvPhiS3_iii_param_5
)
{
	.reg .pred 	%p<4>;
	.reg .b16 	%rs<22>;
	.reg .f32 	%f<49>;
	.reg .b32 	%r<66>;
	.reg .b64 	%rd<36>;


	ld.param.u64 	%rd1, [_Z14RgbToYuvKernelI7ushort26BGRA6410ulonglong2EvPhiS3_iii_param_0];
	ld.param.u32 	%r3, [_Z14RgbToYuvKernelI7ushort26BGRA6410ulonglong2EvPhiS3_iii_param_1];
	ld.param.u64 	%rd2, [_Z14RgbToYuvKernelI7ushort26BGRA6410ulonglong2EvPhiS3_iii_param_2];
	ld.param.u32 	%r4, [_Z14RgbToYuvKernelI7ushort26BGRA6410ulonglong2EvPhiS3_iii_param_3];
	ld.param.u32 	%r6, [_Z14RgbToYuvKernelI7ushort26BGRA6410ulonglong2EvPhiS3_iii_param_4];
	ld.param.u32 	%r5, [_Z14RgbToYuvKernelI7ushort26BGRA6410ulonglong2EvPhiS3_iii_param_5];
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r8, %ctaid.x;
	mov.u32 	%r9, %tid.x;
	mad.lo.s32 	%r10, %r8, %r7, %r9;
	shl.b32 	%r1, %r10, 1;
	mov.u32 	%r11, %ntid.y;
	mov.u32 	%r12, %ctaid.y;
	mov.u32 	%r13, %tid.y;
	mad.lo.s32 	%r14, %r12, %r11, %r13;
	shl.b32 	%r2, %r14, 1;
	or.b32  	%r15, %r1, 1;
	setp.ge.s32 	%p1, %r15, %r6;
	or.b32  	%r16, %r2, 1;
	setp.ge.s32 	%p2, %r16, %r5;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	$L__BB0_2;

	mul.wide.s32 	%rd3, %r1, 8;
	mul.lo.s32 	%r17, %r2, %r3;
	cvt.s64.s32 	%rd4, %r17;
	add.s64 	%rd5, %rd3, %rd4;
	cvta.to.global.u64 	%rd6, %rd1;
	add.s64 	%rd7, %rd6, %rd5;
	ld.global.v2.u64 	{%rd8, %rd9}, [%rd7];
	cvt.s64.s32 	%rd12, %r3;
	add.s64 	%rd13, %rd7, %rd12;
	ld.global.v2.u64 	{%rd14, %rd15}, [%rd13];
	shr.u64 	%rd18, %rd8, 32;
	cvt.u32.u64 	%r18, %rd18;
	and.b32  	%r19, %r18, 65535;
	shr.u64 	%rd19, %rd9, 32;
	cvt.u32.u64 	%r20, %rd19;
	and.b32  	%r21, %r20, 65535;
	add.s32 	%r22, %r19, %r21;
	shr.u64 	%rd20, %rd14, 32;
	cvt.u32.u64 	%r23, %rd20;
	and.b32  	%r24, %r23, 65535;
	add.s32 	%r25, %r22, %r24;
	shr.u64 	%rd21, %rd15, 32;
	cvt.u32.u64 	%r26, %rd21;
	and.b32  	%r27, %r26, 65535;
	add.s32 	%r28, %r25, %r27;
	shr.u32 	%r29, %r28, 2;
	cvt.u16.u32 	%rs1, %r29;
	shr.u64 	%rd22, %rd8, 16;
	cvt.u32.u64 	%r30, %rd22;
	and.b32  	%r31, %r30, 65535;
	shr.u64 	%rd23, %rd9, 16;
	cvt.u32.u64 	%r32, %rd23;
	and.b32  	%r33, %r32, 65535;
	add.s32 	%r34, %r31, %r33;
	shr.u64 	%rd24, %rd14, 16;
	cvt.u32.u64 	%r35, %rd24;
	and.b32  	%r36, %r35, 65535;
	add.s32 	%r37, %r34, %r36;
	shr.u64 	%rd25, %rd15, 16;
	cvt.u32.u64 	%r38, %rd25;
	and.b32  	%r39, %r38, 65535;
	add.s32 	%r40, %r37, %r39;
	shr.u32 	%r41, %r40, 2;
	cvt.u16.u32 	%rs2, %r41;
	cvt.u32.u64 	%r42, %rd8;
	and.b32  	%r43, %r42, 65535;
	cvt.u32.u64 	%r44, %rd9;
	and.b32  	%r45, %r44, 65535;
	add.s32 	%r46, %r43, %r45;
	cvt.u32.u64 	%r47, %rd14;
	and.b32  	%r48, %r47, 65535;
	add.s32 	%r49, %r46, %r48;
	cvt.u32.u64 	%r50, %rd15;
	and.b32  	%r51, %r50, 65535;
	add.s32 	%r52, %r49, %r51;
	shr.u32 	%r53, %r52, 2;
	cvt.u16.u32 	%rs3, %r53;
	mul.wide.s32 	%rd26, %r1, 2;
	and.b64  	%rd27, %rd26, 9223372036854775804;
	mul.lo.s32 	%r54, %r2, %r4;
	cvt.s64.s32 	%rd28, %r54;
	add.s64 	%rd29, %rd27, %rd28;
	cvta.to.global.u64 	%rd30, %rd2;
	add.s64 	%rd31, %rd30, %rd29;
	cvt.u16.u64 	%rs4, %rd18;
	cvt.u16.u64 	%rs5, %rd22;
	cvt.u16.u64 	%rs6, %rd8;
	cvt.rn.f32.u16 	%f1, %rs4;
	ld.const.f32 	%f2, [matRgb2Yuv];
	cvt.rn.f32.u16 	%f3, %rs5;
	ld.const.f32 	%f4, [matRgb2Yuv+4];
	mul.f32 	%f5, %f4, %f3;
	fma.rn.f32 	%f6, %f2, %f1, %f5;
	cvt.rn.f32.u16 	%f7, %rs6;
	ld.const.f32 	%f8, [matRgb2Yuv+8];
	fma.rn.f32 	%f9, %f8, %f7, %f6;
	add.f32 	%f10, %f9, 0f45800000;
	cvt.rzi.u32.f32 	%r55, %f10;
	cvt.u16.u64 	%rs7, %rd19;
	cvt.u16.u64 	%rs8, %rd23;
	cvt.u16.u64 	%rs9, %rd9;
	cvt.rn.f32.u16 	%f11, %rs7;
	cvt.rn.f32.u16 	%f12, %rs8;
	mul.f32 	%f13, %f4, %f12;
	fma.rn.f32 	%f14, %f2, %f11, %f13;
	cvt.rn.f32.u16 	%f15, %rs9;
	fma.rn.f32 	%f16, %f8, %f15, %f14;
	add.f32 	%f17, %f16, 0f45800000;
	cvt.rzi.u32.f32 	%r56, %f17;
	cvt.u16.u32 	%rs10, %r56;
	cvt.u16.u32 	%rs11, %r55;
	st.global.v2.u16 	[%rd31], {%rs11, %rs10};
	cvt.s64.s32 	%rd32, %r4;
	add.s64 	%rd33, %rd31, %rd32;
	cvt.u16.u64 	%rs12, %rd20;
	cvt.u16.u64 	%rs13, %rd24;
	cvt.u16.u64 	%rs14, %rd14;
	cvt.rn.f32.u16 	%f18, %rs12;
	cvt.rn.f32.u16 	%f19, %rs13;
	mul.f32 	%f20, %f4, %f19;
	fma.rn.f32 	%f21, %f2, %f18, %f20;
	cvt.rn.f32.u16 	%f22, %rs14;
	fma.rn.f32 	%f23, %f8, %f22, %f21;
	add.f32 	%f24, %f23, 0f45800000;
	cvt.rzi.u32.f32 	%r57, %f24;
	cvt.u16.u64 	%rs15, %rd21;
	cvt.u16.u64 	%rs16, %rd25;
	cvt.u16.u64 	%rs17, %rd15;
	cvt.rn.f32.u16 	%f25, %rs15;
	cvt.rn.f32.u16 	%f26, %rs16;
	mul.f32 	%f27, %f4, %f26;
	fma.rn.f32 	%f28, %f2, %f25, %f27;
	cvt.rn.f32.u16 	%f29, %rs17;
	fma.rn.f32 	%f30, %f8, %f29, %f28;
	add.f32 	%f31, %f30, 0f45800000;
	cvt.rzi.u32.f32 	%r58, %f31;
	cvt.u16.u32 	%rs18, %r58;
	cvt.u16.u32 	%rs19, %r57;
	st.global.v2.u16 	[%rd33], {%rs19, %rs18};
	shr.u32 	%r59, %r2, 31;
	add.s32 	%r60, %r2, %r59;
	shr.s32 	%r61, %r60, 1;
	sub.s32 	%r62, %r5, %r61;
	mul.lo.s32 	%r63, %r62, %r4;
	cvt.s64.s32 	%rd34, %r63;
	add.s64 	%rd35, %rd31, %rd34;
	cvt.rn.f32.u16 	%f32, %rs1;
	ld.const.f32 	%f33, [matRgb2Yuv+12];
	cvt.rn.f32.u16 	%f34, %rs2;
	ld.const.f32 	%f35, [matRgb2Yuv+16];
	mul.f32 	%f36, %f35, %f34;
	fma.rn.f32 	%f37, %f33, %f32, %f36;
	cvt.rn.f32.u16 	%f38, %rs3;
	ld.const.f32 	%f39, [matRgb2Yuv+20];
	fma.rn.f32 	%f40, %f39, %f38, %f37;
	add.f32 	%f41, %f40, 0f47000000;
	cvt.rzi.u32.f32 	%r64, %f41;
	ld.const.f32 	%f42, [matRgb2Yuv+24];
	ld.const.f32 	%f43, [matRgb2Yuv+28];
	mul.f32 	%f44, %f43, %f34;
	fma.rn.f32 	%f45, %f42, %f32, %f44;
	ld.const.f32 	%f46, [matRgb2Yuv+32];
	fma.rn.f32 	%f47, %f46, %f38, %f45;
	add.f32 	%f48, %f47, 0f47000000;
	cvt.rzi.u32.f32 	%r65, %f48;
	cvt.u16.u32 	%rs20, %r65;
	cvt.u16.u32 	%rs21, %r64;
	st.global.v2.u16 	[%rd35], {%rs21, %rs20};

$L__BB0_2:
	ret;

}
.entry _Z14YuvToRgbKernelI6uchar26BGRA325uint2EvPhiS3_iii(
	.param .u64 _Z14YuvToRgbKernelI6uchar26BGRA325uint2EvPhiS3_iii_param_0,
	.param .u32 _Z14YuvToRgbKernelI6uchar26BGRA325uint2EvPhiS3_iii_param_1,
	.param .u64 _Z14YuvToRgbKernelI6uchar26BGRA325uint2EvPhiS3_iii_param_2,
	.param .u32 _Z14YuvToRgbKernelI6uchar26BGRA325uint2EvPhiS3_iii_param_3,
	.param .u32 _Z14YuvToRgbKernelI6uchar26BGRA325uint2EvPhiS3_iii_param_4,
	.param .u32 _Z14YuvToRgbKernelI6uchar26BGRA325uint2EvPhiS3_iii_param_5
)
{
	.reg .pred 	%p<28>;
	.reg .b16 	%rs<7>;
	.reg .f32 	%f<67>;
	.reg .b32 	%r<76>;
	.reg .b64 	%rd<20>;


	ld.param.u64 	%rd1, [_Z14YuvToRgbKernelI6uchar26BGRA325uint2EvPhiS3_iii_param_0];
	ld.param.u32 	%r3, [_Z14YuvToRgbKernelI6uchar26BGRA325uint2EvPhiS3_iii_param_1];
	ld.param.u64 	%rd2, [_Z14YuvToRgbKernelI6uchar26BGRA325uint2EvPhiS3_iii_param_2];
	ld.param.u32 	%r4, [_Z14YuvToRgbKernelI6uchar26BGRA325uint2EvPhiS3_iii_param_3];
	ld.param.u32 	%r6, [_Z14YuvToRgbKernelI6uchar26BGRA325uint2EvPhiS3_iii_param_4];
	ld.param.u32 	%r5, [_Z14YuvToRgbKernelI6uchar26BGRA325uint2EvPhiS3_iii_param_5];
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r8, %ctaid.x;
	mov.u32 	%r9, %tid.x;
	mad.lo.s32 	%r10, %r8, %r7, %r9;
	shl.b32 	%r1, %r10, 1;
	mov.u32 	%r11, %ntid.y;
	mov.u32 	%r12, %ctaid.y;
	mov.u32 	%r13, %tid.y;
	mad.lo.s32 	%r14, %r12, %r11, %r13;
	shl.b32 	%r2, %r14, 1;
	or.b32  	%r15, %r1, 1;
	setp.ge.s32 	%p1, %r15, %r6;
	or.b32  	%r16, %r2, 1;
	setp.ge.s32 	%p2, %r16, %r5;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	$L__BB1_2;

	cvt.s64.s32 	%rd3, %r1;
	and.b64  	%rd4, %rd3, 9223372036854775806;
	mul.lo.s32 	%r17, %r2, %r3;
	cvt.s64.s32 	%rd5, %r17;
	add.s64 	%rd6, %rd4, %rd5;
	cvta.to.global.u64 	%rd7, %rd1;
	add.s64 	%rd8, %rd7, %rd6;
	mul.wide.s32 	%rd9, %r1, 4;
	mul.lo.s32 	%r18, %r2, %r4;
	cvt.s64.s32 	%rd10, %r18;
	add.s64 	%rd11, %rd9, %rd10;
	cvta.to.global.u64 	%rd12, %rd2;
	add.s64 	%rd13, %rd12, %rd11;
	ld.global.v2.u8 	{%rs1, %rs2}, [%rd8];
	cvt.s64.s32 	%rd14, %r3;
	add.s64 	%rd15, %rd8, %rd14;
	ld.global.v2.u8 	{%rs3, %rs4}, [%rd15];
	shr.u32 	%r19, %r2, 31;
	add.s32 	%r20, %r2, %r19;
	shr.s32 	%r21, %r20, 1;
	sub.s32 	%r22, %r5, %r21;
	mul.lo.s32 	%r23, %r22, %r3;
	cvt.s64.s32 	%rd16, %r23;
	add.s64 	%rd17, %rd8, %rd16;
	ld.global.v2.u8 	{%rs5, %rs6}, [%rd17];
	cvt.u32.u16 	%r24, %rs1;
	add.s32 	%r25, %r24, -16;
	cvt.rn.f32.s32 	%f1, %r25;
	cvt.u32.u16 	%r26, %rs5;
	add.s32 	%r27, %r26, -128;
	cvt.rn.f32.s32 	%f2, %r27;
	cvt.u32.u16 	%r28, %rs6;
	add.s32 	%r29, %r28, -128;
	cvt.rn.f32.s32 	%f3, %r29;
	ld.const.f32 	%f4, [matYuv2Rgb];
	ld.const.f32 	%f5, [matYuv2Rgb+4];
	mul.f32 	%f6, %f5, %f2;
	fma.rn.f32 	%f7, %f4, %f1, %f6;
	ld.const.f32 	%f8, [matYuv2Rgb+8];
	fma.rn.f32 	%f9, %f8, %f3, %f7;
	setp.lt.f32 	%p4, %f9, 0f00000000;
	setp.gt.f32 	%p5, %f9, 0f437F0000;
	selp.f32 	%f10, 0f437F0000, %f9, %p5;
	selp.f32 	%f11, 0f00000000, %f10, %p4;
	cvt.rzi.u32.f32 	%r30, %f11;
	ld.const.f32 	%f12, [matYuv2Rgb+12];
	ld.const.f32 	%f13, [matYuv2Rgb+16];
	mul.f32 	%f14, %f13, %f2;
	fma.rn.f32 	%f15, %f12, %f1, %f14;
	ld.const.f32 	%f16, [matYuv2Rgb+20];
	fma.rn.f32 	%f17, %f16, %f3, %f15;
	setp.lt.f32 	%p6, %f17, 0f00000000;
	setp.gt.f32 	%p7, %f17, 0f437F0000;
	selp.f32 	%f18, 0f437F0000, %f17, %p7;
	selp.f32 	%f19, 0f00000000, %f18, %p6;
	cvt.rzi.u32.f32 	%r31, %f19;
	ld.const.f32 	%f20, [matYuv2Rgb+24];
	ld.const.f32 	%f21, [matYuv2Rgb+28];
	mul.f32 	%f22, %f21, %f2;
	fma.rn.f32 	%f23, %f20, %f1, %f22;
	ld.const.f32 	%f24, [matYuv2Rgb+32];
	fma.rn.f32 	%f25, %f24, %f3, %f23;
	setp.lt.f32 	%p8, %f25, 0f00000000;
	setp.gt.f32 	%p9, %f25, 0f437F0000;
	selp.f32 	%f26, 0f437F0000, %f25, %p9;
	selp.f32 	%f27, 0f00000000, %f26, %p8;
	cvt.rzi.u32.f32 	%r32, %f27;
	and.b32  	%r33, %r32, 255;
	shl.b32 	%r34, %r30, 16;
	and.b32  	%r35, %r34, 16711680;
	shl.b32 	%r36, %r31, 8;
	and.b32  	%r37, %r36, 65280;
	or.b32  	%r38, %r37, %r35;
	cvt.u32.u16 	%r39, %rs2;
	add.s32 	%r40, %r39, -16;
	cvt.rn.f32.s32 	%f28, %r40;
	fma.rn.f32 	%f29, %f4, %f28, %f6;
	fma.rn.f32 	%f30, %f8, %f3, %f29;
	setp.lt.f32 	%p10, %f30, 0f00000000;
	setp.gt.f32 	%p11, %f30, 0f437F0000;
	selp.f32 	%f31, 0f437F0000, %f30, %p11;
	selp.f32 	%f32, 0f00000000, %f31, %p10;
	cvt.rzi.u32.f32 	%r41, %f32;
	fma.rn.f32 	%f33, %f12, %f28, %f14;
	fma.rn.f32 	%f34, %f16, %f3, %f33;
	setp.lt.f32 	%p12, %f34, 0f00000000;
	setp.gt.f32 	%p13, %f34, 0f437F0000;
	selp.f32 	%f35, 0f437F0000, %f34, %p13;
	selp.f32 	%f36, 0f00000000, %f35, %p12;
	cvt.rzi.u32.f32 	%r42, %f36;
	fma.rn.f32 	%f37, %f20, %f28, %f22;
	fma.rn.f32 	%f38, %f24, %f3, %f37;
	setp.lt.f32 	%p14, %f38, 0f00000000;
	setp.gt.f32 	%p15, %f38, 0f437F0000;
	selp.f32 	%f39, 0f437F0000, %f38, %p15;
	selp.f32 	%f40, 0f00000000, %f39, %p14;
	cvt.rzi.u32.f32 	%r43, %f40;
	and.b32  	%r44, %r43, 255;
	shl.b32 	%r45, %r41, 16;
	and.b32  	%r46, %r45, 16711680;
	shl.b32 	%r47, %r42, 8;
	and.b32  	%r48, %r47, 65280;
	or.b32  	%r49, %r48, %r46;
	or.b32  	%r50, %r49, %r44;
	or.b32  	%r51, %r38, %r33;
	st.global.v2.u32 	[%rd13], {%r51, %r50};
	cvt.s64.s32 	%rd18, %r4;
	add.s64 	%rd19, %rd13, %rd18;
	cvt.u32.u16 	%r52, %rs3;
	add.s32 	%r53, %r52, -16;
	cvt.rn.f32.s32 	%f41, %r53;
	fma.rn.f32 	%f42, %f4, %f41, %f6;
	fma.rn.f32 	%f43, %f8, %f3, %f42;
	setp.lt.f32 	%p16, %f43, 0f00000000;
	setp.gt.f32 	%p17, %f43, 0f437F0000;
	selp.f32 	%f44, 0f437F0000, %f43, %p17;
	selp.f32 	%f45, 0f00000000, %f44, %p16;
	cvt.rzi.u32.f32 	%r54, %f45;
	fma.rn.f32 	%f46, %f12, %f41, %f14;
	fma.rn.f32 	%f47, %f16, %f3, %f46;
	setp.lt.f32 	%p18, %f47, 0f00000000;
	setp.gt.f32 	%p19, %f47, 0f437F0000;
	selp.f32 	%f48, 0f437F0000, %f47, %p19;
	selp.f32 	%f49, 0f00000000, %f48, %p18;
	cvt.rzi.u32.f32 	%r55, %f49;
	fma.rn.f32 	%f50, %f20, %f41, %f22;
	fma.rn.f32 	%f51, %f24, %f3, %f50;
	setp.lt.f32 	%p20, %f51, 0f00000000;
	setp.gt.f32 	%p21, %f51, 0f437F0000;
	selp.f32 	%f52, 0f437F0000, %f51, %p21;
	selp.f32 	%f53, 0f00000000, %f52, %p20;
	cvt.rzi.u32.f32 	%r56, %f53;
	and.b32  	%r57, %r56, 255;
	shl.b32 	%r58, %r54, 16;
	and.b32  	%r59, %r58, 16711680;
	shl.b32 	%r60, %r55, 8;
	and.b32  	%r61, %r60, 65280;
	or.b32  	%r62, %r61, %r59;
	cvt.u32.u16 	%r63, %rs4;
	add.s32 	%r64, %r63, -16;
	cvt.rn.f32.s32 	%f54, %r64;
	fma.rn.f32 	%f55, %f4, %f54, %f6;
	fma.rn.f32 	%f56, %f8, %f3, %f55;
	setp.lt.f32 	%p22, %f56, 0f00000000;
	setp.gt.f32 	%p23, %f56, 0f437F0000;
	selp.f32 	%f57, 0f437F0000, %f56, %p23;
	selp.f32 	%f58, 0f00000000, %f57, %p22;
	cvt.rzi.u32.f32 	%r65, %f58;
	fma.rn.f32 	%f59, %f12, %f54, %f14;
	fma.rn.f32 	%f60, %f16, %f3, %f59;
	setp.lt.f32 	%p24, %f60, 0f00000000;
	setp.gt.f32 	%p25, %f60, 0f437F0000;
	selp.f32 	%f61, 0f437F0000, %f60, %p25;
	selp.f32 	%f62, 0f00000000, %f61, %p24;
	cvt.rzi.u32.f32 	%r66, %f62;
	fma.rn.f32 	%f63, %f20, %f54, %f22;
	fma.rn.f32 	%f64, %f24, %f3, %f63;
	setp.lt.f32 	%p26, %f64, 0f00000000;
	setp.gt.f32 	%p27, %f64, 0f437F0000;
	selp.f32 	%f65, 0f437F0000, %f64, %p27;
	selp.f32 	%f66, 0f00000000, %f65, %p26;
	cvt.rzi.u32.f32 	%r67, %f66;
	and.b32  	%r68, %r67, 255;
	shl.b32 	%r69, %r65, 16;
	and.b32  	%r70, %r69, 16711680;
	shl.b32 	%r71, %r66, 8;
	and.b32  	%r72, %r71, 65280;
	or.b32  	%r73, %r72, %r70;
	or.b32  	%r74, %r73, %r68;
	or.b32  	%r75, %r62, %r57;
	st.global.v2.u32 	[%rd19], {%r75, %r74};

$L__BB1_2:
	ret;

}
.entry _Z14YuvToRgbKernelI6uchar26RGBA325uint2EvPhiS3_iii(
	.param .u64 _Z14YuvToRgbKernelI6uchar26RGBA325uint2EvPhiS3_iii_param_0,
	.param .u32 _Z14YuvToRgbKernelI6uchar26RGBA325uint2EvPhiS3_iii_param_1,
	.param .u64 _Z14YuvToRgbKernelI6uchar26RGBA325uint2EvPhiS3_iii_param_2,
	.param .u32 _Z14YuvToRgbKernelI6uchar26RGBA325uint2EvPhiS3_iii_param_3,
	.param .u32 _Z14YuvToRgbKernelI6uchar26RGBA325uint2EvPhiS3_iii_param_4,
	.param .u32 _Z14YuvToRgbKernelI6uchar26RGBA325uint2EvPhiS3_iii_param_5
)
{
	.reg .pred 	%p<28>;
	.reg .b16 	%rs<7>;
	.reg .f32 	%f<67>;
	.reg .b32 	%r<68>;
	.reg .b64 	%rd<20>;


	ld.param.u64 	%rd1, [_Z14YuvToRgbKernelI6uchar26RGBA325uint2EvPhiS3_iii_param_0];
	ld.param.u32 	%r3, [_Z14YuvToRgbKernelI6uchar26RGBA325uint2EvPhiS3_iii_param_1];
	ld.param.u64 	%rd2, [_Z14YuvToRgbKernelI6uchar26RGBA325uint2EvPhiS3_iii_param_2];
	ld.param.u32 	%r4, [_Z14YuvToRgbKernelI6uchar26RGBA325uint2EvPhiS3_iii_param_3];
	ld.param.u32 	%r6, [_Z14YuvToRgbKernelI6uchar26RGBA325uint2EvPhiS3_iii_param_4];
	ld.param.u32 	%r5, [_Z14YuvToRgbKernelI6uchar26RGBA325uint2EvPhiS3_iii_param_5];
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r8, %ctaid.x;
	mov.u32 	%r9, %tid.x;
	mad.lo.s32 	%r10, %r8, %r7, %r9;
	shl.b32 	%r1, %r10, 1;
	mov.u32 	%r11, %ntid.y;
	mov.u32 	%r12, %ctaid.y;
	mov.u32 	%r13, %tid.y;
	mad.lo.s32 	%r14, %r12, %r11, %r13;
	shl.b32 	%r2, %r14, 1;
	or.b32  	%r15, %r1, 1;
	setp.ge.s32 	%p1, %r15, %r6;
	or.b32  	%r16, %r2, 1;
	setp.ge.s32 	%p2, %r16, %r5;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	$L__BB2_2;

	cvt.s64.s32 	%rd3, %r1;
	and.b64  	%rd4, %rd3, 9223372036854775806;
	mul.lo.s32 	%r17, %r2, %r3;
	cvt.s64.s32 	%rd5, %r17;
	add.s64 	%rd6, %rd4, %rd5;
	cvta.to.global.u64 	%rd7, %rd1;
	add.s64 	%rd8, %rd7, %rd6;
	mul.wide.s32 	%rd9, %r1, 4;
	mul.lo.s32 	%r18, %r2, %r4;
	cvt.s64.s32 	%rd10, %r18;
	add.s64 	%rd11, %rd9, %rd10;
	cvta.to.global.u64 	%rd12, %rd2;
	add.s64 	%rd13, %rd12, %rd11;
	ld.global.v2.u8 	{%rs1, %rs2}, [%rd8];
	cvt.s64.s32 	%rd14, %r3;
	add.s64 	%rd15, %rd8, %rd14;
	ld.global.v2.u8 	{%rs3, %rs4}, [%rd15];
	shr.u32 	%r19, %r2, 31;
	add.s32 	%r20, %r2, %r19;
	shr.s32 	%r21, %r20, 1;
	sub.s32 	%r22, %r5, %r21;
	mul.lo.s32 	%r23, %r22, %r3;
	cvt.s64.s32 	%rd16, %r23;
	add.s64 	%rd17, %rd8, %rd16;
	ld.global.v2.u8 	{%rs5, %rs6}, [%rd17];
	cvt.u32.u16 	%r24, %rs1;
	add.s32 	%r25, %r24, -16;
	cvt.rn.f32.s32 	%f1, %r25;
	cvt.u32.u16 	%r26, %rs5;
	add.s32 	%r27, %r26, -128;
	cvt.rn.f32.s32 	%f2, %r27;
	cvt.u32.u16 	%r28, %rs6;
	add.s32 	%r29, %r28, -128;
	cvt.rn.f32.s32 	%f3, %r29;
	ld.const.f32 	%f4, [matYuv2Rgb];
	ld.const.f32 	%f5, [matYuv2Rgb+4];
	mul.f32 	%f6, %f5, %f2;
	fma.rn.f32 	%f7, %f4, %f1, %f6;
	ld.const.f32 	%f8, [matYuv2Rgb+8];
	fma.rn.f32 	%f9, %f8, %f3, %f7;
	setp.lt.f32 	%p4, %f9, 0f00000000;
	setp.gt.f32 	%p5, %f9, 0f437F0000;
	selp.f32 	%f10, 0f437F0000, %f9, %p5;
	selp.f32 	%f11, 0f00000000, %f10, %p4;
	cvt.rzi.u32.f32 	%r30, %f11;
	ld.const.f32 	%f12, [matYuv2Rgb+12];
	ld.const.f32 	%f13, [matYuv2Rgb+16];
	mul.f32 	%f14, %f13, %f2;
	fma.rn.f32 	%f15, %f12, %f1, %f14;
	ld.const.f32 	%f16, [matYuv2Rgb+20];
	fma.rn.f32 	%f17, %f16, %f3, %f15;
	setp.lt.f32 	%p6, %f17, 0f00000000;
	setp.gt.f32 	%p7, %f17, 0f437F0000;
	selp.f32 	%f18, 0f437F0000, %f17, %p7;
	selp.f32 	%f19, 0f00000000, %f18, %p6;
	cvt.rzi.u32.f32 	%r31, %f19;
	ld.const.f32 	%f20, [matYuv2Rgb+24];
	ld.const.f32 	%f21, [matYuv2Rgb+28];
	mul.f32 	%f22, %f21, %f2;
	fma.rn.f32 	%f23, %f20, %f1, %f22;
	ld.const.f32 	%f24, [matYuv2Rgb+32];
	fma.rn.f32 	%f25, %f24, %f3, %f23;
	setp.lt.f32 	%p8, %f25, 0f00000000;
	setp.gt.f32 	%p9, %f25, 0f437F0000;
	selp.f32 	%f26, 0f437F0000, %f25, %p9;
	selp.f32 	%f27, 0f00000000, %f26, %p8;
	cvt.rzi.u32.f32 	%r32, %f27;
	and.b32  	%r33, %r30, 255;
	and.b32  	%r34, %r31, 255;
	and.b32  	%r35, %r32, 255;
	prmt.b32 	%r36, %r34, %r33, 30212;
	cvt.u32.u16 	%r37, %rs2;
	add.s32 	%r38, %r37, -16;
	cvt.rn.f32.s32 	%f28, %r38;
	fma.rn.f32 	%f29, %f4, %f28, %f6;
	fma.rn.f32 	%f30, %f8, %f3, %f29;
	setp.lt.f32 	%p10, %f30, 0f00000000;
	setp.gt.f32 	%p11, %f30, 0f437F0000;
	selp.f32 	%f31, 0f437F0000, %f30, %p11;
	selp.f32 	%f32, 0f00000000, %f31, %p10;
	cvt.rzi.u32.f32 	%r39, %f32;
	fma.rn.f32 	%f33, %f12, %f28, %f14;
	fma.rn.f32 	%f34, %f16, %f3, %f33;
	setp.lt.f32 	%p12, %f34, 0f00000000;
	setp.gt.f32 	%p13, %f34, 0f437F0000;
	selp.f32 	%f35, 0f437F0000, %f34, %p13;
	selp.f32 	%f36, 0f00000000, %f35, %p12;
	cvt.rzi.u32.f32 	%r40, %f36;
	fma.rn.f32 	%f37, %f20, %f28, %f22;
	fma.rn.f32 	%f38, %f24, %f3, %f37;
	setp.lt.f32 	%p14, %f38, 0f00000000;
	setp.gt.f32 	%p15, %f38, 0f437F0000;
	selp.f32 	%f39, 0f437F0000, %f38, %p15;
	selp.f32 	%f40, 0f00000000, %f39, %p14;
	cvt.rzi.u32.f32 	%r41, %f40;
	and.b32  	%r42, %r39, 255;
	and.b32  	%r43, %r40, 255;
	and.b32  	%r44, %r41, 255;
	prmt.b32 	%r45, %r43, %r42, 30212;
	prmt.b32 	%r46, %r44, %r45, 28756;
	prmt.b32 	%r47, %r35, %r36, 28756;
	st.global.v2.u32 	[%rd13], {%r47, %r46};
	cvt.s64.s32 	%rd18, %r4;
	add.s64 	%rd19, %rd13, %rd18;
	cvt.u32.u16 	%r48, %rs3;
	add.s32 	%r49, %r48, -16;
	cvt.rn.f32.s32 	%f41, %r49;
	fma.rn.f32 	%f42, %f4, %f41, %f6;
	fma.rn.f32 	%f43, %f8, %f3, %f42;
	setp.lt.f32 	%p16, %f43, 0f00000000;
	setp.gt.f32 	%p17, %f43, 0f437F0000;
	selp.f32 	%f44, 0f437F0000, %f43, %p17;
	selp.f32 	%f45, 0f00000000, %f44, %p16;
	cvt.rzi.u32.f32 	%r50, %f45;
	fma.rn.f32 	%f46, %f12, %f41, %f14;
	fma.rn.f32 	%f47, %f16, %f3, %f46;
	setp.lt.f32 	%p18, %f47, 0f00000000;
	setp.gt.f32 	%p19, %f47, 0f437F0000;
	selp.f32 	%f48, 0f437F0000, %f47, %p19;
	selp.f32 	%f49, 0f00000000, %f48, %p18;
	cvt.rzi.u32.f32 	%r51, %f49;
	fma.rn.f32 	%f50, %f20, %f41, %f22;
	fma.rn.f32 	%f51, %f24, %f3, %f50;
	setp.lt.f32 	%p20, %f51, 0f00000000;
	setp.gt.f32 	%p21, %f51, 0f437F0000;
	selp.f32 	%f52, 0f437F0000, %f51, %p21;
	selp.f32 	%f53, 0f00000000, %f52, %p20;
	cvt.rzi.u32.f32 	%r52, %f53;
	and.b32  	%r53, %r50, 255;
	and.b32  	%r54, %r51, 255;
	and.b32  	%r55, %r52, 255;
	prmt.b32 	%r56, %r54, %r53, 30212;
	cvt.u32.u16 	%r57, %rs4;
	add.s32 	%r58, %r57, -16;
	cvt.rn.f32.s32 	%f54, %r58;
	fma.rn.f32 	%f55, %f4, %f54, %f6;
	fma.rn.f32 	%f56, %f8, %f3, %f55;
	setp.lt.f32 	%p22, %f56, 0f00000000;
	setp.gt.f32 	%p23, %f56, 0f437F0000;
	selp.f32 	%f57, 0f437F0000, %f56, %p23;
	selp.f32 	%f58, 0f00000000, %f57, %p22;
	cvt.rzi.u32.f32 	%r59, %f58;
	fma.rn.f32 	%f59, %f12, %f54, %f14;
	fma.rn.f32 	%f60, %f16, %f3, %f59;
	setp.lt.f32 	%p24, %f60, 0f00000000;
	setp.gt.f32 	%p25, %f60, 0f437F0000;
	selp.f32 	%f61, 0f437F0000, %f60, %p25;
	selp.f32 	%f62, 0f00000000, %f61, %p24;
	cvt.rzi.u32.f32 	%r60, %f62;
	fma.rn.f32 	%f63, %f20, %f54, %f22;
	fma.rn.f32 	%f64, %f24, %f3, %f63;
	setp.lt.f32 	%p26, %f64, 0f00000000;
	setp.gt.f32 	%p27, %f64, 0f437F0000;
	selp.f32 	%f65, 0f437F0000, %f64, %p27;
	selp.f32 	%f66, 0f00000000, %f65, %p26;
	cvt.rzi.u32.f32 	%r61, %f66;
	and.b32  	%r62, %r59, 255;
	and.b32  	%r63, %r60, 255;
	and.b32  	%r64, %r61, 255;
	prmt.b32 	%r65, %r63, %r62, 30212;
	prmt.b32 	%r66, %r64, %r65, 28756;
	prmt.b32 	%r67, %r55, %r56, 28756;
	st.global.v2.u32 	[%rd19], {%r67, %r66};

$L__BB2_2:
	ret;

}
.entry _Z14YuvToRgbKernelI6uchar26BGRA6410ulonglong2EvPhiS3_iii(
	.param .u64 _Z14YuvToRgbKernelI6uchar26BGRA6410ulonglong2EvPhiS3_iii_param_0,
	.param .u32 _Z14YuvToRgbKernelI6uchar26BGRA6410ulonglong2EvPhiS3_iii_param_1,
	.param .u64 _Z14YuvToRgbKernelI6uchar26BGRA6410ulonglong2EvPhiS3_iii_param_2,
	.param .u32 _Z14YuvToRgbKernelI6uchar26BGRA6410ulonglong2EvPhiS3_iii_param_3,
	.param .u32 _Z14YuvToRgbKernelI6uchar26BGRA6410ulonglong2EvPhiS3_iii_param_4,
	.param .u32 _Z14YuvToRgbKernelI6uchar26BGRA6410ulonglong2EvPhiS3_iii_param_5
)
{
	.reg .pred 	%p<28>;
	.reg .b16 	%rs<7>;
	.reg .f32 	%f<67>;
	.reg .b32 	%r<68>;
	.reg .b64 	%rd<40>;


	ld.param.u64 	%rd1, [_Z14YuvToRgbKernelI6uchar26BGRA6410ulonglong2EvPhiS3_iii_param_0];
	ld.param.u32 	%r3, [_Z14YuvToRgbKernelI6uchar26BGRA6410ulonglong2EvPhiS3_iii_param_1];
	ld.param.u64 	%rd2, [_Z14YuvToRgbKernelI6uchar26BGRA6410ulonglong2EvPhiS3_iii_param_2];
	ld.param.u32 	%r4, [_Z14YuvToRgbKernelI6uchar26BGRA6410ulonglong2EvPhiS3_iii_param_3];
	ld.param.u32 	%r6, [_Z14YuvToRgbKernelI6uchar26BGRA6410ulonglong2EvPhiS3_iii_param_4];
	ld.param.u32 	%r5, [_Z14YuvToRgbKernelI6uchar26BGRA6410ulonglong2EvPhiS3_iii_param_5];
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r8, %ctaid.x;
	mov.u32 	%r9, %tid.x;
	mad.lo.s32 	%r10, %r8, %r7, %r9;
	shl.b32 	%r1, %r10, 1;
	mov.u32 	%r11, %ntid.y;
	mov.u32 	%r12, %ctaid.y;
	mov.u32 	%r13, %tid.y;
	mad.lo.s32 	%r14, %r12, %r11, %r13;
	shl.b32 	%r2, %r14, 1;
	or.b32  	%r15, %r1, 1;
	setp.ge.s32 	%p1, %r15, %r6;
	or.b32  	%r16, %r2, 1;
	setp.ge.s32 	%p2, %r16, %r5;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	$L__BB3_2;

	cvt.s64.s32 	%rd3, %r1;
	and.b64  	%rd4, %rd3, 9223372036854775806;
	mul.lo.s32 	%r17, %r2, %r3;
	cvt.s64.s32 	%rd5, %r17;
	add.s64 	%rd6, %rd4, %rd5;
	cvta.to.global.u64 	%rd7, %rd1;
	add.s64 	%rd8, %rd7, %rd6;
	mul.wide.s32 	%rd9, %r1, 8;
	mul.lo.s32 	%r18, %r2, %r4;
	cvt.s64.s32 	%rd10, %r18;
	add.s64 	%rd11, %rd9, %rd10;
	cvta.to.global.u64 	%rd12, %rd2;
	add.s64 	%rd13, %rd12, %rd11;
	ld.global.v2.u8 	{%rs1, %rs2}, [%rd8];
	cvt.s64.s32 	%rd14, %r3;
	add.s64 	%rd15, %rd8, %rd14;
	ld.global.v2.u8 	{%rs3, %rs4}, [%rd15];
	shr.u32 	%r19, %r2, 31;
	add.s32 	%r20, %r2, %r19;
	shr.s32 	%r21, %r20, 1;
	sub.s32 	%r22, %r5, %r21;
	mul.lo.s32 	%r23, %r22, %r3;
	cvt.s64.s32 	%rd16, %r23;
	add.s64 	%rd17, %rd8, %rd16;
	ld.global.v2.u8 	{%rs5, %rs6}, [%rd17];
	cvt.u32.u16 	%r24, %rs1;
	add.s32 	%r25, %r24, -16;
	cvt.rn.f32.s32 	%f1, %r25;
	cvt.u32.u16 	%r26, %rs5;
	add.s32 	%r27, %r26, -128;
	cvt.rn.f32.s32 	%f2, %r27;
	cvt.u32.u16 	%r28, %rs6;
	add.s32 	%r29, %r28, -128;
	cvt.rn.f32.s32 	%f3, %r29;
	ld.const.f32 	%f4, [matYuv2Rgb];
	ld.const.f32 	%f5, [matYuv2Rgb+4];
	mul.f32 	%f6, %f5, %f2;
	fma.rn.f32 	%f7, %f4, %f1, %f6;
	ld.const.f32 	%f8, [matYuv2Rgb+8];
	fma.rn.f32 	%f9, %f8, %f3, %f7;
	setp.lt.f32 	%p4, %f9, 0f00000000;
	setp.gt.f32 	%p5, %f9, 0f437F0000;
	selp.f32 	%f10, 0f437F0000, %f9, %p5;
	selp.f32 	%f11, 0f00000000, %f10, %p4;
	cvt.rzi.u32.f32 	%r30, %f11;
	ld.const.f32 	%f12, [matYuv2Rgb+12];
	ld.const.f32 	%f13, [matYuv2Rgb+16];
	mul.f32 	%f14, %f13, %f2;
	fma.rn.f32 	%f15, %f12, %f1, %f14;
	ld.const.f32 	%f16, [matYuv2Rgb+20];
	fma.rn.f32 	%f17, %f16, %f3, %f15;
	setp.lt.f32 	%p6, %f17, 0f00000000;
	setp.gt.f32 	%p7, %f17, 0f437F0000;
	selp.f32 	%f18, 0f437F0000, %f17, %p7;
	selp.f32 	%f19, 0f00000000, %f18, %p6;
	cvt.rzi.u32.f32 	%r31, %f19;
	ld.const.f32 	%f20, [matYuv2Rgb+24];
	ld.const.f32 	%f21, [matYuv2Rgb+28];
	mul.f32 	%f22, %f21, %f2;
	fma.rn.f32 	%f23, %f20, %f1, %f22;
	ld.const.f32 	%f24, [matYuv2Rgb+32];
	fma.rn.f32 	%f25, %f24, %f3, %f23;
	setp.lt.f32 	%p8, %f25, 0f00000000;
	setp.gt.f32 	%p9, %f25, 0f437F0000;
	selp.f32 	%f26, 0f437F0000, %f25, %p9;
	selp.f32 	%f27, 0f00000000, %f26, %p8;
	cvt.rzi.u32.f32 	%r32, %f27;
	shl.b32 	%r33, %r30, 8;
	and.b32  	%r34, %r33, 65280;
	shl.b32 	%r35, %r31, 24;
	shl.b32 	%r36, %r32, 8;
	and.b32  	%r37, %r36, 65280;
	cvt.u64.u32 	%rd18, %r34;
	cvt.u64.u32 	%rd19, %r35;
	bfi.b64 	%rd20, %rd18, %rd19, 32, 32;
	cvt.u64.u32 	%rd21, %r37;
	cvt.u32.u16 	%r38, %rs2;
	add.s32 	%r39, %r38, -16;
	cvt.rn.f32.s32 	%f28, %r39;
	fma.rn.f32 	%f29, %f4, %f28, %f6;
	fma.rn.f32 	%f30, %f8, %f3, %f29;
	setp.lt.f32 	%p10, %f30, 0f00000000;
	setp.gt.f32 	%p11, %f30, 0f437F0000;
	selp.f32 	%f31, 0f437F0000, %f30, %p11;
	selp.f32 	%f32, 0f00000000, %f31, %p10;
	cvt.rzi.u32.f32 	%r40, %f32;
	fma.rn.f32 	%f33, %f12, %f28, %f14;
	fma.rn.f32 	%f34, %f16, %f3, %f33;
	setp.lt.f32 	%p12, %f34, 0f00000000;
	setp.gt.f32 	%p13, %f34, 0f437F0000;
	selp.f32 	%f35, 0f437F0000, %f34, %p13;
	selp.f32 	%f36, 0f00000000, %f35, %p12;
	cvt.rzi.u32.f32 	%r41, %f36;
	fma.rn.f32 	%f37, %f20, %f28, %f22;
	fma.rn.f32 	%f38, %f24, %f3, %f37;
	setp.lt.f32 	%p14, %f38, 0f00000000;
	setp.gt.f32 	%p15, %f38, 0f437F0000;
	selp.f32 	%f39, 0f437F0000, %f38, %p15;
	selp.f32 	%f40, 0f00000000, %f39, %p14;
	cvt.rzi.u32.f32 	%r42, %f40;
	shl.b32 	%r43, %r40, 8;
	and.b32  	%r44, %r43, 65280;
	shl.b32 	%r45, %r41, 24;
	shl.b32 	%r46, %r42, 8;
	and.b32  	%r47, %r46, 65280;
	cvt.u64.u32 	%rd22, %r44;
	cvt.u64.u32 	%rd23, %r45;
	bfi.b64 	%rd24, %rd22, %rd23, 32, 32;
	cvt.u64.u32 	%rd25, %r47;
	or.b64  	%rd26, %rd24, %rd25;
	or.b64  	%rd27, %rd20, %rd21;
	st.global.v2.u64 	[%rd13], {%rd27, %rd26};
	cvt.s64.s32 	%rd28, %r4;
	add.s64 	%rd29, %rd13, %rd28;
	cvt.u32.u16 	%r48, %rs3;
	add.s32 	%r49, %r48, -16;
	cvt.rn.f32.s32 	%f41, %r49;
	fma.rn.f32 	%f42, %f4, %f41, %f6;
	fma.rn.f32 	%f43, %f8, %f3, %f42;
	setp.lt.f32 	%p16, %f43, 0f00000000;
	setp.gt.f32 	%p17, %f43, 0f437F0000;
	selp.f32 	%f44, 0f437F0000, %f43, %p17;
	selp.f32 	%f45, 0f00000000, %f44, %p16;
	cvt.rzi.u32.f32 	%r50, %f45;
	fma.rn.f32 	%f46, %f12, %f41, %f14;
	fma.rn.f32 	%f47, %f16, %f3, %f46;
	setp.lt.f32 	%p18, %f47, 0f00000000;
	setp.gt.f32 	%p19, %f47, 0f437F0000;
	selp.f32 	%f48, 0f437F0000, %f47, %p19;
	selp.f32 	%f49, 0f00000000, %f48, %p18;
	cvt.rzi.u32.f32 	%r51, %f49;
	fma.rn.f32 	%f50, %f20, %f41, %f22;
	fma.rn.f32 	%f51, %f24, %f3, %f50;
	setp.lt.f32 	%p20, %f51, 0f00000000;
	setp.gt.f32 	%p21, %f51, 0f437F0000;
	selp.f32 	%f52, 0f437F0000, %f51, %p21;
	selp.f32 	%f53, 0f00000000, %f52, %p20;
	cvt.rzi.u32.f32 	%r52, %f53;
	shl.b32 	%r53, %r50, 8;
	and.b32  	%r54, %r53, 65280;
	shl.b32 	%r55, %r51, 24;
	shl.b32 	%r56, %r52, 8;
	and.b32  	%r57, %r56, 65280;
	cvt.u64.u32 	%rd30, %r54;
	cvt.u64.u32 	%rd31, %r55;
	bfi.b64 	%rd32, %rd30, %rd31, 32, 32;
	cvt.u64.u32 	%rd33, %r57;
	cvt.u32.u16 	%r58, %rs4;
	add.s32 	%r59, %r58, -16;
	cvt.rn.f32.s32 	%f54, %r59;
	fma.rn.f32 	%f55, %f4, %f54, %f6;
	fma.rn.f32 	%f56, %f8, %f3, %f55;
	setp.lt.f32 	%p22, %f56, 0f00000000;
	setp.gt.f32 	%p23, %f56, 0f437F0000;
	selp.f32 	%f57, 0f437F0000, %f56, %p23;
	selp.f32 	%f58, 0f00000000, %f57, %p22;
	cvt.rzi.u32.f32 	%r60, %f58;
	fma.rn.f32 	%f59, %f12, %f54, %f14;
	fma.rn.f32 	%f60, %f16, %f3, %f59;
	setp.lt.f32 	%p24, %f60, 0f00000000;
	setp.gt.f32 	%p25, %f60, 0f437F0000;
	selp.f32 	%f61, 0f437F0000, %f60, %p25;
	selp.f32 	%f62, 0f00000000, %f61, %p24;
	cvt.rzi.u32.f32 	%r61, %f62;
	fma.rn.f32 	%f63, %f20, %f54, %f22;
	fma.rn.f32 	%f64, %f24, %f3, %f63;
	setp.lt.f32 	%p26, %f64, 0f00000000;
	setp.gt.f32 	%p27, %f64, 0f437F0000;
	selp.f32 	%f65, 0f437F0000, %f64, %p27;
	selp.f32 	%f66, 0f00000000, %f65, %p26;
	cvt.rzi.u32.f32 	%r62, %f66;
	shl.b32 	%r63, %r60, 8;
	and.b32  	%r64, %r63, 65280;
	shl.b32 	%r65, %r61, 24;
	shl.b32 	%r66, %r62, 8;
	and.b32  	%r67, %r66, 65280;
	cvt.u64.u32 	%rd34, %r64;
	cvt.u64.u32 	%rd35, %r65;
	bfi.b64 	%rd36, %rd34, %rd35, 32, 32;
	cvt.u64.u32 	%rd37, %r67;
	or.b64  	%rd38, %rd36, %rd37;
	or.b64  	%rd39, %rd32, %rd33;
	st.global.v2.u64 	[%rd29], {%rd39, %rd38};

$L__BB3_2:
	ret;

}
.entry _Z14YuvToRgbKernelI6uchar26RGBA6410ulonglong2EvPhiS3_iii(
	.param .u64 _Z14YuvToRgbKernelI6uchar26RGBA6410ulonglong2EvPhiS3_iii_param_0,
	.param .u32 _Z14YuvToRgbKernelI6uchar26RGBA6410ulonglong2EvPhiS3_iii_param_1,
	.param .u64 _Z14YuvToRgbKernelI6uchar26RGBA6410ulonglong2EvPhiS3_iii_param_2,
	.param .u32 _Z14YuvToRgbKernelI6uchar26RGBA6410ulonglong2EvPhiS3_iii_param_3,
	.param .u32 _Z14YuvToRgbKernelI6uchar26RGBA6410ulonglong2EvPhiS3_iii_param_4,
	.param .u32 _Z14YuvToRgbKernelI6uchar26RGBA6410ulonglong2EvPhiS3_iii_param_5
)
{
	.reg .pred 	%p<28>;
	.reg .b16 	%rs<7>;
	.reg .f32 	%f<67>;
	.reg .b32 	%r<72>;
	.reg .b64 	%rd<32>;


	ld.param.u64 	%rd1, [_Z14YuvToRgbKernelI6uchar26RGBA6410ulonglong2EvPhiS3_iii_param_0];
	ld.param.u32 	%r3, [_Z14YuvToRgbKernelI6uchar26RGBA6410ulonglong2EvPhiS3_iii_param_1];
	ld.param.u64 	%rd2, [_Z14YuvToRgbKernelI6uchar26RGBA6410ulonglong2EvPhiS3_iii_param_2];
	ld.param.u32 	%r4, [_Z14YuvToRgbKernelI6uchar26RGBA6410ulonglong2EvPhiS3_iii_param_3];
	ld.param.u32 	%r6, [_Z14YuvToRgbKernelI6uchar26RGBA6410ulonglong2EvPhiS3_iii_param_4];
	ld.param.u32 	%r5, [_Z14YuvToRgbKernelI6uchar26RGBA6410ulonglong2EvPhiS3_iii_param_5];
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r8, %ctaid.x;
	mov.u32 	%r9, %tid.x;
	mad.lo.s32 	%r10, %r8, %r7, %r9;
	shl.b32 	%r1, %r10, 1;
	mov.u32 	%r11, %ntid.y;
	mov.u32 	%r12, %ctaid.y;
	mov.u32 	%r13, %tid.y;
	mad.lo.s32 	%r14, %r12, %r11, %r13;
	shl.b32 	%r2, %r14, 1;
	or.b32  	%r15, %r1, 1;
	setp.ge.s32 	%p1, %r15, %r6;
	or.b32  	%r16, %r2, 1;
	setp.ge.s32 	%p2, %r16, %r5;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	$L__BB4_2;

	cvt.s64.s32 	%rd3, %r1;
	and.b64  	%rd4, %rd3, 9223372036854775806;
	mul.lo.s32 	%r17, %r2, %r3;
	cvt.s64.s32 	%rd5, %r17;
	add.s64 	%rd6, %rd4, %rd5;
	cvta.to.global.u64 	%rd7, %rd1;
	add.s64 	%rd8, %rd7, %rd6;
	mul.wide.s32 	%rd9, %r1, 8;
	mul.lo.s32 	%r18, %r2, %r4;
	cvt.s64.s32 	%rd10, %r18;
	add.s64 	%rd11, %rd9, %rd10;
	cvta.to.global.u64 	%rd12, %rd2;
	add.s64 	%rd13, %rd12, %rd11;
	ld.global.v2.u8 	{%rs1, %rs2}, [%rd8];
	cvt.s64.s32 	%rd14, %r3;
	add.s64 	%rd15, %rd8, %rd14;
	ld.global.v2.u8 	{%rs3, %rs4}, [%rd15];
	shr.u32 	%r19, %r2, 31;
	add.s32 	%r20, %r2, %r19;
	shr.s32 	%r21, %r20, 1;
	sub.s32 	%r22, %r5, %r21;
	mul.lo.s32 	%r23, %r22, %r3;
	cvt.s64.s32 	%rd16, %r23;
	add.s64 	%rd17, %rd8, %rd16;
	ld.global.v2.u8 	{%rs5, %rs6}, [%rd17];
	cvt.u32.u16 	%r24, %rs1;
	add.s32 	%r25, %r24, -16;
	cvt.rn.f32.s32 	%f1, %r25;
	cvt.u32.u16 	%r26, %rs5;
	add.s32 	%r27, %r26, -128;
	cvt.rn.f32.s32 	%f2, %r27;
	cvt.u32.u16 	%r28, %rs6;
	add.s32 	%r29, %r28, -128;
	cvt.rn.f32.s32 	%f3, %r29;
	ld.const.f32 	%f4, [matYuv2Rgb];
	ld.const.f32 	%f5, [matYuv2Rgb+4];
	mul.f32 	%f6, %f5, %f2;
	fma.rn.f32 	%f7, %f4, %f1, %f6;
	ld.const.f32 	%f8, [matYuv2Rgb+8];
	fma.rn.f32 	%f9, %f8, %f3, %f7;
	setp.lt.f32 	%p4, %f9, 0f00000000;
	setp.gt.f32 	%p5, %f9, 0f437F0000;
	selp.f32 	%f10, 0f437F0000, %f9, %p5;
	selp.f32 	%f11, 0f00000000, %f10, %p4;
	cvt.rzi.u32.f32 	%r30, %f11;
	ld.const.f32 	%f12, [matYuv2Rgb+12];
	ld.const.f32 	%f13, [matYuv2Rgb+16];
	mul.f32 	%f14, %f13, %f2;
	fma.rn.f32 	%f15, %f12, %f1, %f14;
	ld.const.f32 	%f16, [matYuv2Rgb+20];
	fma.rn.f32 	%f17, %f16, %f3, %f15;
	setp.lt.f32 	%p6, %f17, 0f00000000;
	setp.gt.f32 	%p7, %f17, 0f437F0000;
	selp.f32 	%f18, 0f437F0000, %f17, %p7;
	selp.f32 	%f19, 0f00000000, %f18, %p6;
	cvt.rzi.u32.f32 	%r31, %f19;
	ld.const.f32 	%f20, [matYuv2Rgb+24];
	ld.const.f32 	%f21, [matYuv2Rgb+28];
	mul.f32 	%f22, %f21, %f2;
	fma.rn.f32 	%f23, %f20, %f1, %f22;
	ld.const.f32 	%f24, [matYuv2Rgb+32];
	fma.rn.f32 	%f25, %f24, %f3, %f23;
	setp.lt.f32 	%p8, %f25, 0f00000000;
	setp.gt.f32 	%p9, %f25, 0f437F0000;
	selp.f32 	%f26, 0f437F0000, %f25, %p9;
	selp.f32 	%f27, 0f00000000, %f26, %p8;
	cvt.rzi.u32.f32 	%r32, %f27;
	shl.b32 	%r33, %r30, 8;
	and.b32  	%r34, %r33, 65280;
	shl.b32 	%r35, %r31, 24;
	shl.b32 	%r36, %r32, 8;
	and.b32  	%r37, %r36, 65280;
	cvt.u64.u32 	%rd18, %r37;
	or.b32  	%r38, %r35, %r34;
	cvt.u64.u32 	%rd19, %r38;
	cvt.u32.u16 	%r39, %rs2;
	add.s32 	%r40, %r39, -16;
	cvt.rn.f32.s32 	%f28, %r40;
	fma.rn.f32 	%f29, %f4, %f28, %f6;
	fma.rn.f32 	%f30, %f8, %f3, %f29;
	setp.lt.f32 	%p10, %f30, 0f00000000;
	setp.gt.f32 	%p11, %f30, 0f437F0000;
	selp.f32 	%f31, 0f437F0000, %f30, %p11;
	selp.f32 	%f32, 0f00000000, %f31, %p10;
	cvt.rzi.u32.f32 	%r41, %f32;
	fma.rn.f32 	%f33, %f12, %f28, %f14;
	fma.rn.f32 	%f34, %f16, %f3, %f33;
	setp.lt.f32 	%p12, %f34, 0f00000000;
	setp.gt.f32 	%p13, %f34, 0f437F0000;
	selp.f32 	%f35, 0f437F0000, %f34, %p13;
	selp.f32 	%f36, 0f00000000, %f35, %p12;
	cvt.rzi.u32.f32 	%r42, %f36;
	fma.rn.f32 	%f37, %f20, %f28, %f22;
	fma.rn.f32 	%f38, %f24, %f3, %f37;
	setp.lt.f32 	%p14, %f38, 0f00000000;
	setp.gt.f32 	%p15, %f38, 0f437F0000;
	selp.f32 	%f39, 0f437F0000, %f38, %p15;
	selp.f32 	%f40, 0f00000000, %f39, %p14;
	cvt.rzi.u32.f32 	%r43, %f40;
	shl.b32 	%r44, %r41, 8;
	and.b32  	%r45, %r44, 65280;
	shl.b32 	%r46, %r42, 24;
	shl.b32 	%r47, %r43, 8;
	and.b32  	%r48, %r47, 65280;
	cvt.u64.u32 	%rd20, %r48;
	or.b32  	%r49, %r46, %r45;
	cvt.u64.u32 	%rd21, %r49;
	bfi.b64 	%rd22, %rd20, %rd21, 32, 32;
	bfi.b64 	%rd23, %rd18, %rd19, 32, 32;
	st.global.v2.u64 	[%rd13], {%rd23, %rd22};
	cvt.s64.s32 	%rd24, %r4;
	add.s64 	%rd25, %rd13, %rd24;
	cvt.u32.u16 	%r50, %rs3;
	add.s32 	%r51, %r50, -16;
	cvt.rn.f32.s32 	%f41, %r51;
	fma.rn.f32 	%f42, %f4, %f41, %f6;
	fma.rn.f32 	%f43, %f8, %f3, %f42;
	setp.lt.f32 	%p16, %f43, 0f00000000;
	setp.gt.f32 	%p17, %f43, 0f437F0000;
	selp.f32 	%f44, 0f437F0000, %f43, %p17;
	selp.f32 	%f45, 0f00000000, %f44, %p16;
	cvt.rzi.u32.f32 	%r52, %f45;
	fma.rn.f32 	%f46, %f12, %f41, %f14;
	fma.rn.f32 	%f47, %f16, %f3, %f46;
	setp.lt.f32 	%p18, %f47, 0f00000000;
	setp.gt.f32 	%p19, %f47, 0f437F0000;
	selp.f32 	%f48, 0f437F0000, %f47, %p19;
	selp.f32 	%f49, 0f00000000, %f48, %p18;
	cvt.rzi.u32.f32 	%r53, %f49;
	fma.rn.f32 	%f50, %f20, %f41, %f22;
	fma.rn.f32 	%f51, %f24, %f3, %f50;
	setp.lt.f32 	%p20, %f51, 0f00000000;
	setp.gt.f32 	%p21, %f51, 0f437F0000;
	selp.f32 	%f52, 0f437F0000, %f51, %p21;
	selp.f32 	%f53, 0f00000000, %f52, %p20;
	cvt.rzi.u32.f32 	%r54, %f53;
	shl.b32 	%r55, %r52, 8;
	and.b32  	%r56, %r55, 65280;
	shl.b32 	%r57, %r53, 24;
	shl.b32 	%r58, %r54, 8;
	and.b32  	%r59, %r58, 65280;
	cvt.u64.u32 	%rd26, %r59;
	or.b32  	%r60, %r57, %r56;
	cvt.u64.u32 	%rd27, %r60;
	cvt.u32.u16 	%r61, %rs4;
	add.s32 	%r62, %r61, -16;
	cvt.rn.f32.s32 	%f54, %r62;
	fma.rn.f32 	%f55, %f4, %f54, %f6;
	fma.rn.f32 	%f56, %f8, %f3, %f55;
	setp.lt.f32 	%p22, %f56, 0f00000000;
	setp.gt.f32 	%p23, %f56, 0f437F0000;
	selp.f32 	%f57, 0f437F0000, %f56, %p23;
	selp.f32 	%f58, 0f00000000, %f57, %p22;
	cvt.rzi.u32.f32 	%r63, %f58;
	fma.rn.f32 	%f59, %f12, %f54, %f14;
	fma.rn.f32 	%f60, %f16, %f3, %f59;
	setp.lt.f32 	%p24, %f60, 0f00000000;
	setp.gt.f32 	%p25, %f60, 0f437F0000;
	selp.f32 	%f61, 0f437F0000, %f60, %p25;
	selp.f32 	%f62, 0f00000000, %f61, %p24;
	cvt.rzi.u32.f32 	%r64, %f62;
	fma.rn.f32 	%f63, %f20, %f54, %f22;
	fma.rn.f32 	%f64, %f24, %f3, %f63;
	setp.lt.f32 	%p26, %f64, 0f00000000;
	setp.gt.f32 	%p27, %f64, 0f437F0000;
	selp.f32 	%f65, 0f437F0000, %f64, %p27;
	selp.f32 	%f66, 0f00000000, %f65, %p26;
	cvt.rzi.u32.f32 	%r65, %f66;
	shl.b32 	%r66, %r63, 8;
	and.b32  	%r67, %r66, 65280;
	shl.b32 	%r68, %r64, 24;
	shl.b32 	%r69, %r65, 8;
	and.b32  	%r70, %r69, 65280;
	cvt.u64.u32 	%rd28, %r70;
	or.b32  	%r71, %r68, %r67;
	cvt.u64.u32 	%rd29, %r71;
	bfi.b64 	%rd30, %rd28, %rd29, 32, 32;
	bfi.b64 	%rd31, %rd26, %rd27, 32, 32;
	st.global.v2.u64 	[%rd25], {%rd31, %rd30};

$L__BB4_2:
	ret;

}
.entry _Z17Yuv444ToRgbKernelI6uchar26BGRA325uint2EvPhiS3_iii(
	.param .u64 _Z17Yuv444ToRgbKernelI6uchar26BGRA325uint2EvPhiS3_iii_param_0,
	.param .u32 _Z17Yuv444ToRgbKernelI6uchar26BGRA325uint2EvPhiS3_iii_param_1,
	.param .u64 _Z17Yuv444ToRgbKernelI6uchar26BGRA325uint2EvPhiS3_iii_param_2,
	.param .u32 _Z17Yuv444ToRgbKernelI6uchar26BGRA325uint2EvPhiS3_iii_param_3,
	.param .u32 _Z17Yuv444ToRgbKernelI6uchar26BGRA325uint2EvPhiS3_iii_param_4,
	.param .u32 _Z17Yuv444ToRgbKernelI6uchar26BGRA325uint2EvPhiS3_iii_param_5
)
{
	.reg .pred 	%p<16>;
	.reg .b16 	%rs<7>;
	.reg .f32 	%f<46>;
	.reg .b32 	%r<51>;
	.reg .b64 	%rd<18>;


	ld.param.u64 	%rd1, [_Z17Yuv444ToRgbKernelI6uchar26BGRA325uint2EvPhiS3_iii_param_0];
	ld.param.u32 	%r3, [_Z17Yuv444ToRgbKernelI6uchar26BGRA325uint2EvPhiS3_iii_param_1];
	ld.param.u64 	%rd2, [_Z17Yuv444ToRgbKernelI6uchar26BGRA325uint2EvPhiS3_iii_param_2];
	ld.param.u32 	%r4, [_Z17Yuv444ToRgbKernelI6uchar26BGRA325uint2EvPhiS3_iii_param_3];
	ld.param.u32 	%r6, [_Z17Yuv444ToRgbKernelI6uchar26BGRA325uint2EvPhiS3_iii_param_4];
	ld.param.u32 	%r5, [_Z17Yuv444ToRgbKernelI6uchar26BGRA325uint2EvPhiS3_iii_param_5];
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r8, %ctaid.x;
	mov.u32 	%r9, %tid.x;
	mad.lo.s32 	%r10, %r8, %r7, %r9;
	shl.b32 	%r1, %r10, 1;
	mov.u32 	%r11, %ntid.y;
	mov.u32 	%r12, %ctaid.y;
	mov.u32 	%r13, %tid.y;
	mad.lo.s32 	%r2, %r12, %r11, %r13;
	or.b32  	%r14, %r1, 1;
	setp.ge.s32 	%p1, %r14, %r6;
	setp.ge.s32 	%p2, %r2, %r5;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	$L__BB5_2;

	cvta.to.global.u64 	%rd3, %rd2;
	cvt.s64.s32 	%rd4, %r1;
	and.b64  	%rd5, %rd4, 9223372036854775806;
	mul.lo.s32 	%r15, %r2, %r3;
	cvt.s64.s32 	%rd6, %r15;
	add.s64 	%rd7, %rd5, %rd6;
	cvta.to.global.u64 	%rd8, %rd1;
	add.s64 	%rd9, %rd8, %rd7;
	mul.wide.s32 	%rd10, %r1, 4;
	mul.lo.s32 	%r16, %r2, %r4;
	cvt.s64.s32 	%rd11, %r16;
	add.s64 	%rd12, %rd10, %rd11;
	add.s64 	%rd13, %rd3, %rd12;
	ld.global.v2.u8 	{%rs1, %rs2}, [%rd9];
	mul.lo.s32 	%r17, %r5, %r3;
	cvt.s64.s32 	%rd14, %r17;
	add.s64 	%rd15, %rd9, %rd14;
	ld.global.v2.u8 	{%rs3, %rs4}, [%rd15];
	shl.b32 	%r18, %r17, 1;
	cvt.s64.s32 	%rd16, %r18;
	add.s64 	%rd17, %rd9, %rd16;
	ld.global.v2.u8 	{%rs5, %rs6}, [%rd17];
	cvt.u32.u16 	%r19, %rs1;
	add.s32 	%r20, %r19, -16;
	cvt.rn.f32.s32 	%f1, %r20;
	cvt.u32.u16 	%r21, %rs3;
	add.s32 	%r22, %r21, -128;
	cvt.rn.f32.s32 	%f2, %r22;
	cvt.u32.u16 	%r23, %rs5;
	add.s32 	%r24, %r23, -128;
	cvt.rn.f32.s32 	%f3, %r24;
	ld.const.f32 	%f4, [matYuv2Rgb];
	ld.const.f32 	%f5, [matYuv2Rgb+4];
	mul.f32 	%f6, %f5, %f2;
	fma.rn.f32 	%f7, %f4, %f1, %f6;
	ld.const.f32 	%f8, [matYuv2Rgb+8];
	fma.rn.f32 	%f9, %f8, %f3, %f7;
	setp.lt.f32 	%p4, %f9, 0f00000000;
	setp.gt.f32 	%p5, %f9, 0f437F0000;
	selp.f32 	%f10, 0f437F0000, %f9, %p5;
	selp.f32 	%f11, 0f00000000, %f10, %p4;
	cvt.rzi.u32.f32 	%r25, %f11;
	ld.const.f32 	%f12, [matYuv2Rgb+12];
	ld.const.f32 	%f13, [matYuv2Rgb+16];
	mul.f32 	%f14, %f13, %f2;
	fma.rn.f32 	%f15, %f12, %f1, %f14;
	ld.const.f32 	%f16, [matYuv2Rgb+20];
	fma.rn.f32 	%f17, %f16, %f3, %f15;
	setp.lt.f32 	%p6, %f17, 0f00000000;
	setp.gt.f32 	%p7, %f17, 0f437F0000;
	selp.f32 	%f18, 0f437F0000, %f17, %p7;
	selp.f32 	%f19, 0f00000000, %f18, %p6;
	cvt.rzi.u32.f32 	%r26, %f19;
	ld.const.f32 	%f20, [matYuv2Rgb+24];
	ld.const.f32 	%f21, [matYuv2Rgb+28];
	mul.f32 	%f22, %f21, %f2;
	fma.rn.f32 	%f23, %f20, %f1, %f22;
	ld.const.f32 	%f24, [matYuv2Rgb+32];
	fma.rn.f32 	%f25, %f24, %f3, %f23;
	setp.lt.f32 	%p8, %f25, 0f00000000;
	setp.gt.f32 	%p9, %f25, 0f437F0000;
	selp.f32 	%f26, 0f437F0000, %f25, %p9;
	selp.f32 	%f27, 0f00000000, %f26, %p8;
	cvt.rzi.u32.f32 	%r27, %f27;
	and.b32  	%r28, %r27, 255;
	shl.b32 	%r29, %r25, 16;
	and.b32  	%r30, %r29, 16711680;
	shl.b32 	%r31, %r26, 8;
	and.b32  	%r32, %r31, 65280;
	or.b32  	%r33, %r32, %r30;
	cvt.u32.u16 	%r34, %rs2;
	add.s32 	%r35, %r34, -16;
	cvt.rn.f32.s32 	%f28, %r35;
	cvt.u32.u16 	%r36, %rs4;
	add.s32 	%r37, %r36, -128;
	cvt.rn.f32.s32 	%f29, %r37;
	cvt.u32.u16 	%r38, %rs6;
	add.s32 	%r39, %r38, -128;
	cvt.rn.f32.s32 	%f30, %r39;
	mul.f32 	%f31, %f5, %f29;
	fma.rn.f32 	%f32, %f4, %f28, %f31;
	fma.rn.f32 	%f33, %f8, %f30, %f32;
	setp.lt.f32 	%p10, %f33, 0f00000000;
	setp.gt.f32 	%p11, %f33, 0f437F0000;
	selp.f32 	%f34, 0f437F0000, %f33, %p11;
	selp.f32 	%f35, 0f00000000, %f34, %p10;
	cvt.rzi.u32.f32 	%r40, %f35;
	mul.f32 	%f36, %f13, %f29;
	fma.rn.f32 	%f37, %f12, %f28, %f36;
	fma.rn.f32 	%f38, %f16, %f30, %f37;
	setp.lt.f32 	%p12, %f38, 0f00000000;
	setp.gt.f32 	%p13, %f38, 0f437F0000;
	selp.f32 	%f39, 0f437F0000, %f38, %p13;
	selp.f32 	%f40, 0f00000000, %f39, %p12;
	cvt.rzi.u32.f32 	%r41, %f40;
	mul.f32 	%f41, %f21, %f29;
	fma.rn.f32 	%f42, %f20, %f28, %f41;
	fma.rn.f32 	%f43, %f24, %f30, %f42;
	setp.lt.f32 	%p14, %f43, 0f00000000;
	setp.gt.f32 	%p15, %f43, 0f437F0000;
	selp.f32 	%f44, 0f437F0000, %f43, %p15;
	selp.f32 	%f45, 0f00000000, %f44, %p14;
	cvt.rzi.u32.f32 	%r42, %f45;
	and.b32  	%r43, %r42, 255;
	shl.b32 	%r44, %r40, 16;
	and.b32  	%r45, %r44, 16711680;
	shl.b32 	%r46, %r41, 8;
	and.b32  	%r47, %r46, 65280;
	or.b32  	%r48, %r47, %r45;
	or.b32  	%r49, %r48, %r43;
	or.b32  	%r50, %r33, %r28;
	st.global.v2.u32 	[%rd13], {%r50, %r49};

$L__BB5_2:
	ret;

}
.entry _Z17Yuv444ToRgbKernelI6uchar26RGBA325uint2EvPhiS3_iii(
	.param .u64 _Z17Yuv444ToRgbKernelI6uchar26RGBA325uint2EvPhiS3_iii_param_0,
	.param .u32 _Z17Yuv444ToRgbKernelI6uchar26RGBA325uint2EvPhiS3_iii_param_1,
	.param .u64 _Z17Yuv444ToRgbKernelI6uchar26RGBA325uint2EvPhiS3_iii_param_2,
	.param .u32 _Z17Yuv444ToRgbKernelI6uchar26RGBA325uint2EvPhiS3_iii_param_3,
	.param .u32 _Z17Yuv444ToRgbKernelI6uchar26RGBA325uint2EvPhiS3_iii_param_4,
	.param .u32 _Z17Yuv444ToRgbKernelI6uchar26RGBA325uint2EvPhiS3_iii_param_5
)
{
	.reg .pred 	%p<16>;
	.reg .b16 	%rs<7>;
	.reg .f32 	%f<46>;
	.reg .b32 	%r<47>;
	.reg .b64 	%rd<18>;


	ld.param.u64 	%rd1, [_Z17Yuv444ToRgbKernelI6uchar26RGBA325uint2EvPhiS3_iii_param_0];
	ld.param.u32 	%r3, [_Z17Yuv444ToRgbKernelI6uchar26RGBA325uint2EvPhiS3_iii_param_1];
	ld.param.u64 	%rd2, [_Z17Yuv444ToRgbKernelI6uchar26RGBA325uint2EvPhiS3_iii_param_2];
	ld.param.u32 	%r4, [_Z17Yuv444ToRgbKernelI6uchar26RGBA325uint2EvPhiS3_iii_param_3];
	ld.param.u32 	%r6, [_Z17Yuv444ToRgbKernelI6uchar26RGBA325uint2EvPhiS3_iii_param_4];
	ld.param.u32 	%r5, [_Z17Yuv444ToRgbKernelI6uchar26RGBA325uint2EvPhiS3_iii_param_5];
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r8, %ctaid.x;
	mov.u32 	%r9, %tid.x;
	mad.lo.s32 	%r10, %r8, %r7, %r9;
	shl.b32 	%r1, %r10, 1;
	mov.u32 	%r11, %ntid.y;
	mov.u32 	%r12, %ctaid.y;
	mov.u32 	%r13, %tid.y;
	mad.lo.s32 	%r2, %r12, %r11, %r13;
	or.b32  	%r14, %r1, 1;
	setp.ge.s32 	%p1, %r14, %r6;
	setp.ge.s32 	%p2, %r2, %r5;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	$L__BB6_2;

	cvta.to.global.u64 	%rd3, %rd2;
	cvt.s64.s32 	%rd4, %r1;
	and.b64  	%rd5, %rd4, 9223372036854775806;
	mul.lo.s32 	%r15, %r2, %r3;
	cvt.s64.s32 	%rd6, %r15;
	add.s64 	%rd7, %rd5, %rd6;
	cvta.to.global.u64 	%rd8, %rd1;
	add.s64 	%rd9, %rd8, %rd7;
	mul.wide.s32 	%rd10, %r1, 4;
	mul.lo.s32 	%r16, %r2, %r4;
	cvt.s64.s32 	%rd11, %r16;
	add.s64 	%rd12, %rd10, %rd11;
	add.s64 	%rd13, %rd3, %rd12;
	ld.global.v2.u8 	{%rs1, %rs2}, [%rd9];
	mul.lo.s32 	%r17, %r5, %r3;
	cvt.s64.s32 	%rd14, %r17;
	add.s64 	%rd15, %rd9, %rd14;
	ld.global.v2.u8 	{%rs3, %rs4}, [%rd15];
	shl.b32 	%r18, %r17, 1;
	cvt.s64.s32 	%rd16, %r18;
	add.s64 	%rd17, %rd9, %rd16;
	ld.global.v2.u8 	{%rs5, %rs6}, [%rd17];
	cvt.u32.u16 	%r19, %rs1;
	add.s32 	%r20, %r19, -16;
	cvt.rn.f32.s32 	%f1, %r20;
	cvt.u32.u16 	%r21, %rs3;
	add.s32 	%r22, %r21, -128;
	cvt.rn.f32.s32 	%f2, %r22;
	cvt.u32.u16 	%r23, %rs5;
	add.s32 	%r24, %r23, -128;
	cvt.rn.f32.s32 	%f3, %r24;
	ld.const.f32 	%f4, [matYuv2Rgb];
	ld.const.f32 	%f5, [matYuv2Rgb+4];
	mul.f32 	%f6, %f5, %f2;
	fma.rn.f32 	%f7, %f4, %f1, %f6;
	ld.const.f32 	%f8, [matYuv2Rgb+8];
	fma.rn.f32 	%f9, %f8, %f3, %f7;
	setp.lt.f32 	%p4, %f9, 0f00000000;
	setp.gt.f32 	%p5, %f9, 0f437F0000;
	selp.f32 	%f10, 0f437F0000, %f9, %p5;
	selp.f32 	%f11, 0f00000000, %f10, %p4;
	cvt.rzi.u32.f32 	%r25, %f11;
	ld.const.f32 	%f12, [matYuv2Rgb+12];
	ld.const.f32 	%f13, [matYuv2Rgb+16];
	mul.f32 	%f14, %f13, %f2;
	fma.rn.f32 	%f15, %f12, %f1, %f14;
	ld.const.f32 	%f16, [matYuv2Rgb+20];
	fma.rn.f32 	%f17, %f16, %f3, %f15;
	setp.lt.f32 	%p6, %f17, 0f00000000;
	setp.gt.f32 	%p7, %f17, 0f437F0000;
	selp.f32 	%f18, 0f437F0000, %f17, %p7;
	selp.f32 	%f19, 0f00000000, %f18, %p6;
	cvt.rzi.u32.f32 	%r26, %f19;
	ld.const.f32 	%f20, [matYuv2Rgb+24];
	ld.const.f32 	%f21, [matYuv2Rgb+28];
	mul.f32 	%f22, %f21, %f2;
	fma.rn.f32 	%f23, %f20, %f1, %f22;
	ld.const.f32 	%f24, [matYuv2Rgb+32];
	fma.rn.f32 	%f25, %f24, %f3, %f23;
	setp.lt.f32 	%p8, %f25, 0f00000000;
	setp.gt.f32 	%p9, %f25, 0f437F0000;
	selp.f32 	%f26, 0f437F0000, %f25, %p9;
	selp.f32 	%f27, 0f00000000, %f26, %p8;
	cvt.rzi.u32.f32 	%r27, %f27;
	and.b32  	%r28, %r25, 255;
	and.b32  	%r29, %r26, 255;
	and.b32  	%r30, %r27, 255;
	prmt.b32 	%r31, %r29, %r28, 30212;
	cvt.u32.u16 	%r32, %rs2;
	add.s32 	%r33, %r32, -16;
	cvt.rn.f32.s32 	%f28, %r33;
	cvt.u32.u16 	%r34, %rs4;
	add.s32 	%r35, %r34, -128;
	cvt.rn.f32.s32 	%f29, %r35;
	cvt.u32.u16 	%r36, %rs6;
	add.s32 	%r37, %r36, -128;
	cvt.rn.f32.s32 	%f30, %r37;
	mul.f32 	%f31, %f5, %f29;
	fma.rn.f32 	%f32, %f4, %f28, %f31;
	fma.rn.f32 	%f33, %f8, %f30, %f32;
	setp.lt.f32 	%p10, %f33, 0f00000000;
	setp.gt.f32 	%p11, %f33, 0f437F0000;
	selp.f32 	%f34, 0f437F0000, %f33, %p11;
	selp.f32 	%f35, 0f00000000, %f34, %p10;
	cvt.rzi.u32.f32 	%r38, %f35;
	mul.f32 	%f36, %f13, %f29;
	fma.rn.f32 	%f37, %f12, %f28, %f36;
	fma.rn.f32 	%f38, %f16, %f30, %f37;
	setp.lt.f32 	%p12, %f38, 0f00000000;
	setp.gt.f32 	%p13, %f38, 0f437F0000;
	selp.f32 	%f39, 0f437F0000, %f38, %p13;
	selp.f32 	%f40, 0f00000000, %f39, %p12;
	cvt.rzi.u32.f32 	%r39, %f40;
	mul.f32 	%f41, %f21, %f29;
	fma.rn.f32 	%f42, %f20, %f28, %f41;
	fma.rn.f32 	%f43, %f24, %f30, %f42;
	setp.lt.f32 	%p14, %f43, 0f00000000;
	setp.gt.f32 	%p15, %f43, 0f437F0000;
	selp.f32 	%f44, 0f437F0000, %f43, %p15;
	selp.f32 	%f45, 0f00000000, %f44, %p14;
	cvt.rzi.u32.f32 	%r40, %f45;
	and.b32  	%r41, %r38, 255;
	and.b32  	%r42, %r39, 255;
	and.b32  	%r43, %r40, 255;
	prmt.b32 	%r44, %r42, %r41, 30212;
	prmt.b32 	%r45, %r43, %r44, 28756;
	prmt.b32 	%r46, %r30, %r31, 28756;
	st.global.v2.u32 	[%rd13], {%r46, %r45};

$L__BB6_2:
	ret;

}
.entry _Z17Yuv444ToRgbKernelI6uchar26BGRA6410ulonglong2EvPhiS3_iii(
	.param .u64 _Z17Yuv444ToRgbKernelI6uchar26BGRA6410ulonglong2EvPhiS3_iii_param_0,
	.param .u32 _Z17Yuv444ToRgbKernelI6uchar26BGRA6410ulonglong2EvPhiS3_iii_param_1,
	.param .u64 _Z17Yuv444ToRgbKernelI6uchar26BGRA6410ulonglong2EvPhiS3_iii_param_2,
	.param .u32 _Z17Yuv444ToRgbKernelI6uchar26BGRA6410ulonglong2EvPhiS3_iii_param_3,
	.param .u32 _Z17Yuv444ToRgbKernelI6uchar26BGRA6410ulonglong2EvPhiS3_iii_param_4,
	.param .u32 _Z17Yuv444ToRgbKernelI6uchar26BGRA6410ulonglong2EvPhiS3_iii_param_5
)
{
	.reg .pred 	%p<16>;
	.reg .b16 	%rs<7>;
	.reg .f32 	%f<46>;
	.reg .b32 	%r<47>;
	.reg .b64 	%rd<28>;


	ld.param.u64 	%rd1, [_Z17Yuv444ToRgbKernelI6uchar26BGRA6410ulonglong2EvPhiS3_iii_param_0];
	ld.param.u32 	%r3, [_Z17Yuv444ToRgbKernelI6uchar26BGRA6410ulonglong2EvPhiS3_iii_param_1];
	ld.param.u64 	%rd2, [_Z17Yuv444ToRgbKernelI6uchar26BGRA6410ulonglong2EvPhiS3_iii_param_2];
	ld.param.u32 	%r4, [_Z17Yuv444ToRgbKernelI6uchar26BGRA6410ulonglong2EvPhiS3_iii_param_3];
	ld.param.u32 	%r6, [_Z17Yuv444ToRgbKernelI6uchar26BGRA6410ulonglong2EvPhiS3_iii_param_4];
	ld.param.u32 	%r5, [_Z17Yuv444ToRgbKernelI6uchar26BGRA6410ulonglong2EvPhiS3_iii_param_5];
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r8, %ctaid.x;
	mov.u32 	%r9, %tid.x;
	mad.lo.s32 	%r10, %r8, %r7, %r9;
	shl.b32 	%r1, %r10, 1;
	mov.u32 	%r11, %ntid.y;
	mov.u32 	%r12, %ctaid.y;
	mov.u32 	%r13, %tid.y;
	mad.lo.s32 	%r2, %r12, %r11, %r13;
	or.b32  	%r14, %r1, 1;
	setp.ge.s32 	%p1, %r14, %r6;
	setp.ge.s32 	%p2, %r2, %r5;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	$L__BB7_2;

	cvta.to.global.u64 	%rd3, %rd2;
	cvt.s64.s32 	%rd4, %r1;
	and.b64  	%rd5, %rd4, 9223372036854775806;
	mul.lo.s32 	%r15, %r2, %r3;
	cvt.s64.s32 	%rd6, %r15;
	add.s64 	%rd7, %rd5, %rd6;
	cvta.to.global.u64 	%rd8, %rd1;
	add.s64 	%rd9, %rd8, %rd7;
	mul.wide.s32 	%rd10, %r1, 8;
	mul.lo.s32 	%r16, %r2, %r4;
	cvt.s64.s32 	%rd11, %r16;
	add.s64 	%rd12, %rd10, %rd11;
	add.s64 	%rd13, %rd3, %rd12;
	ld.global.v2.u8 	{%rs1, %rs2}, [%rd9];
	mul.lo.s32 	%r17, %r5, %r3;
	cvt.s64.s32 	%rd14, %r17;
	add.s64 	%rd15, %rd9, %rd14;
	ld.global.v2.u8 	{%rs3, %rs4}, [%rd15];
	shl.b32 	%r18, %r17, 1;
	cvt.s64.s32 	%rd16, %r18;
	add.s64 	%rd17, %rd9, %rd16;
	ld.global.v2.u8 	{%rs5, %rs6}, [%rd17];
	cvt.u32.u16 	%r19, %rs1;
	add.s32 	%r20, %r19, -16;
	cvt.rn.f32.s32 	%f1, %r20;
	cvt.u32.u16 	%r21, %rs3;
	add.s32 	%r22, %r21, -128;
	cvt.rn.f32.s32 	%f2, %r22;
	cvt.u32.u16 	%r23, %rs5;
	add.s32 	%r24, %r23, -128;
	cvt.rn.f32.s32 	%f3, %r24;
	ld.const.f32 	%f4, [matYuv2Rgb];
	ld.const.f32 	%f5, [matYuv2Rgb+4];
	mul.f32 	%f6, %f5, %f2;
	fma.rn.f32 	%f7, %f4, %f1, %f6;
	ld.const.f32 	%f8, [matYuv2Rgb+8];
	fma.rn.f32 	%f9, %f8, %f3, %f7;
	setp.lt.f32 	%p4, %f9, 0f00000000;
	setp.gt.f32 	%p5, %f9, 0f437F0000;
	selp.f32 	%f10, 0f437F0000, %f9, %p5;
	selp.f32 	%f11, 0f00000000, %f10, %p4;
	cvt.rzi.u32.f32 	%r25, %f11;
	ld.const.f32 	%f12, [matYuv2Rgb+12];
	ld.const.f32 	%f13, [matYuv2Rgb+16];
	mul.f32 	%f14, %f13, %f2;
	fma.rn.f32 	%f15, %f12, %f1, %f14;
	ld.const.f32 	%f16, [matYuv2Rgb+20];
	fma.rn.f32 	%f17, %f16, %f3, %f15;
	setp.lt.f32 	%p6, %f17, 0f00000000;
	setp.gt.f32 	%p7, %f17, 0f437F0000;
	selp.f32 	%f18, 0f437F0000, %f17, %p7;
	selp.f32 	%f19, 0f00000000, %f18, %p6;
	cvt.rzi.u32.f32 	%r26, %f19;
	ld.const.f32 	%f20, [matYuv2Rgb+24];
	ld.const.f32 	%f21, [matYuv2Rgb+28];
	mul.f32 	%f22, %f21, %f2;
	fma.rn.f32 	%f23, %f20, %f1, %f22;
	ld.const.f32 	%f24, [matYuv2Rgb+32];
	fma.rn.f32 	%f25, %f24, %f3, %f23;
	setp.lt.f32 	%p8, %f25, 0f00000000;
	setp.gt.f32 	%p9, %f25, 0f437F0000;
	selp.f32 	%f26, 0f437F0000, %f25, %p9;
	selp.f32 	%f27, 0f00000000, %f26, %p8;
	cvt.rzi.u32.f32 	%r27, %f27;
	shl.b32 	%r28, %r25, 8;
	and.b32  	%r29, %r28, 65280;
	shl.b32 	%r30, %r26, 24;
	shl.b32 	%r31, %r27, 8;
	and.b32  	%r32, %r31, 65280;
	cvt.u64.u32 	%rd18, %r29;
	cvt.u64.u32 	%rd19, %r30;
	bfi.b64 	%rd20, %rd18, %rd19, 32, 32;
	cvt.u64.u32 	%rd21, %r32;
	cvt.u32.u16 	%r33, %rs2;
	add.s32 	%r34, %r33, -16;
	cvt.rn.f32.s32 	%f28, %r34;
	cvt.u32.u16 	%r35, %rs4;
	add.s32 	%r36, %r35, -128;
	cvt.rn.f32.s32 	%f29, %r36;
	cvt.u32.u16 	%r37, %rs6;
	add.s32 	%r38, %r37, -128;
	cvt.rn.f32.s32 	%f30, %r38;
	mul.f32 	%f31, %f5, %f29;
	fma.rn.f32 	%f32, %f4, %f28, %f31;
	fma.rn.f32 	%f33, %f8, %f30, %f32;
	setp.lt.f32 	%p10, %f33, 0f00000000;
	setp.gt.f32 	%p11, %f33, 0f437F0000;
	selp.f32 	%f34, 0f437F0000, %f33, %p11;
	selp.f32 	%f35, 0f00000000, %f34, %p10;
	cvt.rzi.u32.f32 	%r39, %f35;
	mul.f32 	%f36, %f13, %f29;
	fma.rn.f32 	%f37, %f12, %f28, %f36;
	fma.rn.f32 	%f38, %f16, %f30, %f37;
	setp.lt.f32 	%p12, %f38, 0f00000000;
	setp.gt.f32 	%p13, %f38, 0f437F0000;
	selp.f32 	%f39, 0f437F0000, %f38, %p13;
	selp.f32 	%f40, 0f00000000, %f39, %p12;
	cvt.rzi.u32.f32 	%r40, %f40;
	mul.f32 	%f41, %f21, %f29;
	fma.rn.f32 	%f42, %f20, %f28, %f41;
	fma.rn.f32 	%f43, %f24, %f30, %f42;
	setp.lt.f32 	%p14, %f43, 0f00000000;
	setp.gt.f32 	%p15, %f43, 0f437F0000;
	selp.f32 	%f44, 0f437F0000, %f43, %p15;
	selp.f32 	%f45, 0f00000000, %f44, %p14;
	cvt.rzi.u32.f32 	%r41, %f45;
	shl.b32 	%r42, %r39, 8;
	and.b32  	%r43, %r42, 65280;
	shl.b32 	%r44, %r40, 24;
	shl.b32 	%r45, %r41, 8;
	and.b32  	%r46, %r45, 65280;
	cvt.u64.u32 	%rd22, %r43;
	cvt.u64.u32 	%rd23, %r44;
	bfi.b64 	%rd24, %rd22, %rd23, 32, 32;
	cvt.u64.u32 	%rd25, %r46;
	or.b64  	%rd26, %rd24, %rd25;
	or.b64  	%rd27, %rd20, %rd21;
	st.global.v2.u64 	[%rd13], {%rd27, %rd26};

$L__BB7_2:
	ret;

}
.entry _Z17Yuv444ToRgbKernelI6uchar26RGBA6410ulonglong2EvPhiS3_iii(
	.param .u64 _Z17Yuv444ToRgbKernelI6uchar26RGBA6410ulonglong2EvPhiS3_iii_param_0,
	.param .u32 _Z17Yuv444ToRgbKernelI6uchar26RGBA6410ulonglong2EvPhiS3_iii_param_1,
	.param .u64 _Z17Yuv444ToRgbKernelI6uchar26RGBA6410ulonglong2EvPhiS3_iii_param_2,
	.param .u32 _Z17Yuv444ToRgbKernelI6uchar26RGBA6410ulonglong2EvPhiS3_iii_param_3,
	.param .u32 _Z17Yuv444ToRgbKernelI6uchar26RGBA6410ulonglong2EvPhiS3_iii_param_4,
	.param .u32 _Z17Yuv444ToRgbKernelI6uchar26RGBA6410ulonglong2EvPhiS3_iii_param_5
)
{
	.reg .pred 	%p<16>;
	.reg .b16 	%rs<7>;
	.reg .f32 	%f<46>;
	.reg .b32 	%r<49>;
	.reg .b64 	%rd<24>;


	ld.param.u64 	%rd1, [_Z17Yuv444ToRgbKernelI6uchar26RGBA6410ulonglong2EvPhiS3_iii_param_0];
	ld.param.u32 	%r3, [_Z17Yuv444ToRgbKernelI6uchar26RGBA6410ulonglong2EvPhiS3_iii_param_1];
	ld.param.u64 	%rd2, [_Z17Yuv444ToRgbKernelI6uchar26RGBA6410ulonglong2EvPhiS3_iii_param_2];
	ld.param.u32 	%r4, [_Z17Yuv444ToRgbKernelI6uchar26RGBA6410ulonglong2EvPhiS3_iii_param_3];
	ld.param.u32 	%r6, [_Z17Yuv444ToRgbKernelI6uchar26RGBA6410ulonglong2EvPhiS3_iii_param_4];
	ld.param.u32 	%r5, [_Z17Yuv444ToRgbKernelI6uchar26RGBA6410ulonglong2EvPhiS3_iii_param_5];
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r8, %ctaid.x;
	mov.u32 	%r9, %tid.x;
	mad.lo.s32 	%r10, %r8, %r7, %r9;
	shl.b32 	%r1, %r10, 1;
	mov.u32 	%r11, %ntid.y;
	mov.u32 	%r12, %ctaid.y;
	mov.u32 	%r13, %tid.y;
	mad.lo.s32 	%r2, %r12, %r11, %r13;
	or.b32  	%r14, %r1, 1;
	setp.ge.s32 	%p1, %r14, %r6;
	setp.ge.s32 	%p2, %r2, %r5;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	$L__BB8_2;

	cvta.to.global.u64 	%rd3, %rd2;
	cvt.s64.s32 	%rd4, %r1;
	and.b64  	%rd5, %rd4, 9223372036854775806;
	mul.lo.s32 	%r15, %r2, %r3;
	cvt.s64.s32 	%rd6, %r15;
	add.s64 	%rd7, %rd5, %rd6;
	cvta.to.global.u64 	%rd8, %rd1;
	add.s64 	%rd9, %rd8, %rd7;
	mul.wide.s32 	%rd10, %r1, 8;
	mul.lo.s32 	%r16, %r2, %r4;
	cvt.s64.s32 	%rd11, %r16;
	add.s64 	%rd12, %rd10, %rd11;
	add.s64 	%rd13, %rd3, %rd12;
	ld.global.v2.u8 	{%rs1, %rs2}, [%rd9];
	mul.lo.s32 	%r17, %r5, %r3;
	cvt.s64.s32 	%rd14, %r17;
	add.s64 	%rd15, %rd9, %rd14;
	ld.global.v2.u8 	{%rs3, %rs4}, [%rd15];
	shl.b32 	%r18, %r17, 1;
	cvt.s64.s32 	%rd16, %r18;
	add.s64 	%rd17, %rd9, %rd16;
	ld.global.v2.u8 	{%rs5, %rs6}, [%rd17];
	cvt.u32.u16 	%r19, %rs1;
	add.s32 	%r20, %r19, -16;
	cvt.rn.f32.s32 	%f1, %r20;
	cvt.u32.u16 	%r21, %rs3;
	add.s32 	%r22, %r21, -128;
	cvt.rn.f32.s32 	%f2, %r22;
	cvt.u32.u16 	%r23, %rs5;
	add.s32 	%r24, %r23, -128;
	cvt.rn.f32.s32 	%f3, %r24;
	ld.const.f32 	%f4, [matYuv2Rgb];
	ld.const.f32 	%f5, [matYuv2Rgb+4];
	mul.f32 	%f6, %f5, %f2;
	fma.rn.f32 	%f7, %f4, %f1, %f6;
	ld.const.f32 	%f8, [matYuv2Rgb+8];
	fma.rn.f32 	%f9, %f8, %f3, %f7;
	setp.lt.f32 	%p4, %f9, 0f00000000;
	setp.gt.f32 	%p5, %f9, 0f437F0000;
	selp.f32 	%f10, 0f437F0000, %f9, %p5;
	selp.f32 	%f11, 0f00000000, %f10, %p4;
	cvt.rzi.u32.f32 	%r25, %f11;
	ld.const.f32 	%f12, [matYuv2Rgb+12];
	ld.const.f32 	%f13, [matYuv2Rgb+16];
	mul.f32 	%f14, %f13, %f2;
	fma.rn.f32 	%f15, %f12, %f1, %f14;
	ld.const.f32 	%f16, [matYuv2Rgb+20];
	fma.rn.f32 	%f17, %f16, %f3, %f15;
	setp.lt.f32 	%p6, %f17, 0f00000000;
	setp.gt.f32 	%p7, %f17, 0f437F0000;
	selp.f32 	%f18, 0f437F0000, %f17, %p7;
	selp.f32 	%f19, 0f00000000, %f18, %p6;
	cvt.rzi.u32.f32 	%r26, %f19;
	ld.const.f32 	%f20, [matYuv2Rgb+24];
	ld.const.f32 	%f21, [matYuv2Rgb+28];
	mul.f32 	%f22, %f21, %f2;
	fma.rn.f32 	%f23, %f20, %f1, %f22;
	ld.const.f32 	%f24, [matYuv2Rgb+32];
	fma.rn.f32 	%f25, %f24, %f3, %f23;
	setp.lt.f32 	%p8, %f25, 0f00000000;
	setp.gt.f32 	%p9, %f25, 0f437F0000;
	selp.f32 	%f26, 0f437F0000, %f25, %p9;
	selp.f32 	%f27, 0f00000000, %f26, %p8;
	cvt.rzi.u32.f32 	%r27, %f27;
	shl.b32 	%r28, %r25, 8;
	and.b32  	%r29, %r28, 65280;
	shl.b32 	%r30, %r26, 24;
	shl.b32 	%r31, %r27, 8;
	and.b32  	%r32, %r31, 65280;
	cvt.u64.u32 	%rd18, %r32;
	or.b32  	%r33, %r30, %r29;
	cvt.u64.u32 	%rd19, %r33;
	cvt.u32.u16 	%r34, %rs2;
	add.s32 	%r35, %r34, -16;
	cvt.rn.f32.s32 	%f28, %r35;
	cvt.u32.u16 	%r36, %rs4;
	add.s32 	%r37, %r36, -128;
	cvt.rn.f32.s32 	%f29, %r37;
	cvt.u32.u16 	%r38, %rs6;
	add.s32 	%r39, %r38, -128;
	cvt.rn.f32.s32 	%f30, %r39;
	mul.f32 	%f31, %f5, %f29;
	fma.rn.f32 	%f32, %f4, %f28, %f31;
	fma.rn.f32 	%f33, %f8, %f30, %f32;
	setp.lt.f32 	%p10, %f33, 0f00000000;
	setp.gt.f32 	%p11, %f33, 0f437F0000;
	selp.f32 	%f34, 0f437F0000, %f33, %p11;
	selp.f32 	%f35, 0f00000000, %f34, %p10;
	cvt.rzi.u32.f32 	%r40, %f35;
	mul.f32 	%f36, %f13, %f29;
	fma.rn.f32 	%f37, %f12, %f28, %f36;
	fma.rn.f32 	%f38, %f16, %f30, %f37;
	setp.lt.f32 	%p12, %f38, 0f00000000;
	setp.gt.f32 	%p13, %f38, 0f437F0000;
	selp.f32 	%f39, 0f437F0000, %f38, %p13;
	selp.f32 	%f40, 0f00000000, %f39, %p12;
	cvt.rzi.u32.f32 	%r41, %f40;
	mul.f32 	%f41, %f21, %f29;
	fma.rn.f32 	%f42, %f20, %f28, %f41;
	fma.rn.f32 	%f43, %f24, %f30, %f42;
	setp.lt.f32 	%p14, %f43, 0f00000000;
	setp.gt.f32 	%p15, %f43, 0f437F0000;
	selp.f32 	%f44, 0f437F0000, %f43, %p15;
	selp.f32 	%f45, 0f00000000, %f44, %p14;
	cvt.rzi.u32.f32 	%r42, %f45;
	shl.b32 	%r43, %r40, 8;
	and.b32  	%r44, %r43, 65280;
	shl.b32 	%r45, %r41, 24;
	shl.b32 	%r46, %r42, 8;
	and.b32  	%r47, %r46, 65280;
	cvt.u64.u32 	%rd20, %r47;
	or.b32  	%r48, %r45, %r44;
	cvt.u64.u32 	%rd21, %r48;
	bfi.b64 	%rd22, %rd20, %rd21, 32, 32;
	bfi.b64 	%rd23, %rd18, %rd19, 32, 32;
	st.global.v2.u64 	[%rd13], {%rd23, %rd22};

$L__BB8_2:
	ret;

}
.entry _Z14YuvToRgbKernelI7ushort26BGRA325uint2EvPhiS3_iii(
	.param .u64 _Z14YuvToRgbKernelI7ushort26BGRA325uint2EvPhiS3_iii_param_0,
	.param .u32 _Z14YuvToRgbKernelI7ushort26BGRA325uint2EvPhiS3_iii_param_1,
	.param .u64 _Z14YuvToRgbKernelI7ushort26BGRA325uint2EvPhiS3_iii_param_2,
	.param .u32 _Z14YuvToRgbKernelI7ushort26BGRA325uint2EvPhiS3_iii_param_3,
	.param .u32 _Z14YuvToRgbKernelI7ushort26BGRA325uint2EvPhiS3_iii_param_4,
	.param .u32 _Z14YuvToRgbKernelI7ushort26BGRA325uint2EvPhiS3_iii_param_5
)
{
	.reg .pred 	%p<28>;
	.reg .b16 	%rs<13>;
	.reg .f32 	%f<67>;
	.reg .b32 	%r<72>;
	.reg .b64 	%rd<20>;


	ld.param.u64 	%rd1, [_Z14YuvToRgbKernelI7ushort26BGRA325uint2EvPhiS3_iii_param_0];
	ld.param.u32 	%r3, [_Z14YuvToRgbKernelI7ushort26BGRA325uint2EvPhiS3_iii_param_1];
	ld.param.u64 	%rd2, [_Z14YuvToRgbKernelI7ushort26BGRA325uint2EvPhiS3_iii_param_2];
	ld.param.u32 	%r4, [_Z14YuvToRgbKernelI7ushort26BGRA325uint2EvPhiS3_iii_param_3];
	ld.param.u32 	%r6, [_Z14YuvToRgbKernelI7ushort26BGRA325uint2EvPhiS3_iii_param_4];
	ld.param.u32 	%r5, [_Z14YuvToRgbKernelI7ushort26BGRA325uint2EvPhiS3_iii_param_5];
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r8, %ctaid.x;
	mov.u32 	%r9, %tid.x;
	mad.lo.s32 	%r10, %r8, %r7, %r9;
	shl.b32 	%r1, %r10, 1;
	mov.u32 	%r11, %ntid.y;
	mov.u32 	%r12, %ctaid.y;
	mov.u32 	%r13, %tid.y;
	mad.lo.s32 	%r14, %r12, %r11, %r13;
	shl.b32 	%r2, %r14, 1;
	or.b32  	%r15, %r1, 1;
	setp.ge.s32 	%p1, %r15, %r6;
	or.b32  	%r16, %r2, 1;
	setp.ge.s32 	%p2, %r16, %r5;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	$L__BB9_2;

	mul.wide.s32 	%rd3, %r1, 2;
	and.b64  	%rd4, %rd3, 9223372036854775804;
	mul.lo.s32 	%r17, %r2, %r3;
	cvt.s64.s32 	%rd5, %r17;
	add.s64 	%rd6, %rd4, %rd5;
	cvta.to.global.u64 	%rd7, %rd1;
	add.s64 	%rd8, %rd7, %rd6;
	mul.wide.s32 	%rd9, %r1, 4;
	mul.lo.s32 	%r18, %r2, %r4;
	cvt.s64.s32 	%rd10, %r18;
	add.s64 	%rd11, %rd9, %rd10;
	cvta.to.global.u64 	%rd12, %rd2;
	add.s64 	%rd13, %rd12, %rd11;
	ld.global.v2.u16 	{%rs1, %rs2}, [%rd8];
	cvt.s64.s32 	%rd14, %r3;
	add.s64 	%rd15, %rd8, %rd14;
	ld.global.v2.u16 	{%rs5, %rs6}, [%rd15];
	shr.u32 	%r19, %r2, 31;
	add.s32 	%r20, %r2, %r19;
	shr.s32 	%r21, %r20, 1;
	sub.s32 	%r22, %r5, %r21;
	mul.lo.s32 	%r23, %r22, %r3;
	cvt.s64.s32 	%rd16, %r23;
	add.s64 	%rd17, %rd8, %rd16;
	ld.global.v2.u16 	{%rs9, %rs10}, [%rd17];
	cvt.u32.u16 	%r24, %rs1;
	add.s32 	%r25, %r24, -4096;
	cvt.rn.f32.s32 	%f1, %r25;
	cvt.u32.u16 	%r26, %rs9;
	add.s32 	%r27, %r26, -32768;
	cvt.rn.f32.s32 	%f2, %r27;
	cvt.u32.u16 	%r28, %rs10;
	add.s32 	%r29, %r28, -32768;
	cvt.rn.f32.s32 	%f3, %r29;
	ld.const.f32 	%f4, [matYuv2Rgb];
	ld.const.f32 	%f5, [matYuv2Rgb+4];
	mul.f32 	%f6, %f5, %f2;
	fma.rn.f32 	%f7, %f4, %f1, %f6;
	ld.const.f32 	%f8, [matYuv2Rgb+8];
	fma.rn.f32 	%f9, %f8, %f3, %f7;
	setp.lt.f32 	%p4, %f9, 0f00000000;
	setp.gt.f32 	%p5, %f9, 0f477FFF00;
	selp.f32 	%f10, 0f477FFF00, %f9, %p5;
	selp.f32 	%f11, 0f00000000, %f10, %p4;
	cvt.rzi.u32.f32 	%r30, %f11;
	ld.const.f32 	%f12, [matYuv2Rgb+12];
	ld.const.f32 	%f13, [matYuv2Rgb+16];
	mul.f32 	%f14, %f13, %f2;
	fma.rn.f32 	%f15, %f12, %f1, %f14;
	ld.const.f32 	%f16, [matYuv2Rgb+20];
	fma.rn.f32 	%f17, %f16, %f3, %f15;
	setp.lt.f32 	%p6, %f17, 0f00000000;
	setp.gt.f32 	%p7, %f17, 0f477FFF00;
	selp.f32 	%f18, 0f477FFF00, %f17, %p7;
	selp.f32 	%f19, 0f00000000, %f18, %p6;
	cvt.rzi.u32.f32 	%r31, %f19;
	ld.const.f32 	%f20, [matYuv2Rgb+24];
	ld.const.f32 	%f21, [matYuv2Rgb+28];
	mul.f32 	%f22, %f21, %f2;
	fma.rn.f32 	%f23, %f20, %f1, %f22;
	ld.const.f32 	%f24, [matYuv2Rgb+32];
	fma.rn.f32 	%f25, %f24, %f3, %f23;
	setp.lt.f32 	%p8, %f25, 0f00000000;
	setp.gt.f32 	%p9, %f25, 0f477FFF00;
	selp.f32 	%f26, 0f477FFF00, %f25, %p9;
	selp.f32 	%f27, 0f00000000, %f26, %p8;
	cvt.rzi.u32.f32 	%r32, %f27;
	and.b32  	%r33, %r31, 65280;
	bfe.u32 	%r34, %r32, 8, 8;
	shl.b32 	%r35, %r30, 8;
	and.b32  	%r36, %r35, 16711680;
	or.b32  	%r37, %r33, %r36;
	cvt.u32.u16 	%r38, %rs2;
	add.s32 	%r39, %r38, -4096;
	cvt.rn.f32.s32 	%f28, %r39;
	fma.rn.f32 	%f29, %f4, %f28, %f6;
	fma.rn.f32 	%f30, %f8, %f3, %f29;
	setp.lt.f32 	%p10, %f30, 0f00000000;
	setp.gt.f32 	%p11, %f30, 0f477FFF00;
	selp.f32 	%f31, 0f477FFF00, %f30, %p11;
	selp.f32 	%f32, 0f00000000, %f31, %p10;
	cvt.rzi.u32.f32 	%r40, %f32;
	fma.rn.f32 	%f33, %f12, %f28, %f14;
	fma.rn.f32 	%f34, %f16, %f3, %f33;
	setp.lt.f32 	%p12, %f34, 0f00000000;
	setp.gt.f32 	%p13, %f34, 0f477FFF00;
	selp.f32 	%f35, 0f477FFF00, %f34, %p13;
	selp.f32 	%f36, 0f00000000, %f35, %p12;
	cvt.rzi.u32.f32 	%r41, %f36;
	fma.rn.f32 	%f37, %f20, %f28, %f22;
	fma.rn.f32 	%f38, %f24, %f3, %f37;
	setp.lt.f32 	%p14, %f38, 0f00000000;
	setp.gt.f32 	%p15, %f38, 0f477FFF00;
	selp.f32 	%f39, 0f477FFF00, %f38, %p15;
	selp.f32 	%f40, 0f00000000, %f39, %p14;
	cvt.rzi.u32.f32 	%r42, %f40;
	and.b32  	%r43, %r41, 65280;
	bfe.u32 	%r44, %r42, 8, 8;
	shl.b32 	%r45, %r40, 8;
	and.b32  	%r46, %r45, 16711680;
	or.b32  	%r47, %r43, %r46;
	or.b32  	%r48, %r47, %r44;
	or.b32  	%r49, %r37, %r34;
	st.global.v2.u32 	[%rd13], {%r49, %r48};
	cvt.s64.s32 	%rd18, %r4;
	add.s64 	%rd19, %rd13, %rd18;
	cvt.u32.u16 	%r50, %rs5;
	add.s32 	%r51, %r50, -4096;
	cvt.rn.f32.s32 	%f41, %r51;
	fma.rn.f32 	%f42, %f4, %f41, %f6;
	fma.rn.f32 	%f43, %f8, %f3, %f42;
	setp.lt.f32 	%p16, %f43, 0f00000000;
	setp.gt.f32 	%p17, %f43, 0f477FFF00;
	selp.f32 	%f44, 0f477FFF00, %f43, %p17;
	selp.f32 	%f45, 0f00000000, %f44, %p16;
	cvt.rzi.u32.f32 	%r52, %f45;
	fma.rn.f32 	%f46, %f12, %f41, %f14;
	fma.rn.f32 	%f47, %f16, %f3, %f46;
	setp.lt.f32 	%p18, %f47, 0f00000000;
	setp.gt.f32 	%p19, %f47, 0f477FFF00;
	selp.f32 	%f48, 0f477FFF00, %f47, %p19;
	selp.f32 	%f49, 0f00000000, %f48, %p18;
	cvt.rzi.u32.f32 	%r53, %f49;
	fma.rn.f32 	%f50, %f20, %f41, %f22;
	fma.rn.f32 	%f51, %f24, %f3, %f50;
	setp.lt.f32 	%p20, %f51, 0f00000000;
	setp.gt.f32 	%p21, %f51, 0f477FFF00;
	selp.f32 	%f52, 0f477FFF00, %f51, %p21;
	selp.f32 	%f53, 0f00000000, %f52, %p20;
	cvt.rzi.u32.f32 	%r54, %f53;
	and.b32  	%r55, %r53, 65280;
	bfe.u32 	%r56, %r54, 8, 8;
	shl.b32 	%r57, %r52, 8;
	and.b32  	%r58, %r57, 16711680;
	or.b32  	%r59, %r55, %r58;
	cvt.u32.u16 	%r60, %rs6;
	add.s32 	%r61, %r60, -4096;
	cvt.rn.f32.s32 	%f54, %r61;
	fma.rn.f32 	%f55, %f4, %f54, %f6;
	fma.rn.f32 	%f56, %f8, %f3, %f55;
	setp.lt.f32 	%p22, %f56, 0f00000000;
	setp.gt.f32 	%p23, %f56, 0f477FFF00;
	selp.f32 	%f57, 0f477FFF00, %f56, %p23;
	selp.f32 	%f58, 0f00000000, %f57, %p22;
	cvt.rzi.u32.f32 	%r62, %f58;
	fma.rn.f32 	%f59, %f12, %f54, %f14;
	fma.rn.f32 	%f60, %f16, %f3, %f59;
	setp.lt.f32 	%p24, %f60, 0f00000000;
	setp.gt.f32 	%p25, %f60, 0f477FFF00;
	selp.f32 	%f61, 0f477FFF00, %f60, %p25;
	selp.f32 	%f62, 0f00000000, %f61, %p24;
	cvt.rzi.u32.f32 	%r63, %f62;
	fma.rn.f32 	%f63, %f20, %f54, %f22;
	fma.rn.f32 	%f64, %f24, %f3, %f63;
	setp.lt.f32 	%p26, %f64, 0f00000000;
	setp.gt.f32 	%p27, %f64, 0f477FFF00;
	selp.f32 	%f65, 0f477FFF00, %f64, %p27;
	selp.f32 	%f66, 0f00000000, %f65, %p26;
	cvt.rzi.u32.f32 	%r64, %f66;
	and.b32  	%r65, %r63, 65280;
	bfe.u32 	%r66, %r64, 8, 8;
	shl.b32 	%r67, %r62, 8;
	and.b32  	%r68, %r67, 16711680;
	or.b32  	%r69, %r65, %r68;
	or.b32  	%r70, %r69, %r66;
	or.b32  	%r71, %r59, %r56;
	st.global.v2.u32 	[%rd19], {%r71, %r70};

$L__BB9_2:
	ret;

}
.entry _Z14YuvToRgbKernelI7ushort26RGBA325uint2EvPhiS3_iii(
	.param .u64 _Z14YuvToRgbKernelI7ushort26RGBA325uint2EvPhiS3_iii_param_0,
	.param .u32 _Z14YuvToRgbKernelI7ushort26RGBA325uint2EvPhiS3_iii_param_1,
	.param .u64 _Z14YuvToRgbKernelI7ushort26RGBA325uint2EvPhiS3_iii_param_2,
	.param .u32 _Z14YuvToRgbKernelI7ushort26RGBA325uint2EvPhiS3_iii_param_3,
	.param .u32 _Z14YuvToRgbKernelI7ushort26RGBA325uint2EvPhiS3_iii_param_4,
	.param .u32 _Z14YuvToRgbKernelI7ushort26RGBA325uint2EvPhiS3_iii_param_5
)
{
	.reg .pred 	%p<28>;
	.reg .b16 	%rs<13>;
	.reg .f32 	%f<67>;
	.reg .b32 	%r<72>;
	.reg .b64 	%rd<20>;


	ld.param.u64 	%rd1, [_Z14YuvToRgbKernelI7ushort26RGBA325uint2EvPhiS3_iii_param_0];
	ld.param.u32 	%r3, [_Z14YuvToRgbKernelI7ushort26RGBA325uint2EvPhiS3_iii_param_1];
	ld.param.u64 	%rd2, [_Z14YuvToRgbKernelI7ushort26RGBA325uint2EvPhiS3_iii_param_2];
	ld.param.u32 	%r4, [_Z14YuvToRgbKernelI7ushort26RGBA325uint2EvPhiS3_iii_param_3];
	ld.param.u32 	%r6, [_Z14YuvToRgbKernelI7ushort26RGBA325uint2EvPhiS3_iii_param_4];
	ld.param.u32 	%r5, [_Z14YuvToRgbKernelI7ushort26RGBA325uint2EvPhiS3_iii_param_5];
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r8, %ctaid.x;
	mov.u32 	%r9, %tid.x;
	mad.lo.s32 	%r10, %r8, %r7, %r9;
	shl.b32 	%r1, %r10, 1;
	mov.u32 	%r11, %ntid.y;
	mov.u32 	%r12, %ctaid.y;
	mov.u32 	%r13, %tid.y;
	mad.lo.s32 	%r14, %r12, %r11, %r13;
	shl.b32 	%r2, %r14, 1;
	or.b32  	%r15, %r1, 1;
	setp.ge.s32 	%p1, %r15, %r6;
	or.b32  	%r16, %r2, 1;
	setp.ge.s32 	%p2, %r16, %r5;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	$L__BB10_2;

	mul.wide.s32 	%rd3, %r1, 2;
	and.b64  	%rd4, %rd3, 9223372036854775804;
	mul.lo.s32 	%r17, %r2, %r3;
	cvt.s64.s32 	%rd5, %r17;
	add.s64 	%rd6, %rd4, %rd5;
	cvta.to.global.u64 	%rd7, %rd1;
	add.s64 	%rd8, %rd7, %rd6;
	mul.wide.s32 	%rd9, %r1, 4;
	mul.lo.s32 	%r18, %r2, %r4;
	cvt.s64.s32 	%rd10, %r18;
	add.s64 	%rd11, %rd9, %rd10;
	cvta.to.global.u64 	%rd12, %rd2;
	add.s64 	%rd13, %rd12, %rd11;
	ld.global.v2.u16 	{%rs1, %rs2}, [%rd8];
	cvt.s64.s32 	%rd14, %r3;
	add.s64 	%rd15, %rd8, %rd14;
	ld.global.v2.u16 	{%rs5, %rs6}, [%rd15];
	shr.u32 	%r19, %r2, 31;
	add.s32 	%r20, %r2, %r19;
	shr.s32 	%r21, %r20, 1;
	sub.s32 	%r22, %r5, %r21;
	mul.lo.s32 	%r23, %r22, %r3;
	cvt.s64.s32 	%rd16, %r23;
	add.s64 	%rd17, %rd8, %rd16;
	ld.global.v2.u16 	{%rs9, %rs10}, [%rd17];
	cvt.u32.u16 	%r24, %rs1;
	add.s32 	%r25, %r24, -4096;
	cvt.rn.f32.s32 	%f1, %r25;
	cvt.u32.u16 	%r26, %rs9;
	add.s32 	%r27, %r26, -32768;
	cvt.rn.f32.s32 	%f2, %r27;
	cvt.u32.u16 	%r28, %rs10;
	add.s32 	%r29, %r28, -32768;
	cvt.rn.f32.s32 	%f3, %r29;
	ld.const.f32 	%f4, [matYuv2Rgb];
	ld.const.f32 	%f5, [matYuv2Rgb+4];
	mul.f32 	%f6, %f5, %f2;
	fma.rn.f32 	%f7, %f4, %f1, %f6;
	ld.const.f32 	%f8, [matYuv2Rgb+8];
	fma.rn.f32 	%f9, %f8, %f3, %f7;
	setp.lt.f32 	%p4, %f9, 0f00000000;
	setp.gt.f32 	%p5, %f9, 0f477FFF00;
	selp.f32 	%f10, 0f477FFF00, %f9, %p5;
	selp.f32 	%f11, 0f00000000, %f10, %p4;
	cvt.rzi.u32.f32 	%r30, %f11;
	ld.const.f32 	%f12, [matYuv2Rgb+12];
	ld.const.f32 	%f13, [matYuv2Rgb+16];
	mul.f32 	%f14, %f13, %f2;
	fma.rn.f32 	%f15, %f12, %f1, %f14;
	ld.const.f32 	%f16, [matYuv2Rgb+20];
	fma.rn.f32 	%f17, %f16, %f3, %f15;
	setp.lt.f32 	%p6, %f17, 0f00000000;
	setp.gt.f32 	%p7, %f17, 0f477FFF00;
	selp.f32 	%f18, 0f477FFF00, %f17, %p7;
	selp.f32 	%f19, 0f00000000, %f18, %p6;
	cvt.rzi.u32.f32 	%r31, %f19;
	ld.const.f32 	%f20, [matYuv2Rgb+24];
	ld.const.f32 	%f21, [matYuv2Rgb+28];
	mul.f32 	%f22, %f21, %f2;
	fma.rn.f32 	%f23, %f20, %f1, %f22;
	ld.const.f32 	%f24, [matYuv2Rgb+32];
	fma.rn.f32 	%f25, %f24, %f3, %f23;
	setp.lt.f32 	%p8, %f25, 0f00000000;
	setp.gt.f32 	%p9, %f25, 0f477FFF00;
	selp.f32 	%f26, 0f477FFF00, %f25, %p9;
	selp.f32 	%f27, 0f00000000, %f26, %p8;
	cvt.rzi.u32.f32 	%r32, %f27;
	bfe.u32 	%r33, %r30, 8, 8;
	and.b32  	%r34, %r31, 65280;
	shl.b32 	%r35, %r32, 8;
	and.b32  	%r36, %r35, 16711680;
	or.b32  	%r37, %r34, %r33;
	cvt.u32.u16 	%r38, %rs2;
	add.s32 	%r39, %r38, -4096;
	cvt.rn.f32.s32 	%f28, %r39;
	fma.rn.f32 	%f29, %f4, %f28, %f6;
	fma.rn.f32 	%f30, %f8, %f3, %f29;
	setp.lt.f32 	%p10, %f30, 0f00000000;
	setp.gt.f32 	%p11, %f30, 0f477FFF00;
	selp.f32 	%f31, 0f477FFF00, %f30, %p11;
	selp.f32 	%f32, 0f00000000, %f31, %p10;
	cvt.rzi.u32.f32 	%r40, %f32;
	fma.rn.f32 	%f33, %f12, %f28, %f14;
	fma.rn.f32 	%f34, %f16, %f3, %f33;
	setp.lt.f32 	%p12, %f34, 0f00000000;
	setp.gt.f32 	%p13, %f34, 0f477FFF00;
	selp.f32 	%f35, 0f477FFF00, %f34, %p13;
	selp.f32 	%f36, 0f00000000, %f35, %p12;
	cvt.rzi.u32.f32 	%r41, %f36;
	fma.rn.f32 	%f37, %f20, %f28, %f22;
	fma.rn.f32 	%f38, %f24, %f3, %f37;
	setp.lt.f32 	%p14, %f38, 0f00000000;
	setp.gt.f32 	%p15, %f38, 0f477FFF00;
	selp.f32 	%f39, 0f477FFF00, %f38, %p15;
	selp.f32 	%f40, 0f00000000, %f39, %p14;
	cvt.rzi.u32.f32 	%r42, %f40;
	bfe.u32 	%r43, %r40, 8, 8;
	and.b32  	%r44, %r41, 65280;
	shl.b32 	%r45, %r42, 8;
	and.b32  	%r46, %r45, 16711680;
	or.b32  	%r47, %r44, %r43;
	or.b32  	%r48, %r47, %r46;
	or.b32  	%r49, %r37, %r36;
	st.global.v2.u32 	[%rd13], {%r49, %r48};
	cvt.s64.s32 	%rd18, %r4;
	add.s64 	%rd19, %rd13, %rd18;
	cvt.u32.u16 	%r50, %rs5;
	add.s32 	%r51, %r50, -4096;
	cvt.rn.f32.s32 	%f41, %r51;
	fma.rn.f32 	%f42, %f4, %f41, %f6;
	fma.rn.f32 	%f43, %f8, %f3, %f42;
	setp.lt.f32 	%p16, %f43, 0f00000000;
	setp.gt.f32 	%p17, %f43, 0f477FFF00;
	selp.f32 	%f44, 0f477FFF00, %f43, %p17;
	selp.f32 	%f45, 0f00000000, %f44, %p16;
	cvt.rzi.u32.f32 	%r52, %f45;
	fma.rn.f32 	%f46, %f12, %f41, %f14;
	fma.rn.f32 	%f47, %f16, %f3, %f46;
	setp.lt.f32 	%p18, %f47, 0f00000000;
	setp.gt.f32 	%p19, %f47, 0f477FFF00;
	selp.f32 	%f48, 0f477FFF00, %f47, %p19;
	selp.f32 	%f49, 0f00000000, %f48, %p18;
	cvt.rzi.u32.f32 	%r53, %f49;
	fma.rn.f32 	%f50, %f20, %f41, %f22;
	fma.rn.f32 	%f51, %f24, %f3, %f50;
	setp.lt.f32 	%p20, %f51, 0f00000000;
	setp.gt.f32 	%p21, %f51, 0f477FFF00;
	selp.f32 	%f52, 0f477FFF00, %f51, %p21;
	selp.f32 	%f53, 0f00000000, %f52, %p20;
	cvt.rzi.u32.f32 	%r54, %f53;
	bfe.u32 	%r55, %r52, 8, 8;
	and.b32  	%r56, %r53, 65280;
	shl.b32 	%r57, %r54, 8;
	and.b32  	%r58, %r57, 16711680;
	or.b32  	%r59, %r56, %r55;
	cvt.u32.u16 	%r60, %rs6;
	add.s32 	%r61, %r60, -4096;
	cvt.rn.f32.s32 	%f54, %r61;
	fma.rn.f32 	%f55, %f4, %f54, %f6;
	fma.rn.f32 	%f56, %f8, %f3, %f55;
	setp.lt.f32 	%p22, %f56, 0f00000000;
	setp.gt.f32 	%p23, %f56, 0f477FFF00;
	selp.f32 	%f57, 0f477FFF00, %f56, %p23;
	selp.f32 	%f58, 0f00000000, %f57, %p22;
	cvt.rzi.u32.f32 	%r62, %f58;
	fma.rn.f32 	%f59, %f12, %f54, %f14;
	fma.rn.f32 	%f60, %f16, %f3, %f59;
	setp.lt.f32 	%p24, %f60, 0f00000000;
	setp.gt.f32 	%p25, %f60, 0f477FFF00;
	selp.f32 	%f61, 0f477FFF00, %f60, %p25;
	selp.f32 	%f62, 0f00000000, %f61, %p24;
	cvt.rzi.u32.f32 	%r63, %f62;
	fma.rn.f32 	%f63, %f20, %f54, %f22;
	fma.rn.f32 	%f64, %f24, %f3, %f63;
	setp.lt.f32 	%p26, %f64, 0f00000000;
	setp.gt.f32 	%p27, %f64, 0f477FFF00;
	selp.f32 	%f65, 0f477FFF00, %f64, %p27;
	selp.f32 	%f66, 0f00000000, %f65, %p26;
	cvt.rzi.u32.f32 	%r64, %f66;
	bfe.u32 	%r65, %r62, 8, 8;
	and.b32  	%r66, %r63, 65280;
	shl.b32 	%r67, %r64, 8;
	and.b32  	%r68, %r67, 16711680;
	or.b32  	%r69, %r66, %r65;
	or.b32  	%r70, %r69, %r68;
	or.b32  	%r71, %r59, %r58;
	st.global.v2.u32 	[%rd19], {%r71, %r70};

$L__BB10_2:
	ret;

}
.entry _Z14YuvToRgbKernelI7ushort26BGRA6410ulonglong2EvPhiS3_iii(
	.param .u64 _Z14YuvToRgbKernelI7ushort26BGRA6410ulonglong2EvPhiS3_iii_param_0,
	.param .u32 _Z14YuvToRgbKernelI7ushort26BGRA6410ulonglong2EvPhiS3_iii_param_1,
	.param .u64 _Z14YuvToRgbKernelI7ushort26BGRA6410ulonglong2EvPhiS3_iii_param_2,
	.param .u32 _Z14YuvToRgbKernelI7ushort26BGRA6410ulonglong2EvPhiS3_iii_param_3,
	.param .u32 _Z14YuvToRgbKernelI7ushort26BGRA6410ulonglong2EvPhiS3_iii_param_4,
	.param .u32 _Z14YuvToRgbKernelI7ushort26BGRA6410ulonglong2EvPhiS3_iii_param_5
)
{
	.reg .pred 	%p<28>;
	.reg .b16 	%rs<13>;
	.reg .f32 	%f<67>;
	.reg .b32 	%r<60>;
	.reg .b64 	%rd<40>;


	ld.param.u64 	%rd1, [_Z14YuvToRgbKernelI7ushort26BGRA6410ulonglong2EvPhiS3_iii_param_0];
	ld.param.u32 	%r3, [_Z14YuvToRgbKernelI7ushort26BGRA6410ulonglong2EvPhiS3_iii_param_1];
	ld.param.u64 	%rd2, [_Z14YuvToRgbKernelI7ushort26BGRA6410ulonglong2EvPhiS3_iii_param_2];
	ld.param.u32 	%r4, [_Z14YuvToRgbKernelI7ushort26BGRA6410ulonglong2EvPhiS3_iii_param_3];
	ld.param.u32 	%r6, [_Z14YuvToRgbKernelI7ushort26BGRA6410ulonglong2EvPhiS3_iii_param_4];
	ld.param.u32 	%r5, [_Z14YuvToRgbKernelI7ushort26BGRA6410ulonglong2EvPhiS3_iii_param_5];
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r8, %ctaid.x;
	mov.u32 	%r9, %tid.x;
	mad.lo.s32 	%r10, %r8, %r7, %r9;
	shl.b32 	%r1, %r10, 1;
	mov.u32 	%r11, %ntid.y;
	mov.u32 	%r12, %ctaid.y;
	mov.u32 	%r13, %tid.y;
	mad.lo.s32 	%r14, %r12, %r11, %r13;
	shl.b32 	%r2, %r14, 1;
	or.b32  	%r15, %r1, 1;
	setp.ge.s32 	%p1, %r15, %r6;
	or.b32  	%r16, %r2, 1;
	setp.ge.s32 	%p2, %r16, %r5;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	$L__BB11_2;

	mul.wide.s32 	%rd3, %r1, 2;
	and.b64  	%rd4, %rd3, 9223372036854775804;
	mul.lo.s32 	%r17, %r2, %r3;
	cvt.s64.s32 	%rd5, %r17;
	add.s64 	%rd6, %rd4, %rd5;
	cvta.to.global.u64 	%rd7, %rd1;
	add.s64 	%rd8, %rd7, %rd6;
	mul.wide.s32 	%rd9, %r1, 8;
	mul.lo.s32 	%r18, %r2, %r4;
	cvt.s64.s32 	%rd10, %r18;
	add.s64 	%rd11, %rd9, %rd10;
	cvta.to.global.u64 	%rd12, %rd2;
	add.s64 	%rd13, %rd12, %rd11;
	ld.global.v2.u16 	{%rs1, %rs2}, [%rd8];
	cvt.s64.s32 	%rd14, %r3;
	add.s64 	%rd15, %rd8, %rd14;
	ld.global.v2.u16 	{%rs5, %rs6}, [%rd15];
	shr.u32 	%r19, %r2, 31;
	add.s32 	%r20, %r2, %r19;
	shr.s32 	%r21, %r20, 1;
	sub.s32 	%r22, %r5, %r21;
	mul.lo.s32 	%r23, %r22, %r3;
	cvt.s64.s32 	%rd16, %r23;
	add.s64 	%rd17, %rd8, %rd16;
	ld.global.v2.u16 	{%rs9, %rs10}, [%rd17];
	cvt.u32.u16 	%r24, %rs1;
	add.s32 	%r25, %r24, -4096;
	cvt.rn.f32.s32 	%f1, %r25;
	cvt.u32.u16 	%r26, %rs9;
	add.s32 	%r27, %r26, -32768;
	cvt.rn.f32.s32 	%f2, %r27;
	cvt.u32.u16 	%r28, %rs10;
	add.s32 	%r29, %r28, -32768;
	cvt.rn.f32.s32 	%f3, %r29;
	ld.const.f32 	%f4, [matYuv2Rgb];
	ld.const.f32 	%f5, [matYuv2Rgb+4];
	mul.f32 	%f6, %f5, %f2;
	fma.rn.f32 	%f7, %f4, %f1, %f6;
	ld.const.f32 	%f8, [matYuv2Rgb+8];
	fma.rn.f32 	%f9, %f8, %f3, %f7;
	setp.lt.f32 	%p4, %f9, 0f00000000;
	setp.gt.f32 	%p5, %f9, 0f477FFF00;
	selp.f32 	%f10, 0f477FFF00, %f9, %p5;
	selp.f32 	%f11, 0f00000000, %f10, %p4;
	cvt.rzi.u32.f32 	%r30, %f11;
	ld.const.f32 	%f12, [matYuv2Rgb+12];
	ld.const.f32 	%f13, [matYuv2Rgb+16];
	mul.f32 	%f14, %f13, %f2;
	fma.rn.f32 	%f15, %f12, %f1, %f14;
	ld.const.f32 	%f16, [matYuv2Rgb+20];
	fma.rn.f32 	%f17, %f16, %f3, %f15;
	setp.lt.f32 	%p6, %f17, 0f00000000;
	setp.gt.f32 	%p7, %f17, 0f477FFF00;
	selp.f32 	%f18, 0f477FFF00, %f17, %p7;
	selp.f32 	%f19, 0f00000000, %f18, %p6;
	cvt.rzi.u32.f32 	%r31, %f19;
	ld.const.f32 	%f20, [matYuv2Rgb+24];
	ld.const.f32 	%f21, [matYuv2Rgb+28];
	mul.f32 	%f22, %f21, %f2;
	fma.rn.f32 	%f23, %f20, %f1, %f22;
	ld.const.f32 	%f24, [matYuv2Rgb+32];
	fma.rn.f32 	%f25, %f24, %f3, %f23;
	setp.lt.f32 	%p8, %f25, 0f00000000;
	setp.gt.f32 	%p9, %f25, 0f477FFF00;
	selp.f32 	%f26, 0f477FFF00, %f25, %p9;
	selp.f32 	%f27, 0f00000000, %f26, %p8;
	cvt.rzi.u32.f32 	%r32, %f27;
	and.b32  	%r33, %r30, 65535;
	and.b32  	%r34, %r32, 65535;
	cvt.u64.u32 	%rd18, %r33;
	shl.b32 	%r35, %r31, 16;
	cvt.u64.u32 	%rd19, %r35;
	bfi.b64 	%rd20, %rd18, %rd19, 32, 32;
	cvt.u64.u32 	%rd21, %r34;
	cvt.u32.u16 	%r36, %rs2;
	add.s32 	%r37, %r36, -4096;
	cvt.rn.f32.s32 	%f28, %r37;
	fma.rn.f32 	%f29, %f4, %f28, %f6;
	fma.rn.f32 	%f30, %f8, %f3, %f29;
	setp.lt.f32 	%p10, %f30, 0f00000000;
	setp.gt.f32 	%p11, %f30, 0f477FFF00;
	selp.f32 	%f31, 0f477FFF00, %f30, %p11;
	selp.f32 	%f32, 0f00000000, %f31, %p10;
	cvt.rzi.u32.f32 	%r38, %f32;
	fma.rn.f32 	%f33, %f12, %f28, %f14;
	fma.rn.f32 	%f34, %f16, %f3, %f33;
	setp.lt.f32 	%p12, %f34, 0f00000000;
	setp.gt.f32 	%p13, %f34, 0f477FFF00;
	selp.f32 	%f35, 0f477FFF00, %f34, %p13;
	selp.f32 	%f36, 0f00000000, %f35, %p12;
	cvt.rzi.u32.f32 	%r39, %f36;
	fma.rn.f32 	%f37, %f20, %f28, %f22;
	fma.rn.f32 	%f38, %f24, %f3, %f37;
	setp.lt.f32 	%p14, %f38, 0f00000000;
	setp.gt.f32 	%p15, %f38, 0f477FFF00;
	selp.f32 	%f39, 0f477FFF00, %f38, %p15;
	selp.f32 	%f40, 0f00000000, %f39, %p14;
	cvt.rzi.u32.f32 	%r40, %f40;
	and.b32  	%r41, %r38, 65535;
	and.b32  	%r42, %r40, 65535;
	cvt.u64.u32 	%rd22, %r41;
	shl.b32 	%r43, %r39, 16;
	cvt.u64.u32 	%rd23, %r43;
	bfi.b64 	%rd24, %rd22, %rd23, 32, 32;
	cvt.u64.u32 	%rd25, %r42;
	or.b64  	%rd26, %rd24, %rd25;
	or.b64  	%rd27, %rd20, %rd21;
	st.global.v2.u64 	[%rd13], {%rd27, %rd26};
	cvt.s64.s32 	%rd28, %r4;
	add.s64 	%rd29, %rd13, %rd28;
	cvt.u32.u16 	%r44, %rs5;
	add.s32 	%r45, %r44, -4096;
	cvt.rn.f32.s32 	%f41, %r45;
	fma.rn.f32 	%f42, %f4, %f41, %f6;
	fma.rn.f32 	%f43, %f8, %f3, %f42;
	setp.lt.f32 	%p16, %f43, 0f00000000;
	setp.gt.f32 	%p17, %f43, 0f477FFF00;
	selp.f32 	%f44, 0f477FFF00, %f43, %p17;
	selp.f32 	%f45, 0f00000000, %f44, %p16;
	cvt.rzi.u32.f32 	%r46, %f45;
	fma.rn.f32 	%f46, %f12, %f41, %f14;
	fma.rn.f32 	%f47, %f16, %f3, %f46;
	setp.lt.f32 	%p18, %f47, 0f00000000;
	setp.gt.f32 	%p19, %f47, 0f477FFF00;
	selp.f32 	%f48, 0f477FFF00, %f47, %p19;
	selp.f32 	%f49, 0f00000000, %f48, %p18;
	cvt.rzi.u32.f32 	%r47, %f49;
	fma.rn.f32 	%f50, %f20, %f41, %f22;
	fma.rn.f32 	%f51, %f24, %f3, %f50;
	setp.lt.f32 	%p20, %f51, 0f00000000;
	setp.gt.f32 	%p21, %f51, 0f477FFF00;
	selp.f32 	%f52, 0f477FFF00, %f51, %p21;
	selp.f32 	%f53, 0f00000000, %f52, %p20;
	cvt.rzi.u32.f32 	%r48, %f53;
	and.b32  	%r49, %r46, 65535;
	and.b32  	%r50, %r48, 65535;
	cvt.u64.u32 	%rd30, %r49;
	shl.b32 	%r51, %r47, 16;
	cvt.u64.u32 	%rd31, %r51;
	bfi.b64 	%rd32, %rd30, %rd31, 32, 32;
	cvt.u64.u32 	%rd33, %r50;
	cvt.u32.u16 	%r52, %rs6;
	add.s32 	%r53, %r52, -4096;
	cvt.rn.f32.s32 	%f54, %r53;
	fma.rn.f32 	%f55, %f4, %f54, %f6;
	fma.rn.f32 	%f56, %f8, %f3, %f55;
	setp.lt.f32 	%p22, %f56, 0f00000000;
	setp.gt.f32 	%p23, %f56, 0f477FFF00;
	selp.f32 	%f57, 0f477FFF00, %f56, %p23;
	selp.f32 	%f58, 0f00000000, %f57, %p22;
	cvt.rzi.u32.f32 	%r54, %f58;
	fma.rn.f32 	%f59, %f12, %f54, %f14;
	fma.rn.f32 	%f60, %f16, %f3, %f59;
	setp.lt.f32 	%p24, %f60, 0f00000000;
	setp.gt.f32 	%p25, %f60, 0f477FFF00;
	selp.f32 	%f61, 0f477FFF00, %f60, %p25;
	selp.f32 	%f62, 0f00000000, %f61, %p24;
	cvt.rzi.u32.f32 	%r55, %f62;
	fma.rn.f32 	%f63, %f20, %f54, %f22;
	fma.rn.f32 	%f64, %f24, %f3, %f63;
	setp.lt.f32 	%p26, %f64, 0f00000000;
	setp.gt.f32 	%p27, %f64, 0f477FFF00;
	selp.f32 	%f65, 0f477FFF00, %f64, %p27;
	selp.f32 	%f66, 0f00000000, %f65, %p26;
	cvt.rzi.u32.f32 	%r56, %f66;
	and.b32  	%r57, %r54, 65535;
	and.b32  	%r58, %r56, 65535;
	cvt.u64.u32 	%rd34, %r57;
	shl.b32 	%r59, %r55, 16;
	cvt.u64.u32 	%rd35, %r59;
	bfi.b64 	%rd36, %rd34, %rd35, 32, 32;
	cvt.u64.u32 	%rd37, %r58;
	or.b64  	%rd38, %rd36, %rd37;
	or.b64  	%rd39, %rd32, %rd33;
	st.global.v2.u64 	[%rd29], {%rd39, %rd38};

$L__BB11_2:
	ret;

}
.entry _Z14YuvToRgbKernelI7ushort26RGBA6410ulonglong2EvPhiS3_iii(
	.param .u64 _Z14YuvToRgbKernelI7ushort26RGBA6410ulonglong2EvPhiS3_iii_param_0,
	.param .u32 _Z14YuvToRgbKernelI7ushort26RGBA6410ulonglong2EvPhiS3_iii_param_1,
	.param .u64 _Z14YuvToRgbKernelI7ushort26RGBA6410ulonglong2EvPhiS3_iii_param_2,
	.param .u32 _Z14YuvToRgbKernelI7ushort26RGBA6410ulonglong2EvPhiS3_iii_param_3,
	.param .u32 _Z14YuvToRgbKernelI7ushort26RGBA6410ulonglong2EvPhiS3_iii_param_4,
	.param .u32 _Z14YuvToRgbKernelI7ushort26RGBA6410ulonglong2EvPhiS3_iii_param_5
)
{
	.reg .pred 	%p<28>;
	.reg .b16 	%rs<13>;
	.reg .f32 	%f<67>;
	.reg .b32 	%r<60>;
	.reg .b64 	%rd<32>;


	ld.param.u64 	%rd1, [_Z14YuvToRgbKernelI7ushort26RGBA6410ulonglong2EvPhiS3_iii_param_0];
	ld.param.u32 	%r3, [_Z14YuvToRgbKernelI7ushort26RGBA6410ulonglong2EvPhiS3_iii_param_1];
	ld.param.u64 	%rd2, [_Z14YuvToRgbKernelI7ushort26RGBA6410ulonglong2EvPhiS3_iii_param_2];
	ld.param.u32 	%r4, [_Z14YuvToRgbKernelI7ushort26RGBA6410ulonglong2EvPhiS3_iii_param_3];
	ld.param.u32 	%r6, [_Z14YuvToRgbKernelI7ushort26RGBA6410ulonglong2EvPhiS3_iii_param_4];
	ld.param.u32 	%r5, [_Z14YuvToRgbKernelI7ushort26RGBA6410ulonglong2EvPhiS3_iii_param_5];
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r8, %ctaid.x;
	mov.u32 	%r9, %tid.x;
	mad.lo.s32 	%r10, %r8, %r7, %r9;
	shl.b32 	%r1, %r10, 1;
	mov.u32 	%r11, %ntid.y;
	mov.u32 	%r12, %ctaid.y;
	mov.u32 	%r13, %tid.y;
	mad.lo.s32 	%r14, %r12, %r11, %r13;
	shl.b32 	%r2, %r14, 1;
	or.b32  	%r15, %r1, 1;
	setp.ge.s32 	%p1, %r15, %r6;
	or.b32  	%r16, %r2, 1;
	setp.ge.s32 	%p2, %r16, %r5;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	$L__BB12_2;

	mul.wide.s32 	%rd3, %r1, 2;
	and.b64  	%rd4, %rd3, 9223372036854775804;
	mul.lo.s32 	%r17, %r2, %r3;
	cvt.s64.s32 	%rd5, %r17;
	add.s64 	%rd6, %rd4, %rd5;
	cvta.to.global.u64 	%rd7, %rd1;
	add.s64 	%rd8, %rd7, %rd6;
	mul.wide.s32 	%rd9, %r1, 8;
	mul.lo.s32 	%r18, %r2, %r4;
	cvt.s64.s32 	%rd10, %r18;
	add.s64 	%rd11, %rd9, %rd10;
	cvta.to.global.u64 	%rd12, %rd2;
	add.s64 	%rd13, %rd12, %rd11;
	ld.global.v2.u16 	{%rs1, %rs2}, [%rd8];
	cvt.s64.s32 	%rd14, %r3;
	add.s64 	%rd15, %rd8, %rd14;
	ld.global.v2.u16 	{%rs5, %rs6}, [%rd15];
	shr.u32 	%r19, %r2, 31;
	add.s32 	%r20, %r2, %r19;
	shr.s32 	%r21, %r20, 1;
	sub.s32 	%r22, %r5, %r21;
	mul.lo.s32 	%r23, %r22, %r3;
	cvt.s64.s32 	%rd16, %r23;
	add.s64 	%rd17, %rd8, %rd16;
	ld.global.v2.u16 	{%rs9, %rs10}, [%rd17];
	cvt.u32.u16 	%r24, %rs1;
	add.s32 	%r25, %r24, -4096;
	cvt.rn.f32.s32 	%f1, %r25;
	cvt.u32.u16 	%r26, %rs9;
	add.s32 	%r27, %r26, -32768;
	cvt.rn.f32.s32 	%f2, %r27;
	cvt.u32.u16 	%r28, %rs10;
	add.s32 	%r29, %r28, -32768;
	cvt.rn.f32.s32 	%f3, %r29;
	ld.const.f32 	%f4, [matYuv2Rgb];
	ld.const.f32 	%f5, [matYuv2Rgb+4];
	mul.f32 	%f6, %f5, %f2;
	fma.rn.f32 	%f7, %f4, %f1, %f6;
	ld.const.f32 	%f8, [matYuv2Rgb+8];
	fma.rn.f32 	%f9, %f8, %f3, %f7;
	setp.lt.f32 	%p4, %f9, 0f00000000;
	setp.gt.f32 	%p5, %f9, 0f477FFF00;
	selp.f32 	%f10, 0f477FFF00, %f9, %p5;
	selp.f32 	%f11, 0f00000000, %f10, %p4;
	cvt.rzi.u32.f32 	%r30, %f11;
	ld.const.f32 	%f12, [matYuv2Rgb+12];
	ld.const.f32 	%f13, [matYuv2Rgb+16];
	mul.f32 	%f14, %f13, %f2;
	fma.rn.f32 	%f15, %f12, %f1, %f14;
	ld.const.f32 	%f16, [matYuv2Rgb+20];
	fma.rn.f32 	%f17, %f16, %f3, %f15;
	setp.lt.f32 	%p6, %f17, 0f00000000;
	setp.gt.f32 	%p7, %f17, 0f477FFF00;
	selp.f32 	%f18, 0f477FFF00, %f17, %p7;
	selp.f32 	%f19, 0f00000000, %f18, %p6;
	cvt.rzi.u32.f32 	%r31, %f19;
	ld.const.f32 	%f20, [matYuv2Rgb+24];
	ld.const.f32 	%f21, [matYuv2Rgb+28];
	mul.f32 	%f22, %f21, %f2;
	fma.rn.f32 	%f23, %f20, %f1, %f22;
	ld.const.f32 	%f24, [matYuv2Rgb+32];
	fma.rn.f32 	%f25, %f24, %f3, %f23;
	setp.lt.f32 	%p8, %f25, 0f00000000;
	setp.gt.f32 	%p9, %f25, 0f477FFF00;
	selp.f32 	%f26, 0f477FFF00, %f25, %p9;
	selp.f32 	%f27, 0f00000000, %f26, %p8;
	cvt.rzi.u32.f32 	%r32, %f27;
	and.b32  	%r33, %r30, 65535;
	and.b32  	%r34, %r32, 65535;
	cvt.u64.u32 	%rd18, %r34;
	prmt.b32 	%r35, %r31, %r33, 4180;
	cvt.u64.u32 	%rd19, %r35;
	cvt.u32.u16 	%r36, %rs2;
	add.s32 	%r37, %r36, -4096;
	cvt.rn.f32.s32 	%f28, %r37;
	fma.rn.f32 	%f29, %f4, %f28, %f6;
	fma.rn.f32 	%f30, %f8, %f3, %f29;
	setp.lt.f32 	%p10, %f30, 0f00000000;
	setp.gt.f32 	%p11, %f30, 0f477FFF00;
	selp.f32 	%f31, 0f477FFF00, %f30, %p11;
	selp.f32 	%f32, 0f00000000, %f31, %p10;
	cvt.rzi.u32.f32 	%r38, %f32;
	fma.rn.f32 	%f33, %f12, %f28, %f14;
	fma.rn.f32 	%f34, %f16, %f3, %f33;
	setp.lt.f32 	%p12, %f34, 0f00000000;
	setp.gt.f32 	%p13, %f34, 0f477FFF00;
	selp.f32 	%f35, 0f477FFF00, %f34, %p13;
	selp.f32 	%f36, 0f00000000, %f35, %p12;
	cvt.rzi.u32.f32 	%r39, %f36;
	fma.rn.f32 	%f37, %f20, %f28, %f22;
	fma.rn.f32 	%f38, %f24, %f3, %f37;
	setp.lt.f32 	%p14, %f38, 0f00000000;
	setp.gt.f32 	%p15, %f38, 0f477FFF00;
	selp.f32 	%f39, 0f477FFF00, %f38, %p15;
	selp.f32 	%f40, 0f00000000, %f39, %p14;
	cvt.rzi.u32.f32 	%r40, %f40;
	and.b32  	%r41, %r38, 65535;
	and.b32  	%r42, %r40, 65535;
	cvt.u64.u32 	%rd20, %r42;
	prmt.b32 	%r43, %r39, %r41, 4180;
	cvt.u64.u32 	%rd21, %r43;
	bfi.b64 	%rd22, %rd20, %rd21, 32, 32;
	bfi.b64 	%rd23, %rd18, %rd19, 32, 32;
	st.global.v2.u64 	[%rd13], {%rd23, %rd22};
	cvt.s64.s32 	%rd24, %r4;
	add.s64 	%rd25, %rd13, %rd24;
	cvt.u32.u16 	%r44, %rs5;
	add.s32 	%r45, %r44, -4096;
	cvt.rn.f32.s32 	%f41, %r45;
	fma.rn.f32 	%f42, %f4, %f41, %f6;
	fma.rn.f32 	%f43, %f8, %f3, %f42;
	setp.lt.f32 	%p16, %f43, 0f00000000;
	setp.gt.f32 	%p17, %f43, 0f477FFF00;
	selp.f32 	%f44, 0f477FFF00, %f43, %p17;
	selp.f32 	%f45, 0f00000000, %f44, %p16;
	cvt.rzi.u32.f32 	%r46, %f45;
	fma.rn.f32 	%f46, %f12, %f41, %f14;
	fma.rn.f32 	%f47, %f16, %f3, %f46;
	setp.lt.f32 	%p18, %f47, 0f00000000;
	setp.gt.f32 	%p19, %f47, 0f477FFF00;
	selp.f32 	%f48, 0f477FFF00, %f47, %p19;
	selp.f32 	%f49, 0f00000000, %f48, %p18;
	cvt.rzi.u32.f32 	%r47, %f49;
	fma.rn.f32 	%f50, %f20, %f41, %f22;
	fma.rn.f32 	%f51, %f24, %f3, %f50;
	setp.lt.f32 	%p20, %f51, 0f00000000;
	setp.gt.f32 	%p21, %f51, 0f477FFF00;
	selp.f32 	%f52, 0f477FFF00, %f51, %p21;
	selp.f32 	%f53, 0f00000000, %f52, %p20;
	cvt.rzi.u32.f32 	%r48, %f53;
	and.b32  	%r49, %r46, 65535;
	and.b32  	%r50, %r48, 65535;
	cvt.u64.u32 	%rd26, %r50;
	prmt.b32 	%r51, %r47, %r49, 4180;
	cvt.u64.u32 	%rd27, %r51;
	cvt.u32.u16 	%r52, %rs6;
	add.s32 	%r53, %r52, -4096;
	cvt.rn.f32.s32 	%f54, %r53;
	fma.rn.f32 	%f55, %f4, %f54, %f6;
	fma.rn.f32 	%f56, %f8, %f3, %f55;
	setp.lt.f32 	%p22, %f56, 0f00000000;
	setp.gt.f32 	%p23, %f56, 0f477FFF00;
	selp.f32 	%f57, 0f477FFF00, %f56, %p23;
	selp.f32 	%f58, 0f00000000, %f57, %p22;
	cvt.rzi.u32.f32 	%r54, %f58;
	fma.rn.f32 	%f59, %f12, %f54, %f14;
	fma.rn.f32 	%f60, %f16, %f3, %f59;
	setp.lt.f32 	%p24, %f60, 0f00000000;
	setp.gt.f32 	%p25, %f60, 0f477FFF00;
	selp.f32 	%f61, 0f477FFF00, %f60, %p25;
	selp.f32 	%f62, 0f00000000, %f61, %p24;
	cvt.rzi.u32.f32 	%r55, %f62;
	fma.rn.f32 	%f63, %f20, %f54, %f22;
	fma.rn.f32 	%f64, %f24, %f3, %f63;
	setp.lt.f32 	%p26, %f64, 0f00000000;
	setp.gt.f32 	%p27, %f64, 0f477FFF00;
	selp.f32 	%f65, 0f477FFF00, %f64, %p27;
	selp.f32 	%f66, 0f00000000, %f65, %p26;
	cvt.rzi.u32.f32 	%r56, %f66;
	and.b32  	%r57, %r54, 65535;
	and.b32  	%r58, %r56, 65535;
	cvt.u64.u32 	%rd28, %r58;
	prmt.b32 	%r59, %r55, %r57, 4180;
	cvt.u64.u32 	%rd29, %r59;
	bfi.b64 	%rd30, %rd28, %rd29, 32, 32;
	bfi.b64 	%rd31, %rd26, %rd27, 32, 32;
	st.global.v2.u64 	[%rd25], {%rd31, %rd30};

$L__BB12_2:
	ret;

}
.entry _Z17Yuv444ToRgbKernelI7ushort26BGRA325uint2EvPhiS3_iii(
	.param .u64 _Z17Yuv444ToRgbKernelI7ushort26BGRA325uint2EvPhiS3_iii_param_0,
	.param .u32 _Z17Yuv444ToRgbKernelI7ushort26BGRA325uint2EvPhiS3_iii_param_1,
	.param .u64 _Z17Yuv444ToRgbKernelI7ushort26BGRA325uint2EvPhiS3_iii_param_2,
	.param .u32 _Z17Yuv444ToRgbKernelI7ushort26BGRA325uint2EvPhiS3_iii_param_3,
	.param .u32 _Z17Yuv444ToRgbKernelI7ushort26BGRA325uint2EvPhiS3_iii_param_4,
	.param .u32 _Z17Yuv444ToRgbKernelI7ushort26BGRA325uint2EvPhiS3_iii_param_5
)
{
	.reg .pred 	%p<16>;
	.reg .b16 	%rs<13>;
	.reg .f32 	%f<46>;
	.reg .b32 	%r<49>;
	.reg .b64 	%rd<18>;


	ld.param.u64 	%rd1, [_Z17Yuv444ToRgbKernelI7ushort26BGRA325uint2EvPhiS3_iii_param_0];
	ld.param.u32 	%r3, [_Z17Yuv444ToRgbKernelI7ushort26BGRA325uint2EvPhiS3_iii_param_1];
	ld.param.u64 	%rd2, [_Z17Yuv444ToRgbKernelI7ushort26BGRA325uint2EvPhiS3_iii_param_2];
	ld.param.u32 	%r4, [_Z17Yuv444ToRgbKernelI7ushort26BGRA325uint2EvPhiS3_iii_param_3];
	ld.param.u32 	%r6, [_Z17Yuv444ToRgbKernelI7ushort26BGRA325uint2EvPhiS3_iii_param_4];
	ld.param.u32 	%r5, [_Z17Yuv444ToRgbKernelI7ushort26BGRA325uint2EvPhiS3_iii_param_5];
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r8, %ctaid.x;
	mov.u32 	%r9, %tid.x;
	mad.lo.s32 	%r10, %r8, %r7, %r9;
	shl.b32 	%r1, %r10, 1;
	mov.u32 	%r11, %ntid.y;
	mov.u32 	%r12, %ctaid.y;
	mov.u32 	%r13, %tid.y;
	mad.lo.s32 	%r2, %r12, %r11, %r13;
	or.b32  	%r14, %r1, 1;
	setp.ge.s32 	%p1, %r14, %r6;
	setp.ge.s32 	%p2, %r2, %r5;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	$L__BB13_2;

	cvta.to.global.u64 	%rd3, %rd2;
	mul.wide.s32 	%rd4, %r1, 2;
	and.b64  	%rd5, %rd4, 9223372036854775804;
	mul.lo.s32 	%r15, %r2, %r3;
	cvt.s64.s32 	%rd6, %r15;
	add.s64 	%rd7, %rd5, %rd6;
	cvta.to.global.u64 	%rd8, %rd1;
	add.s64 	%rd9, %rd8, %rd7;
	mul.wide.s32 	%rd10, %r1, 4;
	mul.lo.s32 	%r16, %r2, %r4;
	cvt.s64.s32 	%rd11, %r16;
	add.s64 	%rd12, %rd10, %rd11;
	add.s64 	%rd13, %rd3, %rd12;
	ld.global.v2.u16 	{%rs1, %rs2}, [%rd9];
	mul.lo.s32 	%r17, %r5, %r3;
	cvt.s64.s32 	%rd14, %r17;
	add.s64 	%rd15, %rd9, %rd14;
	ld.global.v2.u16 	{%rs5, %rs6}, [%rd15];
	shl.b32 	%r18, %r17, 1;
	cvt.s64.s32 	%rd16, %r18;
	add.s64 	%rd17, %rd9, %rd16;
	ld.global.v2.u16 	{%rs9, %rs10}, [%rd17];
	cvt.u32.u16 	%r19, %rs1;
	add.s32 	%r20, %r19, -4096;
	cvt.rn.f32.s32 	%f1, %r20;
	cvt.u32.u16 	%r21, %rs5;
	add.s32 	%r22, %r21, -32768;
	cvt.rn.f32.s32 	%f2, %r22;
	cvt.u32.u16 	%r23, %rs9;
	add.s32 	%r24, %r23, -32768;
	cvt.rn.f32.s32 	%f3, %r24;
	ld.const.f32 	%f4, [matYuv2Rgb];
	ld.const.f32 	%f5, [matYuv2Rgb+4];
	mul.f32 	%f6, %f5, %f2;
	fma.rn.f32 	%f7, %f4, %f1, %f6;
	ld.const.f32 	%f8, [matYuv2Rgb+8];
	fma.rn.f32 	%f9, %f8, %f3, %f7;
	setp.lt.f32 	%p4, %f9, 0f00000000;
	setp.gt.f32 	%p5, %f9, 0f477FFF00;
	selp.f32 	%f10, 0f477FFF00, %f9, %p5;
	selp.f32 	%f11, 0f00000000, %f10, %p4;
	cvt.rzi.u32.f32 	%r25, %f11;
	ld.const.f32 	%f12, [matYuv2Rgb+12];
	ld.const.f32 	%f13, [matYuv2Rgb+16];
	mul.f32 	%f14, %f13, %f2;
	fma.rn.f32 	%f15, %f12, %f1, %f14;
	ld.const.f32 	%f16, [matYuv2Rgb+20];
	fma.rn.f32 	%f17, %f16, %f3, %f15;
	setp.lt.f32 	%p6, %f17, 0f00000000;
	setp.gt.f32 	%p7, %f17, 0f477FFF00;
	selp.f32 	%f18, 0f477FFF00, %f17, %p7;
	selp.f32 	%f19, 0f00000000, %f18, %p6;
	cvt.rzi.u32.f32 	%r26, %f19;
	ld.const.f32 	%f20, [matYuv2Rgb+24];
	ld.const.f32 	%f21, [matYuv2Rgb+28];
	mul.f32 	%f22, %f21, %f2;
	fma.rn.f32 	%f23, %f20, %f1, %f22;
	ld.const.f32 	%f24, [matYuv2Rgb+32];
	fma.rn.f32 	%f25, %f24, %f3, %f23;
	setp.lt.f32 	%p8, %f25, 0f00000000;
	setp.gt.f32 	%p9, %f25, 0f477FFF00;
	selp.f32 	%f26, 0f477FFF00, %f25, %p9;
	selp.f32 	%f27, 0f00000000, %f26, %p8;
	cvt.rzi.u32.f32 	%r27, %f27;
	and.b32  	%r28, %r26, 65280;
	bfe.u32 	%r29, %r27, 8, 8;
	shl.b32 	%r30, %r25, 8;
	and.b32  	%r31, %r30, 16711680;
	or.b32  	%r32, %r28, %r31;
	cvt.u32.u16 	%r33, %rs2;
	add.s32 	%r34, %r33, -4096;
	cvt.rn.f32.s32 	%f28, %r34;
	cvt.u32.u16 	%r35, %rs6;
	add.s32 	%r36, %r35, -32768;
	cvt.rn.f32.s32 	%f29, %r36;
	cvt.u32.u16 	%r37, %rs10;
	add.s32 	%r38, %r37, -32768;
	cvt.rn.f32.s32 	%f30, %r38;
	mul.f32 	%f31, %f5, %f29;
	fma.rn.f32 	%f32, %f4, %f28, %f31;
	fma.rn.f32 	%f33, %f8, %f30, %f32;
	setp.lt.f32 	%p10, %f33, 0f00000000;
	setp.gt.f32 	%p11, %f33, 0f477FFF00;
	selp.f32 	%f34, 0f477FFF00, %f33, %p11;
	selp.f32 	%f35, 0f00000000, %f34, %p10;
	cvt.rzi.u32.f32 	%r39, %f35;
	mul.f32 	%f36, %f13, %f29;
	fma.rn.f32 	%f37, %f12, %f28, %f36;
	fma.rn.f32 	%f38, %f16, %f30, %f37;
	setp.lt.f32 	%p12, %f38, 0f00000000;
	setp.gt.f32 	%p13, %f38, 0f477FFF00;
	selp.f32 	%f39, 0f477FFF00, %f38, %p13;
	selp.f32 	%f40, 0f00000000, %f39, %p12;
	cvt.rzi.u32.f32 	%r40, %f40;
	mul.f32 	%f41, %f21, %f29;
	fma.rn.f32 	%f42, %f20, %f28, %f41;
	fma.rn.f32 	%f43, %f24, %f30, %f42;
	setp.lt.f32 	%p14, %f43, 0f00000000;
	setp.gt.f32 	%p15, %f43, 0f477FFF00;
	selp.f32 	%f44, 0f477FFF00, %f43, %p15;
	selp.f32 	%f45, 0f00000000, %f44, %p14;
	cvt.rzi.u32.f32 	%r41, %f45;
	and.b32  	%r42, %r40, 65280;
	bfe.u32 	%r43, %r41, 8, 8;
	shl.b32 	%r44, %r39, 8;
	and.b32  	%r45, %r44, 16711680;
	or.b32  	%r46, %r42, %r45;
	or.b32  	%r47, %r46, %r43;
	or.b32  	%r48, %r32, %r29;
	st.global.v2.u32 	[%rd13], {%r48, %r47};

$L__BB13_2:
	ret;

}
.entry _Z17Yuv444ToRgbKernelI7ushort26RGBA325uint2EvPhiS3_iii(
	.param .u64 _Z17Yuv444ToRgbKernelI7ushort26RGBA325uint2EvPhiS3_iii_param_0,
	.param .u32 _Z17Yuv444ToRgbKernelI7ushort26RGBA325uint2EvPhiS3_iii_param_1,
	.param .u64 _Z17Yuv444ToRgbKernelI7ushort26RGBA325uint2EvPhiS3_iii_param_2,
	.param .u32 _Z17Yuv444ToRgbKernelI7ushort26RGBA325uint2EvPhiS3_iii_param_3,
	.param .u32 _Z17Yuv444ToRgbKernelI7ushort26RGBA325uint2EvPhiS3_iii_param_4,
	.param .u32 _Z17Yuv444ToRgbKernelI7ushort26RGBA325uint2EvPhiS3_iii_param_5
)
{
	.reg .pred 	%p<16>;
	.reg .b16 	%rs<13>;
	.reg .f32 	%f<46>;
	.reg .b32 	%r<49>;
	.reg .b64 	%rd<18>;


	ld.param.u64 	%rd1, [_Z17Yuv444ToRgbKernelI7ushort26RGBA325uint2EvPhiS3_iii_param_0];
	ld.param.u32 	%r3, [_Z17Yuv444ToRgbKernelI7ushort26RGBA325uint2EvPhiS3_iii_param_1];
	ld.param.u64 	%rd2, [_Z17Yuv444ToRgbKernelI7ushort26RGBA325uint2EvPhiS3_iii_param_2];
	ld.param.u32 	%r4, [_Z17Yuv444ToRgbKernelI7ushort26RGBA325uint2EvPhiS3_iii_param_3];
	ld.param.u32 	%r6, [_Z17Yuv444ToRgbKernelI7ushort26RGBA325uint2EvPhiS3_iii_param_4];
	ld.param.u32 	%r5, [_Z17Yuv444ToRgbKernelI7ushort26RGBA325uint2EvPhiS3_iii_param_5];
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r8, %ctaid.x;
	mov.u32 	%r9, %tid.x;
	mad.lo.s32 	%r10, %r8, %r7, %r9;
	shl.b32 	%r1, %r10, 1;
	mov.u32 	%r11, %ntid.y;
	mov.u32 	%r12, %ctaid.y;
	mov.u32 	%r13, %tid.y;
	mad.lo.s32 	%r2, %r12, %r11, %r13;
	or.b32  	%r14, %r1, 1;
	setp.ge.s32 	%p1, %r14, %r6;
	setp.ge.s32 	%p2, %r2, %r5;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	$L__BB14_2;

	cvta.to.global.u64 	%rd3, %rd2;
	mul.wide.s32 	%rd4, %r1, 2;
	and.b64  	%rd5, %rd4, 9223372036854775804;
	mul.lo.s32 	%r15, %r2, %r3;
	cvt.s64.s32 	%rd6, %r15;
	add.s64 	%rd7, %rd5, %rd6;
	cvta.to.global.u64 	%rd8, %rd1;
	add.s64 	%rd9, %rd8, %rd7;
	mul.wide.s32 	%rd10, %r1, 4;
	mul.lo.s32 	%r16, %r2, %r4;
	cvt.s64.s32 	%rd11, %r16;
	add.s64 	%rd12, %rd10, %rd11;
	add.s64 	%rd13, %rd3, %rd12;
	ld.global.v2.u16 	{%rs1, %rs2}, [%rd9];
	mul.lo.s32 	%r17, %r5, %r3;
	cvt.s64.s32 	%rd14, %r17;
	add.s64 	%rd15, %rd9, %rd14;
	ld.global.v2.u16 	{%rs5, %rs6}, [%rd15];
	shl.b32 	%r18, %r17, 1;
	cvt.s64.s32 	%rd16, %r18;
	add.s64 	%rd17, %rd9, %rd16;
	ld.global.v2.u16 	{%rs9, %rs10}, [%rd17];
	cvt.u32.u16 	%r19, %rs1;
	add.s32 	%r20, %r19, -4096;
	cvt.rn.f32.s32 	%f1, %r20;
	cvt.u32.u16 	%r21, %rs5;
	add.s32 	%r22, %r21, -32768;
	cvt.rn.f32.s32 	%f2, %r22;
	cvt.u32.u16 	%r23, %rs9;
	add.s32 	%r24, %r23, -32768;
	cvt.rn.f32.s32 	%f3, %r24;
	ld.const.f32 	%f4, [matYuv2Rgb];
	ld.const.f32 	%f5, [matYuv2Rgb+4];
	mul.f32 	%f6, %f5, %f2;
	fma.rn.f32 	%f7, %f4, %f1, %f6;
	ld.const.f32 	%f8, [matYuv2Rgb+8];
	fma.rn.f32 	%f9, %f8, %f3, %f7;
	setp.lt.f32 	%p4, %f9, 0f00000000;
	setp.gt.f32 	%p5, %f9, 0f477FFF00;
	selp.f32 	%f10, 0f477FFF00, %f9, %p5;
	selp.f32 	%f11, 0f00000000, %f10, %p4;
	cvt.rzi.u32.f32 	%r25, %f11;
	ld.const.f32 	%f12, [matYuv2Rgb+12];
	ld.const.f32 	%f13, [matYuv2Rgb+16];
	mul.f32 	%f14, %f13, %f2;
	fma.rn.f32 	%f15, %f12, %f1, %f14;
	ld.const.f32 	%f16, [matYuv2Rgb+20];
	fma.rn.f32 	%f17, %f16, %f3, %f15;
	setp.lt.f32 	%p6, %f17, 0f00000000;
	setp.gt.f32 	%p7, %f17, 0f477FFF00;
	selp.f32 	%f18, 0f477FFF00, %f17, %p7;
	selp.f32 	%f19, 0f00000000, %f18, %p6;
	cvt.rzi.u32.f32 	%r26, %f19;
	ld.const.f32 	%f20, [matYuv2Rgb+24];
	ld.const.f32 	%f21, [matYuv2Rgb+28];
	mul.f32 	%f22, %f21, %f2;
	fma.rn.f32 	%f23, %f20, %f1, %f22;
	ld.const.f32 	%f24, [matYuv2Rgb+32];
	fma.rn.f32 	%f25, %f24, %f3, %f23;
	setp.lt.f32 	%p8, %f25, 0f00000000;
	setp.gt.f32 	%p9, %f25, 0f477FFF00;
	selp.f32 	%f26, 0f477FFF00, %f25, %p9;
	selp.f32 	%f27, 0f00000000, %f26, %p8;
	cvt.rzi.u32.f32 	%r27, %f27;
	bfe.u32 	%r28, %r25, 8, 8;
	and.b32  	%r29, %r26, 65280;
	shl.b32 	%r30, %r27, 8;
	and.b32  	%r31, %r30, 16711680;
	or.b32  	%r32, %r29, %r28;
	cvt.u32.u16 	%r33, %rs2;
	add.s32 	%r34, %r33, -4096;
	cvt.rn.f32.s32 	%f28, %r34;
	cvt.u32.u16 	%r35, %rs6;
	add.s32 	%r36, %r35, -32768;
	cvt.rn.f32.s32 	%f29, %r36;
	cvt.u32.u16 	%r37, %rs10;
	add.s32 	%r38, %r37, -32768;
	cvt.rn.f32.s32 	%f30, %r38;
	mul.f32 	%f31, %f5, %f29;
	fma.rn.f32 	%f32, %f4, %f28, %f31;
	fma.rn.f32 	%f33, %f8, %f30, %f32;
	setp.lt.f32 	%p10, %f33, 0f00000000;
	setp.gt.f32 	%p11, %f33, 0f477FFF00;
	selp.f32 	%f34, 0f477FFF00, %f33, %p11;
	selp.f32 	%f35, 0f00000000, %f34, %p10;
	cvt.rzi.u32.f32 	%r39, %f35;
	mul.f32 	%f36, %f13, %f29;
	fma.rn.f32 	%f37, %f12, %f28, %f36;
	fma.rn.f32 	%f38, %f16, %f30, %f37;
	setp.lt.f32 	%p12, %f38, 0f00000000;
	setp.gt.f32 	%p13, %f38, 0f477FFF00;
	selp.f32 	%f39, 0f477FFF00, %f38, %p13;
	selp.f32 	%f40, 0f00000000, %f39, %p12;
	cvt.rzi.u32.f32 	%r40, %f40;
	mul.f32 	%f41, %f21, %f29;
	fma.rn.f32 	%f42, %f20, %f28, %f41;
	fma.rn.f32 	%f43, %f24, %f30, %f42;
	setp.lt.f32 	%p14, %f43, 0f00000000;
	setp.gt.f32 	%p15, %f43, 0f477FFF00;
	selp.f32 	%f44, 0f477FFF00, %f43, %p15;
	selp.f32 	%f45, 0f00000000, %f44, %p14;
	cvt.rzi.u32.f32 	%r41, %f45;
	bfe.u32 	%r42, %r39, 8, 8;
	and.b32  	%r43, %r40, 65280;
	shl.b32 	%r44, %r41, 8;
	and.b32  	%r45, %r44, 16711680;
	or.b32  	%r46, %r43, %r42;
	or.b32  	%r47, %r46, %r45;
	or.b32  	%r48, %r32, %r31;
	st.global.v2.u32 	[%rd13], {%r48, %r47};

$L__BB14_2:
	ret;

}
.entry _Z17Yuv444ToRgbKernelI7ushort26BGRA6410ulonglong2EvPhiS3_iii(
	.param .u64 _Z17Yuv444ToRgbKernelI7ushort26BGRA6410ulonglong2EvPhiS3_iii_param_0,
	.param .u32 _Z17Yuv444ToRgbKernelI7ushort26BGRA6410ulonglong2EvPhiS3_iii_param_1,
	.param .u64 _Z17Yuv444ToRgbKernelI7ushort26BGRA6410ulonglong2EvPhiS3_iii_param_2,
	.param .u32 _Z17Yuv444ToRgbKernelI7ushort26BGRA6410ulonglong2EvPhiS3_iii_param_3,
	.param .u32 _Z17Yuv444ToRgbKernelI7ushort26BGRA6410ulonglong2EvPhiS3_iii_param_4,
	.param .u32 _Z17Yuv444ToRgbKernelI7ushort26BGRA6410ulonglong2EvPhiS3_iii_param_5
)
{
	.reg .pred 	%p<16>;
	.reg .b16 	%rs<13>;
	.reg .f32 	%f<46>;
	.reg .b32 	%r<43>;
	.reg .b64 	%rd<28>;


	ld.param.u64 	%rd1, [_Z17Yuv444ToRgbKernelI7ushort26BGRA6410ulonglong2EvPhiS3_iii_param_0];
	ld.param.u32 	%r3, [_Z17Yuv444ToRgbKernelI7ushort26BGRA6410ulonglong2EvPhiS3_iii_param_1];
	ld.param.u64 	%rd2, [_Z17Yuv444ToRgbKernelI7ushort26BGRA6410ulonglong2EvPhiS3_iii_param_2];
	ld.param.u32 	%r4, [_Z17Yuv444ToRgbKernelI7ushort26BGRA6410ulonglong2EvPhiS3_iii_param_3];
	ld.param.u32 	%r6, [_Z17Yuv444ToRgbKernelI7ushort26BGRA6410ulonglong2EvPhiS3_iii_param_4];
	ld.param.u32 	%r5, [_Z17Yuv444ToRgbKernelI7ushort26BGRA6410ulonglong2EvPhiS3_iii_param_5];
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r8, %ctaid.x;
	mov.u32 	%r9, %tid.x;
	mad.lo.s32 	%r10, %r8, %r7, %r9;
	shl.b32 	%r1, %r10, 1;
	mov.u32 	%r11, %ntid.y;
	mov.u32 	%r12, %ctaid.y;
	mov.u32 	%r13, %tid.y;
	mad.lo.s32 	%r2, %r12, %r11, %r13;
	or.b32  	%r14, %r1, 1;
	setp.ge.s32 	%p1, %r14, %r6;
	setp.ge.s32 	%p2, %r2, %r5;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	$L__BB15_2;

	cvta.to.global.u64 	%rd3, %rd2;
	mul.wide.s32 	%rd4, %r1, 2;
	and.b64  	%rd5, %rd4, 9223372036854775804;
	mul.lo.s32 	%r15, %r2, %r3;
	cvt.s64.s32 	%rd6, %r15;
	add.s64 	%rd7, %rd5, %rd6;
	cvta.to.global.u64 	%rd8, %rd1;
	add.s64 	%rd9, %rd8, %rd7;
	mul.wide.s32 	%rd10, %r1, 8;
	mul.lo.s32 	%r16, %r2, %r4;
	cvt.s64.s32 	%rd11, %r16;
	add.s64 	%rd12, %rd10, %rd11;
	add.s64 	%rd13, %rd3, %rd12;
	ld.global.v2.u16 	{%rs1, %rs2}, [%rd9];
	mul.lo.s32 	%r17, %r5, %r3;
	cvt.s64.s32 	%rd14, %r17;
	add.s64 	%rd15, %rd9, %rd14;
	ld.global.v2.u16 	{%rs5, %rs6}, [%rd15];
	shl.b32 	%r18, %r17, 1;
	cvt.s64.s32 	%rd16, %r18;
	add.s64 	%rd17, %rd9, %rd16;
	ld.global.v2.u16 	{%rs9, %rs10}, [%rd17];
	cvt.u32.u16 	%r19, %rs1;
	add.s32 	%r20, %r19, -4096;
	cvt.rn.f32.s32 	%f1, %r20;
	cvt.u32.u16 	%r21, %rs5;
	add.s32 	%r22, %r21, -32768;
	cvt.rn.f32.s32 	%f2, %r22;
	cvt.u32.u16 	%r23, %rs9;
	add.s32 	%r24, %r23, -32768;
	cvt.rn.f32.s32 	%f3, %r24;
	ld.const.f32 	%f4, [matYuv2Rgb];
	ld.const.f32 	%f5, [matYuv2Rgb+4];
	mul.f32 	%f6, %f5, %f2;
	fma.rn.f32 	%f7, %f4, %f1, %f6;
	ld.const.f32 	%f8, [matYuv2Rgb+8];
	fma.rn.f32 	%f9, %f8, %f3, %f7;
	setp.lt.f32 	%p4, %f9, 0f00000000;
	setp.gt.f32 	%p5, %f9, 0f477FFF00;
	selp.f32 	%f10, 0f477FFF00, %f9, %p5;
	selp.f32 	%f11, 0f00000000, %f10, %p4;
	cvt.rzi.u32.f32 	%r25, %f11;
	ld.const.f32 	%f12, [matYuv2Rgb+12];
	ld.const.f32 	%f13, [matYuv2Rgb+16];
	mul.f32 	%f14, %f13, %f2;
	fma.rn.f32 	%f15, %f12, %f1, %f14;
	ld.const.f32 	%f16, [matYuv2Rgb+20];
	fma.rn.f32 	%f17, %f16, %f3, %f15;
	setp.lt.f32 	%p6, %f17, 0f00000000;
	setp.gt.f32 	%p7, %f17, 0f477FFF00;
	selp.f32 	%f18, 0f477FFF00, %f17, %p7;
	selp.f32 	%f19, 0f00000000, %f18, %p6;
	cvt.rzi.u32.f32 	%r26, %f19;
	ld.const.f32 	%f20, [matYuv2Rgb+24];
	ld.const.f32 	%f21, [matYuv2Rgb+28];
	mul.f32 	%f22, %f21, %f2;
	fma.rn.f32 	%f23, %f20, %f1, %f22;
	ld.const.f32 	%f24, [matYuv2Rgb+32];
	fma.rn.f32 	%f25, %f24, %f3, %f23;
	setp.lt.f32 	%p8, %f25, 0f00000000;
	setp.gt.f32 	%p9, %f25, 0f477FFF00;
	selp.f32 	%f26, 0f477FFF00, %f25, %p9;
	selp.f32 	%f27, 0f00000000, %f26, %p8;
	cvt.rzi.u32.f32 	%r27, %f27;
	and.b32  	%r28, %r25, 65535;
	and.b32  	%r29, %r27, 65535;
	cvt.u64.u32 	%rd18, %r28;
	shl.b32 	%r30, %r26, 16;
	cvt.u64.u32 	%rd19, %r30;
	bfi.b64 	%rd20, %rd18, %rd19, 32, 32;
	cvt.u64.u32 	%rd21, %r29;
	cvt.u32.u16 	%r31, %rs2;
	add.s32 	%r32, %r31, -4096;
	cvt.rn.f32.s32 	%f28, %r32;
	cvt.u32.u16 	%r33, %rs6;
	add.s32 	%r34, %r33, -32768;
	cvt.rn.f32.s32 	%f29, %r34;
	cvt.u32.u16 	%r35, %rs10;
	add.s32 	%r36, %r35, -32768;
	cvt.rn.f32.s32 	%f30, %r36;
	mul.f32 	%f31, %f5, %f29;
	fma.rn.f32 	%f32, %f4, %f28, %f31;
	fma.rn.f32 	%f33, %f8, %f30, %f32;
	setp.lt.f32 	%p10, %f33, 0f00000000;
	setp.gt.f32 	%p11, %f33, 0f477FFF00;
	selp.f32 	%f34, 0f477FFF00, %f33, %p11;
	selp.f32 	%f35, 0f00000000, %f34, %p10;
	cvt.rzi.u32.f32 	%r37, %f35;
	mul.f32 	%f36, %f13, %f29;
	fma.rn.f32 	%f37, %f12, %f28, %f36;
	fma.rn.f32 	%f38, %f16, %f30, %f37;
	setp.lt.f32 	%p12, %f38, 0f00000000;
	setp.gt.f32 	%p13, %f38, 0f477FFF00;
	selp.f32 	%f39, 0f477FFF00, %f38, %p13;
	selp.f32 	%f40, 0f00000000, %f39, %p12;
	cvt.rzi.u32.f32 	%r38, %f40;
	mul.f32 	%f41, %f21, %f29;
	fma.rn.f32 	%f42, %f20, %f28, %f41;
	fma.rn.f32 	%f43, %f24, %f30, %f42;
	setp.lt.f32 	%p14, %f43, 0f00000000;
	setp.gt.f32 	%p15, %f43, 0f477FFF00;
	selp.f32 	%f44, 0f477FFF00, %f43, %p15;
	selp.f32 	%f45, 0f00000000, %f44, %p14;
	cvt.rzi.u32.f32 	%r39, %f45;
	and.b32  	%r40, %r37, 65535;
	and.b32  	%r41, %r39, 65535;
	cvt.u64.u32 	%rd22, %r40;
	shl.b32 	%r42, %r38, 16;
	cvt.u64.u32 	%rd23, %r42;
	bfi.b64 	%rd24, %rd22, %rd23, 32, 32;
	cvt.u64.u32 	%rd25, %r41;
	or.b64  	%rd26, %rd24, %rd25;
	or.b64  	%rd27, %rd20, %rd21;
	st.global.v2.u64 	[%rd13], {%rd27, %rd26};

$L__BB15_2:
	ret;

}
.entry _Z17Yuv444ToRgbKernelI7ushort26RGBA6410ulonglong2EvPhiS3_iii(
	.param .u64 _Z17Yuv444ToRgbKernelI7ushort26RGBA6410ulonglong2EvPhiS3_iii_param_0,
	.param .u32 _Z17Yuv444ToRgbKernelI7ushort26RGBA6410ulonglong2EvPhiS3_iii_param_1,
	.param .u64 _Z17Yuv444ToRgbKernelI7ushort26RGBA6410ulonglong2EvPhiS3_iii_param_2,
	.param .u32 _Z17Yuv444ToRgbKernelI7ushort26RGBA6410ulonglong2EvPhiS3_iii_param_3,
	.param .u32 _Z17Yuv444ToRgbKernelI7ushort26RGBA6410ulonglong2EvPhiS3_iii_param_4,
	.param .u32 _Z17Yuv444ToRgbKernelI7ushort26RGBA6410ulonglong2EvPhiS3_iii_param_5
)
{
	.reg .pred 	%p<16>;
	.reg .b16 	%rs<13>;
	.reg .f32 	%f<46>;
	.reg .b32 	%r<43>;
	.reg .b64 	%rd<24>;


	ld.param.u64 	%rd1, [_Z17Yuv444ToRgbKernelI7ushort26RGBA6410ulonglong2EvPhiS3_iii_param_0];
	ld.param.u32 	%r3, [_Z17Yuv444ToRgbKernelI7ushort26RGBA6410ulonglong2EvPhiS3_iii_param_1];
	ld.param.u64 	%rd2, [_Z17Yuv444ToRgbKernelI7ushort26RGBA6410ulonglong2EvPhiS3_iii_param_2];
	ld.param.u32 	%r4, [_Z17Yuv444ToRgbKernelI7ushort26RGBA6410ulonglong2EvPhiS3_iii_param_3];
	ld.param.u32 	%r6, [_Z17Yuv444ToRgbKernelI7ushort26RGBA6410ulonglong2EvPhiS3_iii_param_4];
	ld.param.u32 	%r5, [_Z17Yuv444ToRgbKernelI7ushort26RGBA6410ulonglong2EvPhiS3_iii_param_5];
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r8, %ctaid.x;
	mov.u32 	%r9, %tid.x;
	mad.lo.s32 	%r10, %r8, %r7, %r9;
	shl.b32 	%r1, %r10, 1;
	mov.u32 	%r11, %ntid.y;
	mov.u32 	%r12, %ctaid.y;
	mov.u32 	%r13, %tid.y;
	mad.lo.s32 	%r2, %r12, %r11, %r13;
	or.b32  	%r14, %r1, 1;
	setp.ge.s32 	%p1, %r14, %r6;
	setp.ge.s32 	%p2, %r2, %r5;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	$L__BB16_2;

	cvta.to.global.u64 	%rd3, %rd2;
	mul.wide.s32 	%rd4, %r1, 2;
	and.b64  	%rd5, %rd4, 9223372036854775804;
	mul.lo.s32 	%r15, %r2, %r3;
	cvt.s64.s32 	%rd6, %r15;
	add.s64 	%rd7, %rd5, %rd6;
	cvta.to.global.u64 	%rd8, %rd1;
	add.s64 	%rd9, %rd8, %rd7;
	mul.wide.s32 	%rd10, %r1, 8;
	mul.lo.s32 	%r16, %r2, %r4;
	cvt.s64.s32 	%rd11, %r16;
	add.s64 	%rd12, %rd10, %rd11;
	add.s64 	%rd13, %rd3, %rd12;
	ld.global.v2.u16 	{%rs1, %rs2}, [%rd9];
	mul.lo.s32 	%r17, %r5, %r3;
	cvt.s64.s32 	%rd14, %r17;
	add.s64 	%rd15, %rd9, %rd14;
	ld.global.v2.u16 	{%rs5, %rs6}, [%rd15];
	shl.b32 	%r18, %r17, 1;
	cvt.s64.s32 	%rd16, %r18;
	add.s64 	%rd17, %rd9, %rd16;
	ld.global.v2.u16 	{%rs9, %rs10}, [%rd17];
	cvt.u32.u16 	%r19, %rs1;
	add.s32 	%r20, %r19, -4096;
	cvt.rn.f32.s32 	%f1, %r20;
	cvt.u32.u16 	%r21, %rs5;
	add.s32 	%r22, %r21, -32768;
	cvt.rn.f32.s32 	%f2, %r22;
	cvt.u32.u16 	%r23, %rs9;
	add.s32 	%r24, %r23, -32768;
	cvt.rn.f32.s32 	%f3, %r24;
	ld.const.f32 	%f4, [matYuv2Rgb];
	ld.const.f32 	%f5, [matYuv2Rgb+4];
	mul.f32 	%f6, %f5, %f2;
	fma.rn.f32 	%f7, %f4, %f1, %f6;
	ld.const.f32 	%f8, [matYuv2Rgb+8];
	fma.rn.f32 	%f9, %f8, %f3, %f7;
	setp.lt.f32 	%p4, %f9, 0f00000000;
	setp.gt.f32 	%p5, %f9, 0f477FFF00;
	selp.f32 	%f10, 0f477FFF00, %f9, %p5;
	selp.f32 	%f11, 0f00000000, %f10, %p4;
	cvt.rzi.u32.f32 	%r25, %f11;
	ld.const.f32 	%f12, [matYuv2Rgb+12];
	ld.const.f32 	%f13, [matYuv2Rgb+16];
	mul.f32 	%f14, %f13, %f2;
	fma.rn.f32 	%f15, %f12, %f1, %f14;
	ld.const.f32 	%f16, [matYuv2Rgb+20];
	fma.rn.f32 	%f17, %f16, %f3, %f15;
	setp.lt.f32 	%p6, %f17, 0f00000000;
	setp.gt.f32 	%p7, %f17, 0f477FFF00;
	selp.f32 	%f18, 0f477FFF00, %f17, %p7;
	selp.f32 	%f19, 0f00000000, %f18, %p6;
	cvt.rzi.u32.f32 	%r26, %f19;
	ld.const.f32 	%f20, [matYuv2Rgb+24];
	ld.const.f32 	%f21, [matYuv2Rgb+28];
	mul.f32 	%f22, %f21, %f2;
	fma.rn.f32 	%f23, %f20, %f1, %f22;
	ld.const.f32 	%f24, [matYuv2Rgb+32];
	fma.rn.f32 	%f25, %f24, %f3, %f23;
	setp.lt.f32 	%p8, %f25, 0f00000000;
	setp.gt.f32 	%p9, %f25, 0f477FFF00;
	selp.f32 	%f26, 0f477FFF00, %f25, %p9;
	selp.f32 	%f27, 0f00000000, %f26, %p8;
	cvt.rzi.u32.f32 	%r27, %f27;
	and.b32  	%r28, %r25, 65535;
	and.b32  	%r29, %r27, 65535;
	cvt.u64.u32 	%rd18, %r29;
	prmt.b32 	%r30, %r26, %r28, 4180;
	cvt.u64.u32 	%rd19, %r30;
	cvt.u32.u16 	%r31, %rs2;
	add.s32 	%r32, %r31, -4096;
	cvt.rn.f32.s32 	%f28, %r32;
	cvt.u32.u16 	%r33, %rs6;
	add.s32 	%r34, %r33, -32768;
	cvt.rn.f32.s32 	%f29, %r34;
	cvt.u32.u16 	%r35, %rs10;
	add.s32 	%r36, %r35, -32768;
	cvt.rn.f32.s32 	%f30, %r36;
	mul.f32 	%f31, %f5, %f29;
	fma.rn.f32 	%f32, %f4, %f28, %f31;
	fma.rn.f32 	%f33, %f8, %f30, %f32;
	setp.lt.f32 	%p10, %f33, 0f00000000;
	setp.gt.f32 	%p11, %f33, 0f477FFF00;
	selp.f32 	%f34, 0f477FFF00, %f33, %p11;
	selp.f32 	%f35, 0f00000000, %f34, %p10;
	cvt.rzi.u32.f32 	%r37, %f35;
	mul.f32 	%f36, %f13, %f29;
	fma.rn.f32 	%f37, %f12, %f28, %f36;
	fma.rn.f32 	%f38, %f16, %f30, %f37;
	setp.lt.f32 	%p12, %f38, 0f00000000;
	setp.gt.f32 	%p13, %f38, 0f477FFF00;
	selp.f32 	%f39, 0f477FFF00, %f38, %p13;
	selp.f32 	%f40, 0f00000000, %f39, %p12;
	cvt.rzi.u32.f32 	%r38, %f40;
	mul.f32 	%f41, %f21, %f29;
	fma.rn.f32 	%f42, %f20, %f28, %f41;
	fma.rn.f32 	%f43, %f24, %f30, %f42;
	setp.lt.f32 	%p14, %f43, 0f00000000;
	setp.gt.f32 	%p15, %f43, 0f477FFF00;
	selp.f32 	%f44, 0f477FFF00, %f43, %p15;
	selp.f32 	%f45, 0f00000000, %f44, %p14;
	cvt.rzi.u32.f32 	%r39, %f45;
	and.b32  	%r40, %r37, 65535;
	and.b32  	%r41, %r39, 65535;
	cvt.u64.u32 	%rd20, %r41;
	prmt.b32 	%r42, %r38, %r40, 4180;
	cvt.u64.u32 	%rd21, %r42;
	bfi.b64 	%rd22, %rd20, %rd21, 32, 32;
	bfi.b64 	%rd23, %rd18, %rd19, 32, 32;
	st.global.v2.u64 	[%rd13], {%rd23, %rd22};

$L__BB16_2:
	ret;

}
.entry _Z20YuvToRgbPlanarKernelI6uchar26BGRA32S0_EvPhiS2_iii(
	.param .u64 _Z20YuvToRgbPlanarKernelI6uchar26BGRA32S0_EvPhiS2_iii_param_0,
	.param .u32 _Z20YuvToRgbPlanarKernelI6uchar26BGRA32S0_EvPhiS2_iii_param_1,
	.param .u64 _Z20YuvToRgbPlanarKernelI6uchar26BGRA32S0_EvPhiS2_iii_param_2,
	.param .u32 _Z20YuvToRgbPlanarKernelI6uchar26BGRA32S0_EvPhiS2_iii_param_3,
	.param .u32 _Z20YuvToRgbPlanarKernelI6uchar26BGRA32S0_EvPhiS2_iii_param_4,
	.param .u32 _Z20YuvToRgbPlanarKernelI6uchar26BGRA32S0_EvPhiS2_iii_param_5
)
{
	.reg .pred 	%p<28>;
	.reg .b16 	%rs<19>;
	.reg .f32 	%f<67>;
	.reg .b32 	%r<49>;
	.reg .b64 	%rd<24>;


	ld.param.u64 	%rd1, [_Z20YuvToRgbPlanarKernelI6uchar26BGRA32S0_EvPhiS2_iii_param_0];
	ld.param.u32 	%r3, [_Z20YuvToRgbPlanarKernelI6uchar26BGRA32S0_EvPhiS2_iii_param_1];
	ld.param.u64 	%rd2, [_Z20YuvToRgbPlanarKernelI6uchar26BGRA32S0_EvPhiS2_iii_param_2];
	ld.param.u32 	%r4, [_Z20YuvToRgbPlanarKernelI6uchar26BGRA32S0_EvPhiS2_iii_param_3];
	ld.param.u32 	%r6, [_Z20YuvToRgbPlanarKernelI6uchar26BGRA32S0_EvPhiS2_iii_param_4];
	ld.param.u32 	%r5, [_Z20YuvToRgbPlanarKernelI6uchar26BGRA32S0_EvPhiS2_iii_param_5];
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r8, %ctaid.x;
	mov.u32 	%r9, %tid.x;
	mad.lo.s32 	%r10, %r8, %r7, %r9;
	shl.b32 	%r1, %r10, 1;
	mov.u32 	%r11, %ntid.y;
	mov.u32 	%r12, %ctaid.y;
	mov.u32 	%r13, %tid.y;
	mad.lo.s32 	%r14, %r12, %r11, %r13;
	shl.b32 	%r2, %r14, 1;
	or.b32  	%r15, %r1, 1;
	setp.ge.s32 	%p1, %r15, %r6;
	or.b32  	%r16, %r2, 1;
	setp.ge.s32 	%p2, %r16, %r5;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	$L__BB17_2;

	cvt.s64.s32 	%rd3, %r1;
	and.b64  	%rd4, %rd3, 9223372036854775806;
	mul.lo.s32 	%r17, %r2, %r3;
	cvt.s64.s32 	%rd5, %r17;
	add.s64 	%rd6, %rd4, %rd5;
	cvta.to.global.u64 	%rd7, %rd1;
	add.s64 	%rd8, %rd7, %rd6;
	ld.global.v2.u8 	{%rs1, %rs2}, [%rd8];
	cvt.s64.s32 	%rd9, %r3;
	add.s64 	%rd10, %rd8, %rd9;
	ld.global.v2.u8 	{%rs3, %rs4}, [%rd10];
	shr.u32 	%r18, %r2, 31;
	add.s32 	%r19, %r2, %r18;
	shr.s32 	%r20, %r19, 1;
	sub.s32 	%r21, %r5, %r20;
	mul.lo.s32 	%r22, %r21, %r3;
	cvt.s64.s32 	%rd11, %r22;
	add.s64 	%rd12, %rd8, %rd11;
	ld.global.v2.u8 	{%rs5, %rs6}, [%rd12];
	cvt.u32.u16 	%r23, %rs1;
	add.s32 	%r24, %r23, -16;
	cvt.rn.f32.s32 	%f1, %r24;
	cvt.u32.u16 	%r25, %rs5;
	add.s32 	%r26, %r25, -128;
	cvt.rn.f32.s32 	%f2, %r26;
	cvt.u32.u16 	%r27, %rs6;
	add.s32 	%r28, %r27, -128;
	cvt.rn.f32.s32 	%f3, %r28;
	ld.const.f32 	%f4, [matYuv2Rgb];
	ld.const.f32 	%f5, [matYuv2Rgb+4];
	mul.f32 	%f6, %f5, %f2;
	fma.rn.f32 	%f7, %f4, %f1, %f6;
	ld.const.f32 	%f8, [matYuv2Rgb+8];
	fma.rn.f32 	%f9, %f8, %f3, %f7;
	setp.lt.f32 	%p4, %f9, 0f00000000;
	setp.gt.f32 	%p5, %f9, 0f437F0000;
	selp.f32 	%f10, 0f437F0000, %f9, %p5;
	selp.f32 	%f11, 0f00000000, %f10, %p4;
	cvt.rzi.u32.f32 	%r29, %f11;
	ld.const.f32 	%f12, [matYuv2Rgb+12];
	ld.const.f32 	%f13, [matYuv2Rgb+16];
	mul.f32 	%f14, %f13, %f2;
	fma.rn.f32 	%f15, %f12, %f1, %f14;
	ld.const.f32 	%f16, [matYuv2Rgb+20];
	fma.rn.f32 	%f17, %f16, %f3, %f15;
	setp.lt.f32 	%p6, %f17, 0f00000000;
	setp.gt.f32 	%p7, %f17, 0f437F0000;
	selp.f32 	%f18, 0f437F0000, %f17, %p7;
	selp.f32 	%f19, 0f00000000, %f18, %p6;
	cvt.rzi.u32.f32 	%r30, %f19;
	ld.const.f32 	%f20, [matYuv2Rgb+24];
	ld.const.f32 	%f21, [matYuv2Rgb+28];
	mul.f32 	%f22, %f21, %f2;
	fma.rn.f32 	%f23, %f20, %f1, %f22;
	ld.const.f32 	%f24, [matYuv2Rgb+32];
	fma.rn.f32 	%f25, %f24, %f3, %f23;
	setp.lt.f32 	%p8, %f25, 0f00000000;
	setp.gt.f32 	%p9, %f25, 0f437F0000;
	selp.f32 	%f26, 0f437F0000, %f25, %p9;
	selp.f32 	%f27, 0f00000000, %f26, %p8;
	cvt.rzi.u32.f32 	%r31, %f27;
	cvt.u32.u16 	%r32, %rs2;
	add.s32 	%r33, %r32, -16;
	cvt.rn.f32.s32 	%f28, %r33;
	fma.rn.f32 	%f29, %f4, %f28, %f6;
	fma.rn.f32 	%f30, %f8, %f3, %f29;
	setp.lt.f32 	%p10, %f30, 0f00000000;
	setp.gt.f32 	%p11, %f30, 0f437F0000;
	selp.f32 	%f31, 0f437F0000, %f30, %p11;
	selp.f32 	%f32, 0f00000000, %f31, %p10;
	cvt.rzi.u32.f32 	%r34, %f32;
	fma.rn.f32 	%f33, %f12, %f28, %f14;
	fma.rn.f32 	%f34, %f16, %f3, %f33;
	setp.lt.f32 	%p12, %f34, 0f00000000;
	setp.gt.f32 	%p13, %f34, 0f437F0000;
	selp.f32 	%f35, 0f437F0000, %f34, %p13;
	selp.f32 	%f36, 0f00000000, %f35, %p12;
	cvt.rzi.u32.f32 	%r35, %f36;
	fma.rn.f32 	%f37, %f20, %f28, %f22;
	fma.rn.f32 	%f38, %f24, %f3, %f37;
	setp.lt.f32 	%p14, %f38, 0f00000000;
	setp.gt.f32 	%p15, %f38, 0f437F0000;
	selp.f32 	%f39, 0f437F0000, %f38, %p15;
	selp.f32 	%f40, 0f00000000, %f39, %p14;
	cvt.rzi.u32.f32 	%r36, %f40;
	cvt.u32.u16 	%r37, %rs3;
	add.s32 	%r38, %r37, -16;
	cvt.rn.f32.s32 	%f41, %r38;
	fma.rn.f32 	%f42, %f4, %f41, %f6;
	fma.rn.f32 	%f43, %f8, %f3, %f42;
	setp.lt.f32 	%p16, %f43, 0f00000000;
	setp.gt.f32 	%p17, %f43, 0f437F0000;
	selp.f32 	%f44, 0f437F0000, %f43, %p17;
	selp.f32 	%f45, 0f00000000, %f44, %p16;
	cvt.rzi.u32.f32 	%r39, %f45;
	fma.rn.f32 	%f46, %f12, %f41, %f14;
	fma.rn.f32 	%f47, %f16, %f3, %f46;
	setp.lt.f32 	%p18, %f47, 0f00000000;
	setp.gt.f32 	%p19, %f47, 0f437F0000;
	selp.f32 	%f48, 0f437F0000, %f47, %p19;
	selp.f32 	%f49, 0f00000000, %f48, %p18;
	cvt.rzi.u32.f32 	%r40, %f49;
	fma.rn.f32 	%f50, %f20, %f41, %f22;
	fma.rn.f32 	%f51, %f24, %f3, %f50;
	setp.lt.f32 	%p20, %f51, 0f00000000;
	setp.gt.f32 	%p21, %f51, 0f437F0000;
	selp.f32 	%f52, 0f437F0000, %f51, %p21;
	selp.f32 	%f53, 0f00000000, %f52, %p20;
	cvt.rzi.u32.f32 	%r41, %f53;
	cvt.u32.u16 	%r42, %rs4;
	add.s32 	%r43, %r42, -16;
	cvt.rn.f32.s32 	%f54, %r43;
	fma.rn.f32 	%f55, %f4, %f54, %f6;
	fma.rn.f32 	%f56, %f8, %f3, %f55;
	setp.lt.f32 	%p22, %f56, 0f00000000;
	setp.gt.f32 	%p23, %f56, 0f437F0000;
	selp.f32 	%f57, 0f437F0000, %f56, %p23;
	selp.f32 	%f58, 0f00000000, %f57, %p22;
	cvt.rzi.u32.f32 	%r44, %f58;
	fma.rn.f32 	%f59, %f12, %f54, %f14;
	fma.rn.f32 	%f60, %f16, %f3, %f59;
	setp.lt.f32 	%p24, %f60, 0f00000000;
	setp.gt.f32 	%p25, %f60, 0f437F0000;
	selp.f32 	%f61, 0f437F0000, %f60, %p25;
	selp.f32 	%f62, 0f00000000, %f61, %p24;
	cvt.rzi.u32.f32 	%r45, %f62;
	fma.rn.f32 	%f63, %f20, %f54, %f22;
	fma.rn.f32 	%f64, %f24, %f3, %f63;
	setp.lt.f32 	%p26, %f64, 0f00000000;
	setp.gt.f32 	%p27, %f64, 0f437F0000;
	selp.f32 	%f65, 0f437F0000, %f64, %p27;
	selp.f32 	%f66, 0f00000000, %f65, %p26;
	cvt.rzi.u32.f32 	%r46, %f66;
	mul.lo.s32 	%r47, %r2, %r4;
	cvt.s64.s32 	%rd13, %r47;
	add.s64 	%rd14, %rd4, %rd13;
	cvta.to.global.u64 	%rd15, %rd2;
	add.s64 	%rd16, %rd15, %rd14;
	cvt.u16.u32 	%rs7, %r36;
	cvt.u16.u32 	%rs8, %r31;
	st.global.v2.u8 	[%rd16], {%rs8, %rs7};
	cvt.s64.s32 	%rd17, %r4;
	add.s64 	%rd18, %rd16, %rd17;
	cvt.u16.u32 	%rs9, %r46;
	cvt.u16.u32 	%rs10, %r41;
	st.global.v2.u8 	[%rd18], {%rs10, %rs9};
	mul.lo.s32 	%r48, %r5, %r4;
	cvt.s64.s32 	%rd19, %r48;
	add.s64 	%rd20, %rd16, %rd19;
	cvt.u16.u32 	%rs11, %r35;
	cvt.u16.u32 	%rs12, %r30;
	st.global.v2.u8 	[%rd20], {%rs12, %rs11};
	add.s64 	%rd21, %rd18, %rd19;
	cvt.u16.u32 	%rs13, %r45;
	cvt.u16.u32 	%rs14, %r40;
	st.global.v2.u8 	[%rd21], {%rs14, %rs13};
	add.s64 	%rd22, %rd20, %rd19;
	cvt.u16.u32 	%rs15, %r34;
	cvt.u16.u32 	%rs16, %r29;
	st.global.v2.u8 	[%rd22], {%rs16, %rs15};
	add.s64 	%rd23, %rd21, %rd19;
	cvt.u16.u32 	%rs17, %r44;
	cvt.u16.u32 	%rs18, %r39;
	st.global.v2.u8 	[%rd23], {%rs18, %rs17};

$L__BB17_2:
	ret;

}
.entry _Z20YuvToRgbPlanarKernelI6uchar26RGBA32S0_EvPhiS2_iii(
	.param .u64 _Z20YuvToRgbPlanarKernelI6uchar26RGBA32S0_EvPhiS2_iii_param_0,
	.param .u32 _Z20YuvToRgbPlanarKernelI6uchar26RGBA32S0_EvPhiS2_iii_param_1,
	.param .u64 _Z20YuvToRgbPlanarKernelI6uchar26RGBA32S0_EvPhiS2_iii_param_2,
	.param .u32 _Z20YuvToRgbPlanarKernelI6uchar26RGBA32S0_EvPhiS2_iii_param_3,
	.param .u32 _Z20YuvToRgbPlanarKernelI6uchar26RGBA32S0_EvPhiS2_iii_param_4,
	.param .u32 _Z20YuvToRgbPlanarKernelI6uchar26RGBA32S0_EvPhiS2_iii_param_5
)
{
	.reg .pred 	%p<28>;
	.reg .b16 	%rs<19>;
	.reg .f32 	%f<67>;
	.reg .b32 	%r<49>;
	.reg .b64 	%rd<24>;


	ld.param.u64 	%rd1, [_Z20YuvToRgbPlanarKernelI6uchar26RGBA32S0_EvPhiS2_iii_param_0];
	ld.param.u32 	%r3, [_Z20YuvToRgbPlanarKernelI6uchar26RGBA32S0_EvPhiS2_iii_param_1];
	ld.param.u64 	%rd2, [_Z20YuvToRgbPlanarKernelI6uchar26RGBA32S0_EvPhiS2_iii_param_2];
	ld.param.u32 	%r4, [_Z20YuvToRgbPlanarKernelI6uchar26RGBA32S0_EvPhiS2_iii_param_3];
	ld.param.u32 	%r6, [_Z20YuvToRgbPlanarKernelI6uchar26RGBA32S0_EvPhiS2_iii_param_4];
	ld.param.u32 	%r5, [_Z20YuvToRgbPlanarKernelI6uchar26RGBA32S0_EvPhiS2_iii_param_5];
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r8, %ctaid.x;
	mov.u32 	%r9, %tid.x;
	mad.lo.s32 	%r10, %r8, %r7, %r9;
	shl.b32 	%r1, %r10, 1;
	mov.u32 	%r11, %ntid.y;
	mov.u32 	%r12, %ctaid.y;
	mov.u32 	%r13, %tid.y;
	mad.lo.s32 	%r14, %r12, %r11, %r13;
	shl.b32 	%r2, %r14, 1;
	or.b32  	%r15, %r1, 1;
	setp.ge.s32 	%p1, %r15, %r6;
	or.b32  	%r16, %r2, 1;
	setp.ge.s32 	%p2, %r16, %r5;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	$L__BB18_2;

	cvt.s64.s32 	%rd3, %r1;
	and.b64  	%rd4, %rd3, 9223372036854775806;
	mul.lo.s32 	%r17, %r2, %r3;
	cvt.s64.s32 	%rd5, %r17;
	add.s64 	%rd6, %rd4, %rd5;
	cvta.to.global.u64 	%rd7, %rd1;
	add.s64 	%rd8, %rd7, %rd6;
	ld.global.v2.u8 	{%rs1, %rs2}, [%rd8];
	cvt.s64.s32 	%rd9, %r3;
	add.s64 	%rd10, %rd8, %rd9;
	ld.global.v2.u8 	{%rs3, %rs4}, [%rd10];
	shr.u32 	%r18, %r2, 31;
	add.s32 	%r19, %r2, %r18;
	shr.s32 	%r20, %r19, 1;
	sub.s32 	%r21, %r5, %r20;
	mul.lo.s32 	%r22, %r21, %r3;
	cvt.s64.s32 	%rd11, %r22;
	add.s64 	%rd12, %rd8, %rd11;
	ld.global.v2.u8 	{%rs5, %rs6}, [%rd12];
	cvt.u32.u16 	%r23, %rs1;
	add.s32 	%r24, %r23, -16;
	cvt.rn.f32.s32 	%f1, %r24;
	cvt.u32.u16 	%r25, %rs5;
	add.s32 	%r26, %r25, -128;
	cvt.rn.f32.s32 	%f2, %r26;
	cvt.u32.u16 	%r27, %rs6;
	add.s32 	%r28, %r27, -128;
	cvt.rn.f32.s32 	%f3, %r28;
	ld.const.f32 	%f4, [matYuv2Rgb];
	ld.const.f32 	%f5, [matYuv2Rgb+4];
	mul.f32 	%f6, %f5, %f2;
	fma.rn.f32 	%f7, %f4, %f1, %f6;
	ld.const.f32 	%f8, [matYuv2Rgb+8];
	fma.rn.f32 	%f9, %f8, %f3, %f7;
	setp.lt.f32 	%p4, %f9, 0f00000000;
	setp.gt.f32 	%p5, %f9, 0f437F0000;
	selp.f32 	%f10, 0f437F0000, %f9, %p5;
	selp.f32 	%f11, 0f00000000, %f10, %p4;
	cvt.rzi.u32.f32 	%r29, %f11;
	ld.const.f32 	%f12, [matYuv2Rgb+12];
	ld.const.f32 	%f13, [matYuv2Rgb+16];
	mul.f32 	%f14, %f13, %f2;
	fma.rn.f32 	%f15, %f12, %f1, %f14;
	ld.const.f32 	%f16, [matYuv2Rgb+20];
	fma.rn.f32 	%f17, %f16, %f3, %f15;
	setp.lt.f32 	%p6, %f17, 0f00000000;
	setp.gt.f32 	%p7, %f17, 0f437F0000;
	selp.f32 	%f18, 0f437F0000, %f17, %p7;
	selp.f32 	%f19, 0f00000000, %f18, %p6;
	cvt.rzi.u32.f32 	%r30, %f19;
	ld.const.f32 	%f20, [matYuv2Rgb+24];
	ld.const.f32 	%f21, [matYuv2Rgb+28];
	mul.f32 	%f22, %f21, %f2;
	fma.rn.f32 	%f23, %f20, %f1, %f22;
	ld.const.f32 	%f24, [matYuv2Rgb+32];
	fma.rn.f32 	%f25, %f24, %f3, %f23;
	setp.lt.f32 	%p8, %f25, 0f00000000;
	setp.gt.f32 	%p9, %f25, 0f437F0000;
	selp.f32 	%f26, 0f437F0000, %f25, %p9;
	selp.f32 	%f27, 0f00000000, %f26, %p8;
	cvt.rzi.u32.f32 	%r31, %f27;
	cvt.u32.u16 	%r32, %rs2;
	add.s32 	%r33, %r32, -16;
	cvt.rn.f32.s32 	%f28, %r33;
	fma.rn.f32 	%f29, %f4, %f28, %f6;
	fma.rn.f32 	%f30, %f8, %f3, %f29;
	setp.lt.f32 	%p10, %f30, 0f00000000;
	setp.gt.f32 	%p11, %f30, 0f437F0000;
	selp.f32 	%f31, 0f437F0000, %f30, %p11;
	selp.f32 	%f32, 0f00000000, %f31, %p10;
	cvt.rzi.u32.f32 	%r34, %f32;
	fma.rn.f32 	%f33, %f12, %f28, %f14;
	fma.rn.f32 	%f34, %f16, %f3, %f33;
	setp.lt.f32 	%p12, %f34, 0f00000000;
	setp.gt.f32 	%p13, %f34, 0f437F0000;
	selp.f32 	%f35, 0f437F0000, %f34, %p13;
	selp.f32 	%f36, 0f00000000, %f35, %p12;
	cvt.rzi.u32.f32 	%r35, %f36;
	fma.rn.f32 	%f37, %f20, %f28, %f22;
	fma.rn.f32 	%f38, %f24, %f3, %f37;
	setp.lt.f32 	%p14, %f38, 0f00000000;
	setp.gt.f32 	%p15, %f38, 0f437F0000;
	selp.f32 	%f39, 0f437F0000, %f38, %p15;
	selp.f32 	%f40, 0f00000000, %f39, %p14;
	cvt.rzi.u32.f32 	%r36, %f40;
	cvt.u32.u16 	%r37, %rs3;
	add.s32 	%r38, %r37, -16;
	cvt.rn.f32.s32 	%f41, %r38;
	fma.rn.f32 	%f42, %f4, %f41, %f6;
	fma.rn.f32 	%f43, %f8, %f3, %f42;
	setp.lt.f32 	%p16, %f43, 0f00000000;
	setp.gt.f32 	%p17, %f43, 0f437F0000;
	selp.f32 	%f44, 0f437F0000, %f43, %p17;
	selp.f32 	%f45, 0f00000000, %f44, %p16;
	cvt.rzi.u32.f32 	%r39, %f45;
	fma.rn.f32 	%f46, %f12, %f41, %f14;
	fma.rn.f32 	%f47, %f16, %f3, %f46;
	setp.lt.f32 	%p18, %f47, 0f00000000;
	setp.gt.f32 	%p19, %f47, 0f437F0000;
	selp.f32 	%f48, 0f437F0000, %f47, %p19;
	selp.f32 	%f49, 0f00000000, %f48, %p18;
	cvt.rzi.u32.f32 	%r40, %f49;
	fma.rn.f32 	%f50, %f20, %f41, %f22;
	fma.rn.f32 	%f51, %f24, %f3, %f50;
	setp.lt.f32 	%p20, %f51, 0f00000000;
	setp.gt.f32 	%p21, %f51, 0f437F0000;
	selp.f32 	%f52, 0f437F0000, %f51, %p21;
	selp.f32 	%f53, 0f00000000, %f52, %p20;
	cvt.rzi.u32.f32 	%r41, %f53;
	cvt.u32.u16 	%r42, %rs4;
	add.s32 	%r43, %r42, -16;
	cvt.rn.f32.s32 	%f54, %r43;
	fma.rn.f32 	%f55, %f4, %f54, %f6;
	fma.rn.f32 	%f56, %f8, %f3, %f55;
	setp.lt.f32 	%p22, %f56, 0f00000000;
	setp.gt.f32 	%p23, %f56, 0f437F0000;
	selp.f32 	%f57, 0f437F0000, %f56, %p23;
	selp.f32 	%f58, 0f00000000, %f57, %p22;
	cvt.rzi.u32.f32 	%r44, %f58;
	fma.rn.f32 	%f59, %f12, %f54, %f14;
	fma.rn.f32 	%f60, %f16, %f3, %f59;
	setp.lt.f32 	%p24, %f60, 0f00000000;
	setp.gt.f32 	%p25, %f60, 0f437F0000;
	selp.f32 	%f61, 0f437F0000, %f60, %p25;
	selp.f32 	%f62, 0f00000000, %f61, %p24;
	cvt.rzi.u32.f32 	%r45, %f62;
	fma.rn.f32 	%f63, %f20, %f54, %f22;
	fma.rn.f32 	%f64, %f24, %f3, %f63;
	setp.lt.f32 	%p26, %f64, 0f00000000;
	setp.gt.f32 	%p27, %f64, 0f437F0000;
	selp.f32 	%f65, 0f437F0000, %f64, %p27;
	selp.f32 	%f66, 0f00000000, %f65, %p26;
	cvt.rzi.u32.f32 	%r46, %f66;
	mul.lo.s32 	%r47, %r2, %r4;
	cvt.s64.s32 	%rd13, %r47;
	add.s64 	%rd14, %rd4, %rd13;
	cvta.to.global.u64 	%rd15, %rd2;
	add.s64 	%rd16, %rd15, %rd14;
	cvt.u16.u32 	%rs7, %r34;
	cvt.u16.u32 	%rs8, %r29;
	st.global.v2.u8 	[%rd16], {%rs8, %rs7};
	cvt.s64.s32 	%rd17, %r4;
	add.s64 	%rd18, %rd16, %rd17;
	cvt.u16.u32 	%rs9, %r44;
	cvt.u16.u32 	%rs10, %r39;
	st.global.v2.u8 	[%rd18], {%rs10, %rs9};
	mul.lo.s32 	%r48, %r5, %r4;
	cvt.s64.s32 	%rd19, %r48;
	add.s64 	%rd20, %rd16, %rd19;
	cvt.u16.u32 	%rs11, %r35;
	cvt.u16.u32 	%rs12, %r30;
	st.global.v2.u8 	[%rd20], {%rs12, %rs11};
	add.s64 	%rd21, %rd18, %rd19;
	cvt.u16.u32 	%rs13, %r45;
	cvt.u16.u32 	%rs14, %r40;
	st.global.v2.u8 	[%rd21], {%rs14, %rs13};
	add.s64 	%rd22, %rd20, %rd19;
	cvt.u16.u32 	%rs15, %r36;
	cvt.u16.u32 	%rs16, %r31;
	st.global.v2.u8 	[%rd22], {%rs16, %rs15};
	add.s64 	%rd23, %rd21, %rd19;
	cvt.u16.u32 	%rs17, %r46;
	cvt.u16.u32 	%rs18, %r41;
	st.global.v2.u8 	[%rd23], {%rs18, %rs17};

$L__BB18_2:
	ret;

}
.entry _Z20YuvToRgbPlanarKernelI7ushort26BGRA326uchar2EvPhiS3_iii(
	.param .u64 _Z20YuvToRgbPlanarKernelI7ushort26BGRA326uchar2EvPhiS3_iii_param_0,
	.param .u32 _Z20YuvToRgbPlanarKernelI7ushort26BGRA326uchar2EvPhiS3_iii_param_1,
	.param .u64 _Z20YuvToRgbPlanarKernelI7ushort26BGRA326uchar2EvPhiS3_iii_param_2,
	.param .u32 _Z20YuvToRgbPlanarKernelI7ushort26BGRA326uchar2EvPhiS3_iii_param_3,
	.param .u32 _Z20YuvToRgbPlanarKernelI7ushort26BGRA326uchar2EvPhiS3_iii_param_4,
	.param .u32 _Z20YuvToRgbPlanarKernelI7ushort26BGRA326uchar2EvPhiS3_iii_param_5
)
{
	.reg .pred 	%p<28>;
	.reg .b16 	%rs<25>;
	.reg .f32 	%f<67>;
	.reg .b32 	%r<61>;
	.reg .b64 	%rd<26>;


	ld.param.u64 	%rd1, [_Z20YuvToRgbPlanarKernelI7ushort26BGRA326uchar2EvPhiS3_iii_param_0];
	ld.param.u32 	%r3, [_Z20YuvToRgbPlanarKernelI7ushort26BGRA326uchar2EvPhiS3_iii_param_1];
	ld.param.u64 	%rd2, [_Z20YuvToRgbPlanarKernelI7ushort26BGRA326uchar2EvPhiS3_iii_param_2];
	ld.param.u32 	%r4, [_Z20YuvToRgbPlanarKernelI7ushort26BGRA326uchar2EvPhiS3_iii_param_3];
	ld.param.u32 	%r6, [_Z20YuvToRgbPlanarKernelI7ushort26BGRA326uchar2EvPhiS3_iii_param_4];
	ld.param.u32 	%r5, [_Z20YuvToRgbPlanarKernelI7ushort26BGRA326uchar2EvPhiS3_iii_param_5];
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r8, %ctaid.x;
	mov.u32 	%r9, %tid.x;
	mad.lo.s32 	%r10, %r8, %r7, %r9;
	shl.b32 	%r1, %r10, 1;
	mov.u32 	%r11, %ntid.y;
	mov.u32 	%r12, %ctaid.y;
	mov.u32 	%r13, %tid.y;
	mad.lo.s32 	%r14, %r12, %r11, %r13;
	shl.b32 	%r2, %r14, 1;
	or.b32  	%r15, %r1, 1;
	setp.ge.s32 	%p1, %r15, %r6;
	or.b32  	%r16, %r2, 1;
	setp.ge.s32 	%p2, %r16, %r5;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	$L__BB19_2;

	cvt.s64.s32 	%rd3, %r1;
	mul.wide.s32 	%rd4, %r1, 2;
	and.b64  	%rd5, %rd4, 9223372036854775804;
	mul.lo.s32 	%r17, %r2, %r3;
	cvt.s64.s32 	%rd6, %r17;
	add.s64 	%rd7, %rd5, %rd6;
	cvta.to.global.u64 	%rd8, %rd1;
	add.s64 	%rd9, %rd8, %rd7;
	ld.global.v2.u16 	{%rs1, %rs2}, [%rd9];
	cvt.s64.s32 	%rd10, %r3;
	add.s64 	%rd11, %rd9, %rd10;
	ld.global.v2.u16 	{%rs5, %rs6}, [%rd11];
	shr.u32 	%r18, %r2, 31;
	add.s32 	%r19, %r2, %r18;
	shr.s32 	%r20, %r19, 1;
	sub.s32 	%r21, %r5, %r20;
	mul.lo.s32 	%r22, %r21, %r3;
	cvt.s64.s32 	%rd12, %r22;
	add.s64 	%rd13, %rd9, %rd12;
	ld.global.v2.u16 	{%rs9, %rs10}, [%rd13];
	cvt.u32.u16 	%r23, %rs1;
	add.s32 	%r24, %r23, -4096;
	cvt.rn.f32.s32 	%f1, %r24;
	cvt.u32.u16 	%r25, %rs9;
	add.s32 	%r26, %r25, -32768;
	cvt.rn.f32.s32 	%f2, %r26;
	cvt.u32.u16 	%r27, %rs10;
	add.s32 	%r28, %r27, -32768;
	cvt.rn.f32.s32 	%f3, %r28;
	ld.const.f32 	%f4, [matYuv2Rgb];
	ld.const.f32 	%f5, [matYuv2Rgb+4];
	mul.f32 	%f6, %f5, %f2;
	fma.rn.f32 	%f7, %f4, %f1, %f6;
	ld.const.f32 	%f8, [matYuv2Rgb+8];
	fma.rn.f32 	%f9, %f8, %f3, %f7;
	setp.lt.f32 	%p4, %f9, 0f00000000;
	setp.gt.f32 	%p5, %f9, 0f477FFF00;
	selp.f32 	%f10, 0f477FFF00, %f9, %p5;
	selp.f32 	%f11, 0f00000000, %f10, %p4;
	cvt.rzi.u32.f32 	%r29, %f11;
	ld.const.f32 	%f12, [matYuv2Rgb+12];
	ld.const.f32 	%f13, [matYuv2Rgb+16];
	mul.f32 	%f14, %f13, %f2;
	fma.rn.f32 	%f15, %f12, %f1, %f14;
	ld.const.f32 	%f16, [matYuv2Rgb+20];
	fma.rn.f32 	%f17, %f16, %f3, %f15;
	setp.lt.f32 	%p6, %f17, 0f00000000;
	setp.gt.f32 	%p7, %f17, 0f477FFF00;
	selp.f32 	%f18, 0f477FFF00, %f17, %p7;
	selp.f32 	%f19, 0f00000000, %f18, %p6;
	cvt.rzi.u32.f32 	%r30, %f19;
	ld.const.f32 	%f20, [matYuv2Rgb+24];
	ld.const.f32 	%f21, [matYuv2Rgb+28];
	mul.f32 	%f22, %f21, %f2;
	fma.rn.f32 	%f23, %f20, %f1, %f22;
	ld.const.f32 	%f24, [matYuv2Rgb+32];
	fma.rn.f32 	%f25, %f24, %f3, %f23;
	setp.lt.f32 	%p8, %f25, 0f00000000;
	setp.gt.f32 	%p9, %f25, 0f477FFF00;
	selp.f32 	%f26, 0f477FFF00, %f25, %p9;
	selp.f32 	%f27, 0f00000000, %f26, %p8;
	cvt.rzi.u32.f32 	%r31, %f27;
	shr.u32 	%r32, %r31, 8;
	shr.u32 	%r33, %r30, 8;
	shr.u32 	%r34, %r29, 8;
	cvt.u32.u16 	%r35, %rs2;
	add.s32 	%r36, %r35, -4096;
	cvt.rn.f32.s32 	%f28, %r36;
	fma.rn.f32 	%f29, %f4, %f28, %f6;
	fma.rn.f32 	%f30, %f8, %f3, %f29;
	setp.lt.f32 	%p10, %f30, 0f00000000;
	setp.gt.f32 	%p11, %f30, 0f477FFF00;
	selp.f32 	%f31, 0f477FFF00, %f30, %p11;
	selp.f32 	%f32, 0f00000000, %f31, %p10;
	cvt.rzi.u32.f32 	%r37, %f32;
	fma.rn.f32 	%f33, %f12, %f28, %f14;
	fma.rn.f32 	%f34, %f16, %f3, %f33;
	setp.lt.f32 	%p12, %f34, 0f00000000;
	setp.gt.f32 	%p13, %f34, 0f477FFF00;
	selp.f32 	%f35, 0f477FFF00, %f34, %p13;
	selp.f32 	%f36, 0f00000000, %f35, %p12;
	cvt.rzi.u32.f32 	%r38, %f36;
	fma.rn.f32 	%f37, %f20, %f28, %f22;
	fma.rn.f32 	%f38, %f24, %f3, %f37;
	setp.lt.f32 	%p14, %f38, 0f00000000;
	setp.gt.f32 	%p15, %f38, 0f477FFF00;
	selp.f32 	%f39, 0f477FFF00, %f38, %p15;
	selp.f32 	%f40, 0f00000000, %f39, %p14;
	cvt.rzi.u32.f32 	%r39, %f40;
	shr.u32 	%r40, %r39, 8;
	shr.u32 	%r41, %r38, 8;
	shr.u32 	%r42, %r37, 8;
	cvt.u32.u16 	%r43, %rs5;
	add.s32 	%r44, %r43, -4096;
	cvt.rn.f32.s32 	%f41, %r44;
	fma.rn.f32 	%f42, %f4, %f41, %f6;
	fma.rn.f32 	%f43, %f8, %f3, %f42;
	setp.lt.f32 	%p16, %f43, 0f00000000;
	setp.gt.f32 	%p17, %f43, 0f477FFF00;
	selp.f32 	%f44, 0f477FFF00, %f43, %p17;
	selp.f32 	%f45, 0f00000000, %f44, %p16;
	cvt.rzi.u32.f32 	%r45, %f45;
	fma.rn.f32 	%f46, %f12, %f41, %f14;
	fma.rn.f32 	%f47, %f16, %f3, %f46;
	setp.lt.f32 	%p18, %f47, 0f00000000;
	setp.gt.f32 	%p19, %f47, 0f477FFF00;
	selp.f32 	%f48, 0f477FFF00, %f47, %p19;
	selp.f32 	%f49, 0f00000000, %f48, %p18;
	cvt.rzi.u32.f32 	%r46, %f49;
	fma.rn.f32 	%f50, %f20, %f41, %f22;
	fma.rn.f32 	%f51, %f24, %f3, %f50;
	setp.lt.f32 	%p20, %f51, 0f00000000;
	setp.gt.f32 	%p21, %f51, 0f477FFF00;
	selp.f32 	%f52, 0f477FFF00, %f51, %p21;
	selp.f32 	%f53, 0f00000000, %f52, %p20;
	cvt.rzi.u32.f32 	%r47, %f53;
	shr.u32 	%r48, %r47, 8;
	shr.u32 	%r49, %r46, 8;
	shr.u32 	%r50, %r45, 8;
	cvt.u32.u16 	%r51, %rs6;
	add.s32 	%r52, %r51, -4096;
	cvt.rn.f32.s32 	%f54, %r52;
	fma.rn.f32 	%f55, %f4, %f54, %f6;
	fma.rn.f32 	%f56, %f8, %f3, %f55;
	setp.lt.f32 	%p22, %f56, 0f00000000;
	setp.gt.f32 	%p23, %f56, 0f477FFF00;
	selp.f32 	%f57, 0f477FFF00, %f56, %p23;
	selp.f32 	%f58, 0f00000000, %f57, %p22;
	cvt.rzi.u32.f32 	%r53, %f58;
	fma.rn.f32 	%f59, %f12, %f54, %f14;
	fma.rn.f32 	%f60, %f16, %f3, %f59;
	setp.lt.f32 	%p24, %f60, 0f00000000;
	setp.gt.f32 	%p25, %f60, 0f477FFF00;
	selp.f32 	%f61, 0f477FFF00, %f60, %p25;
	selp.f32 	%f62, 0f00000000, %f61, %p24;
	cvt.rzi.u32.f32 	%r54, %f62;
	fma.rn.f32 	%f63, %f20, %f54, %f22;
	fma.rn.f32 	%f64, %f24, %f3, %f63;
	setp.lt.f32 	%p26, %f64, 0f00000000;
	setp.gt.f32 	%p27, %f64, 0f477FFF00;
	selp.f32 	%f65, 0f477FFF00, %f64, %p27;
	selp.f32 	%f66, 0f00000000, %f65, %p26;
	cvt.rzi.u32.f32 	%r55, %f66;
	shr.u32 	%r56, %r55, 8;
	shr.u32 	%r57, %r54, 8;
	shr.u32 	%r58, %r53, 8;
	and.b64  	%rd14, %rd3, 9223372036854775806;
	mul.lo.s32 	%r59, %r2, %r4;
	cvt.s64.s32 	%rd15, %r59;
	add.s64 	%rd16, %rd14, %rd15;
	cvta.to.global.u64 	%rd17, %rd2;
	add.s64 	%rd18, %rd17, %rd16;
	cvt.u16.u32 	%rs13, %r40;
	cvt.u16.u32 	%rs14, %r32;
	st.global.v2.u8 	[%rd18], {%rs14, %rs13};
	cvt.s64.s32 	%rd19, %r4;
	add.s64 	%rd20, %rd18, %rd19;
	cvt.u16.u32 	%rs15, %r56;
	cvt.u16.u32 	%rs16, %r48;
	st.global.v2.u8 	[%rd20], {%rs16, %rs15};
	mul.lo.s32 	%r60, %r5, %r4;
	cvt.s64.s32 	%rd21, %r60;
	add.s64 	%rd22, %rd18, %rd21;
	cvt.u16.u32 	%rs17, %r41;
	cvt.u16.u32 	%rs18, %r33;
	st.global.v2.u8 	[%rd22], {%rs18, %rs17};
	add.s64 	%rd23, %rd20, %rd21;
	cvt.u16.u32 	%rs19, %r57;
	cvt.u16.u32 	%rs20, %r49;
	st.global.v2.u8 	[%rd23], {%rs20, %rs19};
	add.s64 	%rd24, %rd22, %rd21;
	cvt.u16.u32 	%rs21, %r42;
	cvt.u16.u32 	%rs22, %r34;
	st.global.v2.u8 	[%rd24], {%rs22, %rs21};
	add.s64 	%rd25, %rd23, %rd21;
	cvt.u16.u32 	%rs23, %r58;
	cvt.u16.u32 	%rs24, %r50;
	st.global.v2.u8 	[%rd25], {%rs24, %rs23};

$L__BB19_2:
	ret;

}
.entry _Z20YuvToRgbPlanarKernelI7ushort26RGBA326uchar2EvPhiS3_iii(
	.param .u64 _Z20YuvToRgbPlanarKernelI7ushort26RGBA326uchar2EvPhiS3_iii_param_0,
	.param .u32 _Z20YuvToRgbPlanarKernelI7ushort26RGBA326uchar2EvPhiS3_iii_param_1,
	.param .u64 _Z20YuvToRgbPlanarKernelI7ushort26RGBA326uchar2EvPhiS3_iii_param_2,
	.param .u32 _Z20YuvToRgbPlanarKernelI7ushort26RGBA326uchar2EvPhiS3_iii_param_3,
	.param .u32 _Z20YuvToRgbPlanarKernelI7ushort26RGBA326uchar2EvPhiS3_iii_param_4,
	.param .u32 _Z20YuvToRgbPlanarKernelI7ushort26RGBA326uchar2EvPhiS3_iii_param_5
)
{
	.reg .pred 	%p<28>;
	.reg .b16 	%rs<25>;
	.reg .f32 	%f<67>;
	.reg .b32 	%r<61>;
	.reg .b64 	%rd<26>;


	ld.param.u64 	%rd1, [_Z20YuvToRgbPlanarKernelI7ushort26RGBA326uchar2EvPhiS3_iii_param_0];
	ld.param.u32 	%r3, [_Z20YuvToRgbPlanarKernelI7ushort26RGBA326uchar2EvPhiS3_iii_param_1];
	ld.param.u64 	%rd2, [_Z20YuvToRgbPlanarKernelI7ushort26RGBA326uchar2EvPhiS3_iii_param_2];
	ld.param.u32 	%r4, [_Z20YuvToRgbPlanarKernelI7ushort26RGBA326uchar2EvPhiS3_iii_param_3];
	ld.param.u32 	%r6, [_Z20YuvToRgbPlanarKernelI7ushort26RGBA326uchar2EvPhiS3_iii_param_4];
	ld.param.u32 	%r5, [_Z20YuvToRgbPlanarKernelI7ushort26RGBA326uchar2EvPhiS3_iii_param_5];
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r8, %ctaid.x;
	mov.u32 	%r9, %tid.x;
	mad.lo.s32 	%r10, %r8, %r7, %r9;
	shl.b32 	%r1, %r10, 1;
	mov.u32 	%r11, %ntid.y;
	mov.u32 	%r12, %ctaid.y;
	mov.u32 	%r13, %tid.y;
	mad.lo.s32 	%r14, %r12, %r11, %r13;
	shl.b32 	%r2, %r14, 1;
	or.b32  	%r15, %r1, 1;
	setp.ge.s32 	%p1, %r15, %r6;
	or.b32  	%r16, %r2, 1;
	setp.ge.s32 	%p2, %r16, %r5;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	$L__BB20_2;

	cvt.s64.s32 	%rd3, %r1;
	mul.wide.s32 	%rd4, %r1, 2;
	and.b64  	%rd5, %rd4, 9223372036854775804;
	mul.lo.s32 	%r17, %r2, %r3;
	cvt.s64.s32 	%rd6, %r17;
	add.s64 	%rd7, %rd5, %rd6;
	cvta.to.global.u64 	%rd8, %rd1;
	add.s64 	%rd9, %rd8, %rd7;
	ld.global.v2.u16 	{%rs1, %rs2}, [%rd9];
	cvt.s64.s32 	%rd10, %r3;
	add.s64 	%rd11, %rd9, %rd10;
	ld.global.v2.u16 	{%rs5, %rs6}, [%rd11];
	shr.u32 	%r18, %r2, 31;
	add.s32 	%r19, %r2, %r18;
	shr.s32 	%r20, %r19, 1;
	sub.s32 	%r21, %r5, %r20;
	mul.lo.s32 	%r22, %r21, %r3;
	cvt.s64.s32 	%rd12, %r22;
	add.s64 	%rd13, %rd9, %rd12;
	ld.global.v2.u16 	{%rs9, %rs10}, [%rd13];
	cvt.u32.u16 	%r23, %rs1;
	add.s32 	%r24, %r23, -4096;
	cvt.rn.f32.s32 	%f1, %r24;
	cvt.u32.u16 	%r25, %rs9;
	add.s32 	%r26, %r25, -32768;
	cvt.rn.f32.s32 	%f2, %r26;
	cvt.u32.u16 	%r27, %rs10;
	add.s32 	%r28, %r27, -32768;
	cvt.rn.f32.s32 	%f3, %r28;
	ld.const.f32 	%f4, [matYuv2Rgb];
	ld.const.f32 	%f5, [matYuv2Rgb+4];
	mul.f32 	%f6, %f5, %f2;
	fma.rn.f32 	%f7, %f4, %f1, %f6;
	ld.const.f32 	%f8, [matYuv2Rgb+8];
	fma.rn.f32 	%f9, %f8, %f3, %f7;
	setp.lt.f32 	%p4, %f9, 0f00000000;
	setp.gt.f32 	%p5, %f9, 0f477FFF00;
	selp.f32 	%f10, 0f477FFF00, %f9, %p5;
	selp.f32 	%f11, 0f00000000, %f10, %p4;
	cvt.rzi.u32.f32 	%r29, %f11;
	ld.const.f32 	%f12, [matYuv2Rgb+12];
	ld.const.f32 	%f13, [matYuv2Rgb+16];
	mul.f32 	%f14, %f13, %f2;
	fma.rn.f32 	%f15, %f12, %f1, %f14;
	ld.const.f32 	%f16, [matYuv2Rgb+20];
	fma.rn.f32 	%f17, %f16, %f3, %f15;
	setp.lt.f32 	%p6, %f17, 0f00000000;
	setp.gt.f32 	%p7, %f17, 0f477FFF00;
	selp.f32 	%f18, 0f477FFF00, %f17, %p7;
	selp.f32 	%f19, 0f00000000, %f18, %p6;
	cvt.rzi.u32.f32 	%r30, %f19;
	ld.const.f32 	%f20, [matYuv2Rgb+24];
	ld.const.f32 	%f21, [matYuv2Rgb+28];
	mul.f32 	%f22, %f21, %f2;
	fma.rn.f32 	%f23, %f20, %f1, %f22;
	ld.const.f32 	%f24, [matYuv2Rgb+32];
	fma.rn.f32 	%f25, %f24, %f3, %f23;
	setp.lt.f32 	%p8, %f25, 0f00000000;
	setp.gt.f32 	%p9, %f25, 0f477FFF00;
	selp.f32 	%f26, 0f477FFF00, %f25, %p9;
	selp.f32 	%f27, 0f00000000, %f26, %p8;
	cvt.rzi.u32.f32 	%r31, %f27;
	shr.u32 	%r32, %r29, 8;
	shr.u32 	%r33, %r30, 8;
	shr.u32 	%r34, %r31, 8;
	cvt.u32.u16 	%r35, %rs2;
	add.s32 	%r36, %r35, -4096;
	cvt.rn.f32.s32 	%f28, %r36;
	fma.rn.f32 	%f29, %f4, %f28, %f6;
	fma.rn.f32 	%f30, %f8, %f3, %f29;
	setp.lt.f32 	%p10, %f30, 0f00000000;
	setp.gt.f32 	%p11, %f30, 0f477FFF00;
	selp.f32 	%f31, 0f477FFF00, %f30, %p11;
	selp.f32 	%f32, 0f00000000, %f31, %p10;
	cvt.rzi.u32.f32 	%r37, %f32;
	fma.rn.f32 	%f33, %f12, %f28, %f14;
	fma.rn.f32 	%f34, %f16, %f3, %f33;
	setp.lt.f32 	%p12, %f34, 0f00000000;
	setp.gt.f32 	%p13, %f34, 0f477FFF00;
	selp.f32 	%f35, 0f477FFF00, %f34, %p13;
	selp.f32 	%f36, 0f00000000, %f35, %p12;
	cvt.rzi.u32.f32 	%r38, %f36;
	fma.rn.f32 	%f37, %f20, %f28, %f22;
	fma.rn.f32 	%f38, %f24, %f3, %f37;
	setp.lt.f32 	%p14, %f38, 0f00000000;
	setp.gt.f32 	%p15, %f38, 0f477FFF00;
	selp.f32 	%f39, 0f477FFF00, %f38, %p15;
	selp.f32 	%f40, 0f00000000, %f39, %p14;
	cvt.rzi.u32.f32 	%r39, %f40;
	shr.u32 	%r40, %r37, 8;
	shr.u32 	%r41, %r38, 8;
	shr.u32 	%r42, %r39, 8;
	cvt.u32.u16 	%r43, %rs5;
	add.s32 	%r44, %r43, -4096;
	cvt.rn.f32.s32 	%f41, %r44;
	fma.rn.f32 	%f42, %f4, %f41, %f6;
	fma.rn.f32 	%f43, %f8, %f3, %f42;
	setp.lt.f32 	%p16, %f43, 0f00000000;
	setp.gt.f32 	%p17, %f43, 0f477FFF00;
	selp.f32 	%f44, 0f477FFF00, %f43, %p17;
	selp.f32 	%f45, 0f00000000, %f44, %p16;
	cvt.rzi.u32.f32 	%r45, %f45;
	fma.rn.f32 	%f46, %f12, %f41, %f14;
	fma.rn.f32 	%f47, %f16, %f3, %f46;
	setp.lt.f32 	%p18, %f47, 0f00000000;
	setp.gt.f32 	%p19, %f47, 0f477FFF00;
	selp.f32 	%f48, 0f477FFF00, %f47, %p19;
	selp.f32 	%f49, 0f00000000, %f48, %p18;
	cvt.rzi.u32.f32 	%r46, %f49;
	fma.rn.f32 	%f50, %f20, %f41, %f22;
	fma.rn.f32 	%f51, %f24, %f3, %f50;
	setp.lt.f32 	%p20, %f51, 0f00000000;
	setp.gt.f32 	%p21, %f51, 0f477FFF00;
	selp.f32 	%f52, 0f477FFF00, %f51, %p21;
	selp.f32 	%f53, 0f00000000, %f52, %p20;
	cvt.rzi.u32.f32 	%r47, %f53;
	shr.u32 	%r48, %r45, 8;
	shr.u32 	%r49, %r46, 8;
	shr.u32 	%r50, %r47, 8;
	cvt.u32.u16 	%r51, %rs6;
	add.s32 	%r52, %r51, -4096;
	cvt.rn.f32.s32 	%f54, %r52;
	fma.rn.f32 	%f55, %f4, %f54, %f6;
	fma.rn.f32 	%f56, %f8, %f3, %f55;
	setp.lt.f32 	%p22, %f56, 0f00000000;
	setp.gt.f32 	%p23, %f56, 0f477FFF00;
	selp.f32 	%f57, 0f477FFF00, %f56, %p23;
	selp.f32 	%f58, 0f00000000, %f57, %p22;
	cvt.rzi.u32.f32 	%r53, %f58;
	fma.rn.f32 	%f59, %f12, %f54, %f14;
	fma.rn.f32 	%f60, %f16, %f3, %f59;
	setp.lt.f32 	%p24, %f60, 0f00000000;
	setp.gt.f32 	%p25, %f60, 0f477FFF00;
	selp.f32 	%f61, 0f477FFF00, %f60, %p25;
	selp.f32 	%f62, 0f00000000, %f61, %p24;
	cvt.rzi.u32.f32 	%r54, %f62;
	fma.rn.f32 	%f63, %f20, %f54, %f22;
	fma.rn.f32 	%f64, %f24, %f3, %f63;
	setp.lt.f32 	%p26, %f64, 0f00000000;
	setp.gt.f32 	%p27, %f64, 0f477FFF00;
	selp.f32 	%f65, 0f477FFF00, %f64, %p27;
	selp.f32 	%f66, 0f00000000, %f65, %p26;
	cvt.rzi.u32.f32 	%r55, %f66;
	shr.u32 	%r56, %r53, 8;
	shr.u32 	%r57, %r54, 8;
	shr.u32 	%r58, %r55, 8;
	and.b64  	%rd14, %rd3, 9223372036854775806;
	mul.lo.s32 	%r59, %r2, %r4;
	cvt.s64.s32 	%rd15, %r59;
	add.s64 	%rd16, %rd14, %rd15;
	cvta.to.global.u64 	%rd17, %rd2;
	add.s64 	%rd18, %rd17, %rd16;
	cvt.u16.u32 	%rs13, %r40;
	cvt.u16.u32 	%rs14, %r32;
	st.global.v2.u8 	[%rd18], {%rs14, %rs13};
	cvt.s64.s32 	%rd19, %r4;
	add.s64 	%rd20, %rd18, %rd19;
	cvt.u16.u32 	%rs15, %r56;
	cvt.u16.u32 	%rs16, %r48;
	st.global.v2.u8 	[%rd20], {%rs16, %rs15};
	mul.lo.s32 	%r60, %r5, %r4;
	cvt.s64.s32 	%rd21, %r60;
	add.s64 	%rd22, %rd18, %rd21;
	cvt.u16.u32 	%rs17, %r41;
	cvt.u16.u32 	%rs18, %r33;
	st.global.v2.u8 	[%rd22], {%rs18, %rs17};
	add.s64 	%rd23, %rd20, %rd21;
	cvt.u16.u32 	%rs19, %r57;
	cvt.u16.u32 	%rs20, %r49;
	st.global.v2.u8 	[%rd23], {%rs20, %rs19};
	add.s64 	%rd24, %rd22, %rd21;
	cvt.u16.u32 	%rs21, %r42;
	cvt.u16.u32 	%rs22, %r34;
	st.global.v2.u8 	[%rd24], {%rs22, %rs21};
	add.s64 	%rd25, %rd23, %rd21;
	cvt.u16.u32 	%rs23, %r58;
	cvt.u16.u32 	%rs24, %r50;
	st.global.v2.u8 	[%rd25], {%rs24, %rs23};

$L__BB20_2:
	ret;

}
.entry _Z23Yuv444ToRgbPlanarKernelI6uchar26BGRA32S0_EvPhiS2_iii(
	.param .u64 _Z23Yuv444ToRgbPlanarKernelI6uchar26BGRA32S0_EvPhiS2_iii_param_0,
	.param .u32 _Z23Yuv444ToRgbPlanarKernelI6uchar26BGRA32S0_EvPhiS2_iii_param_1,
	.param .u64 _Z23Yuv444ToRgbPlanarKernelI6uchar26BGRA32S0_EvPhiS2_iii_param_2,
	.param .u32 _Z23Yuv444ToRgbPlanarKernelI6uchar26BGRA32S0_EvPhiS2_iii_param_3,
	.param .u32 _Z23Yuv444ToRgbPlanarKernelI6uchar26BGRA32S0_EvPhiS2_iii_param_4,
	.param .u32 _Z23Yuv444ToRgbPlanarKernelI6uchar26BGRA32S0_EvPhiS2_iii_param_5
)
{
	.reg .pred 	%p<16>;
	.reg .b16 	%rs<13>;
	.reg .f32 	%f<46>;
	.reg .b32 	%r<38>;
	.reg .b64 	%rd<20>;


	ld.param.u64 	%rd1, [_Z23Yuv444ToRgbPlanarKernelI6uchar26BGRA32S0_EvPhiS2_iii_param_0];
	ld.param.u32 	%r3, [_Z23Yuv444ToRgbPlanarKernelI6uchar26BGRA32S0_EvPhiS2_iii_param_1];
	ld.param.u64 	%rd2, [_Z23Yuv444ToRgbPlanarKernelI6uchar26BGRA32S0_EvPhiS2_iii_param_2];
	ld.param.u32 	%r4, [_Z23Yuv444ToRgbPlanarKernelI6uchar26BGRA32S0_EvPhiS2_iii_param_3];
	ld.param.u32 	%r6, [_Z23Yuv444ToRgbPlanarKernelI6uchar26BGRA32S0_EvPhiS2_iii_param_4];
	ld.param.u32 	%r5, [_Z23Yuv444ToRgbPlanarKernelI6uchar26BGRA32S0_EvPhiS2_iii_param_5];
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r8, %ctaid.x;
	mov.u32 	%r9, %tid.x;
	mad.lo.s32 	%r10, %r8, %r7, %r9;
	shl.b32 	%r1, %r10, 1;
	mov.u32 	%r11, %ntid.y;
	mov.u32 	%r12, %ctaid.y;
	mov.u32 	%r13, %tid.y;
	mad.lo.s32 	%r2, %r12, %r11, %r13;
	or.b32  	%r14, %r1, 1;
	setp.ge.s32 	%p1, %r14, %r6;
	setp.ge.s32 	%p2, %r2, %r5;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	$L__BB21_2;

	cvt.s64.s32 	%rd3, %r1;
	and.b64  	%rd4, %rd3, 9223372036854775806;
	mul.lo.s32 	%r15, %r2, %r3;
	cvt.s64.s32 	%rd5, %r15;
	add.s64 	%rd6, %rd4, %rd5;
	cvta.to.global.u64 	%rd7, %rd1;
	add.s64 	%rd8, %rd7, %rd6;
	ld.global.v2.u8 	{%rs1, %rs2}, [%rd8];
	mul.lo.s32 	%r16, %r5, %r3;
	cvt.s64.s32 	%rd9, %r16;
	add.s64 	%rd10, %rd8, %rd9;
	ld.global.v2.u8 	{%rs3, %rs4}, [%rd10];
	shl.b32 	%r17, %r16, 1;
	cvt.s64.s32 	%rd11, %r17;
	add.s64 	%rd12, %rd8, %rd11;
	ld.global.v2.u8 	{%rs5, %rs6}, [%rd12];
	cvt.u32.u16 	%r18, %rs1;
	add.s32 	%r19, %r18, -16;
	cvt.rn.f32.s32 	%f1, %r19;
	cvt.u32.u16 	%r20, %rs3;
	add.s32 	%r21, %r20, -128;
	cvt.rn.f32.s32 	%f2, %r21;
	cvt.u32.u16 	%r22, %rs5;
	add.s32 	%r23, %r22, -128;
	cvt.rn.f32.s32 	%f3, %r23;
	ld.const.f32 	%f4, [matYuv2Rgb];
	ld.const.f32 	%f5, [matYuv2Rgb+4];
	mul.f32 	%f6, %f5, %f2;
	fma.rn.f32 	%f7, %f4, %f1, %f6;
	ld.const.f32 	%f8, [matYuv2Rgb+8];
	fma.rn.f32 	%f9, %f8, %f3, %f7;
	setp.lt.f32 	%p4, %f9, 0f00000000;
	setp.gt.f32 	%p5, %f9, 0f437F0000;
	selp.f32 	%f10, 0f437F0000, %f9, %p5;
	selp.f32 	%f11, 0f00000000, %f10, %p4;
	cvt.rzi.u32.f32 	%r24, %f11;
	ld.const.f32 	%f12, [matYuv2Rgb+12];
	ld.const.f32 	%f13, [matYuv2Rgb+16];
	mul.f32 	%f14, %f13, %f2;
	fma.rn.f32 	%f15, %f12, %f1, %f14;
	ld.const.f32 	%f16, [matYuv2Rgb+20];
	fma.rn.f32 	%f17, %f16, %f3, %f15;
	setp.lt.f32 	%p6, %f17, 0f00000000;
	setp.gt.f32 	%p7, %f17, 0f437F0000;
	selp.f32 	%f18, 0f437F0000, %f17, %p7;
	selp.f32 	%f19, 0f00000000, %f18, %p6;
	cvt.rzi.u32.f32 	%r25, %f19;
	ld.const.f32 	%f20, [matYuv2Rgb+24];
	ld.const.f32 	%f21, [matYuv2Rgb+28];
	mul.f32 	%f22, %f21, %f2;
	fma.rn.f32 	%f23, %f20, %f1, %f22;
	ld.const.f32 	%f24, [matYuv2Rgb+32];
	fma.rn.f32 	%f25, %f24, %f3, %f23;
	setp.lt.f32 	%p8, %f25, 0f00000000;
	setp.gt.f32 	%p9, %f25, 0f437F0000;
	selp.f32 	%f26, 0f437F0000, %f25, %p9;
	selp.f32 	%f27, 0f00000000, %f26, %p8;
	cvt.rzi.u32.f32 	%r26, %f27;
	cvt.u32.u16 	%r27, %rs2;
	add.s32 	%r28, %r27, -16;
	cvt.rn.f32.s32 	%f28, %r28;
	cvt.u32.u16 	%r29, %rs4;
	add.s32 	%r30, %r29, -128;
	cvt.rn.f32.s32 	%f29, %r30;
	cvt.u32.u16 	%r31, %rs6;
	add.s32 	%r32, %r31, -128;
	cvt.rn.f32.s32 	%f30, %r32;
	mul.f32 	%f31, %f5, %f29;
	fma.rn.f32 	%f32, %f4, %f28, %f31;
	fma.rn.f32 	%f33, %f8, %f30, %f32;
	setp.lt.f32 	%p10, %f33, 0f00000000;
	setp.gt.f32 	%p11, %f33, 0f437F0000;
	selp.f32 	%f34, 0f437F0000, %f33, %p11;
	selp.f32 	%f35, 0f00000000, %f34, %p10;
	cvt.rzi.u32.f32 	%r33, %f35;
	mul.f32 	%f36, %f13, %f29;
	fma.rn.f32 	%f37, %f12, %f28, %f36;
	fma.rn.f32 	%f38, %f16, %f30, %f37;
	setp.lt.f32 	%p12, %f38, 0f00000000;
	setp.gt.f32 	%p13, %f38, 0f437F0000;
	selp.f32 	%f39, 0f437F0000, %f38, %p13;
	selp.f32 	%f40, 0f00000000, %f39, %p12;
	cvt.rzi.u32.f32 	%r34, %f40;
	mul.f32 	%f41, %f21, %f29;
	fma.rn.f32 	%f42, %f20, %f28, %f41;
	fma.rn.f32 	%f43, %f24, %f30, %f42;
	setp.lt.f32 	%p14, %f43, 0f00000000;
	setp.gt.f32 	%p15, %f43, 0f437F0000;
	selp.f32 	%f44, 0f437F0000, %f43, %p15;
	selp.f32 	%f45, 0f00000000, %f44, %p14;
	cvt.rzi.u32.f32 	%r35, %f45;
	mul.lo.s32 	%r36, %r2, %r4;
	cvt.s64.s32 	%rd13, %r36;
	add.s64 	%rd14, %rd4, %rd13;
	cvta.to.global.u64 	%rd15, %rd2;
	add.s64 	%rd16, %rd15, %rd14;
	cvt.u16.u32 	%rs7, %r35;
	cvt.u16.u32 	%rs8, %r26;
	st.global.v2.u8 	[%rd16], {%rs8, %rs7};
	mul.lo.s32 	%r37, %r5, %r4;
	cvt.s64.s32 	%rd17, %r37;
	add.s64 	%rd18, %rd16, %rd17;
	cvt.u16.u32 	%rs9, %r34;
	cvt.u16.u32 	%rs10, %r25;
	st.global.v2.u8 	[%rd18], {%rs10, %rs9};
	add.s64 	%rd19, %rd18, %rd17;
	cvt.u16.u32 	%rs11, %r33;
	cvt.u16.u32 	%rs12, %r24;
	st.global.v2.u8 	[%rd19], {%rs12, %rs11};

$L__BB21_2:
	ret;

}
.entry _Z23Yuv444ToRgbPlanarKernelI6uchar26RGBA32S0_EvPhiS2_iii(
	.param .u64 _Z23Yuv444ToRgbPlanarKernelI6uchar26RGBA32S0_EvPhiS2_iii_param_0,
	.param .u32 _Z23Yuv444ToRgbPlanarKernelI6uchar26RGBA32S0_EvPhiS2_iii_param_1,
	.param .u64 _Z23Yuv444ToRgbPlanarKernelI6uchar26RGBA32S0_EvPhiS2_iii_param_2,
	.param .u32 _Z23Yuv444ToRgbPlanarKernelI6uchar26RGBA32S0_EvPhiS2_iii_param_3,
	.param .u32 _Z23Yuv444ToRgbPlanarKernelI6uchar26RGBA32S0_EvPhiS2_iii_param_4,
	.param .u32 _Z23Yuv444ToRgbPlanarKernelI6uchar26RGBA32S0_EvPhiS2_iii_param_5
)
{
	.reg .pred 	%p<16>;
	.reg .b16 	%rs<13>;
	.reg .f32 	%f<46>;
	.reg .b32 	%r<38>;
	.reg .b64 	%rd<20>;


	ld.param.u64 	%rd1, [_Z23Yuv444ToRgbPlanarKernelI6uchar26RGBA32S0_EvPhiS2_iii_param_0];
	ld.param.u32 	%r3, [_Z23Yuv444ToRgbPlanarKernelI6uchar26RGBA32S0_EvPhiS2_iii_param_1];
	ld.param.u64 	%rd2, [_Z23Yuv444ToRgbPlanarKernelI6uchar26RGBA32S0_EvPhiS2_iii_param_2];
	ld.param.u32 	%r4, [_Z23Yuv444ToRgbPlanarKernelI6uchar26RGBA32S0_EvPhiS2_iii_param_3];
	ld.param.u32 	%r6, [_Z23Yuv444ToRgbPlanarKernelI6uchar26RGBA32S0_EvPhiS2_iii_param_4];
	ld.param.u32 	%r5, [_Z23Yuv444ToRgbPlanarKernelI6uchar26RGBA32S0_EvPhiS2_iii_param_5];
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r8, %ctaid.x;
	mov.u32 	%r9, %tid.x;
	mad.lo.s32 	%r10, %r8, %r7, %r9;
	shl.b32 	%r1, %r10, 1;
	mov.u32 	%r11, %ntid.y;
	mov.u32 	%r12, %ctaid.y;
	mov.u32 	%r13, %tid.y;
	mad.lo.s32 	%r2, %r12, %r11, %r13;
	or.b32  	%r14, %r1, 1;
	setp.ge.s32 	%p1, %r14, %r6;
	setp.ge.s32 	%p2, %r2, %r5;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	$L__BB22_2;

	cvt.s64.s32 	%rd3, %r1;
	and.b64  	%rd4, %rd3, 9223372036854775806;
	mul.lo.s32 	%r15, %r2, %r3;
	cvt.s64.s32 	%rd5, %r15;
	add.s64 	%rd6, %rd4, %rd5;
	cvta.to.global.u64 	%rd7, %rd1;
	add.s64 	%rd8, %rd7, %rd6;
	ld.global.v2.u8 	{%rs1, %rs2}, [%rd8];
	mul.lo.s32 	%r16, %r5, %r3;
	cvt.s64.s32 	%rd9, %r16;
	add.s64 	%rd10, %rd8, %rd9;
	ld.global.v2.u8 	{%rs3, %rs4}, [%rd10];
	shl.b32 	%r17, %r16, 1;
	cvt.s64.s32 	%rd11, %r17;
	add.s64 	%rd12, %rd8, %rd11;
	ld.global.v2.u8 	{%rs5, %rs6}, [%rd12];
	cvt.u32.u16 	%r18, %rs1;
	add.s32 	%r19, %r18, -16;
	cvt.rn.f32.s32 	%f1, %r19;
	cvt.u32.u16 	%r20, %rs3;
	add.s32 	%r21, %r20, -128;
	cvt.rn.f32.s32 	%f2, %r21;
	cvt.u32.u16 	%r22, %rs5;
	add.s32 	%r23, %r22, -128;
	cvt.rn.f32.s32 	%f3, %r23;
	ld.const.f32 	%f4, [matYuv2Rgb];
	ld.const.f32 	%f5, [matYuv2Rgb+4];
	mul.f32 	%f6, %f5, %f2;
	fma.rn.f32 	%f7, %f4, %f1, %f6;
	ld.const.f32 	%f8, [matYuv2Rgb+8];
	fma.rn.f32 	%f9, %f8, %f3, %f7;
	setp.lt.f32 	%p4, %f9, 0f00000000;
	setp.gt.f32 	%p5, %f9, 0f437F0000;
	selp.f32 	%f10, 0f437F0000, %f9, %p5;
	selp.f32 	%f11, 0f00000000, %f10, %p4;
	cvt.rzi.u32.f32 	%r24, %f11;
	ld.const.f32 	%f12, [matYuv2Rgb+12];
	ld.const.f32 	%f13, [matYuv2Rgb+16];
	mul.f32 	%f14, %f13, %f2;
	fma.rn.f32 	%f15, %f12, %f1, %f14;
	ld.const.f32 	%f16, [matYuv2Rgb+20];
	fma.rn.f32 	%f17, %f16, %f3, %f15;
	setp.lt.f32 	%p6, %f17, 0f00000000;
	setp.gt.f32 	%p7, %f17, 0f437F0000;
	selp.f32 	%f18, 0f437F0000, %f17, %p7;
	selp.f32 	%f19, 0f00000000, %f18, %p6;
	cvt.rzi.u32.f32 	%r25, %f19;
	ld.const.f32 	%f20, [matYuv2Rgb+24];
	ld.const.f32 	%f21, [matYuv2Rgb+28];
	mul.f32 	%f22, %f21, %f2;
	fma.rn.f32 	%f23, %f20, %f1, %f22;
	ld.const.f32 	%f24, [matYuv2Rgb+32];
	fma.rn.f32 	%f25, %f24, %f3, %f23;
	setp.lt.f32 	%p8, %f25, 0f00000000;
	setp.gt.f32 	%p9, %f25, 0f437F0000;
	selp.f32 	%f26, 0f437F0000, %f25, %p9;
	selp.f32 	%f27, 0f00000000, %f26, %p8;
	cvt.rzi.u32.f32 	%r26, %f27;
	cvt.u32.u16 	%r27, %rs2;
	add.s32 	%r28, %r27, -16;
	cvt.rn.f32.s32 	%f28, %r28;
	cvt.u32.u16 	%r29, %rs4;
	add.s32 	%r30, %r29, -128;
	cvt.rn.f32.s32 	%f29, %r30;
	cvt.u32.u16 	%r31, %rs6;
	add.s32 	%r32, %r31, -128;
	cvt.rn.f32.s32 	%f30, %r32;
	mul.f32 	%f31, %f5, %f29;
	fma.rn.f32 	%f32, %f4, %f28, %f31;
	fma.rn.f32 	%f33, %f8, %f30, %f32;
	setp.lt.f32 	%p10, %f33, 0f00000000;
	setp.gt.f32 	%p11, %f33, 0f437F0000;
	selp.f32 	%f34, 0f437F0000, %f33, %p11;
	selp.f32 	%f35, 0f00000000, %f34, %p10;
	cvt.rzi.u32.f32 	%r33, %f35;
	mul.f32 	%f36, %f13, %f29;
	fma.rn.f32 	%f37, %f12, %f28, %f36;
	fma.rn.f32 	%f38, %f16, %f30, %f37;
	setp.lt.f32 	%p12, %f38, 0f00000000;
	setp.gt.f32 	%p13, %f38, 0f437F0000;
	selp.f32 	%f39, 0f437F0000, %f38, %p13;
	selp.f32 	%f40, 0f00000000, %f39, %p12;
	cvt.rzi.u32.f32 	%r34, %f40;
	mul.f32 	%f41, %f21, %f29;
	fma.rn.f32 	%f42, %f20, %f28, %f41;
	fma.rn.f32 	%f43, %f24, %f30, %f42;
	setp.lt.f32 	%p14, %f43, 0f00000000;
	setp.gt.f32 	%p15, %f43, 0f437F0000;
	selp.f32 	%f44, 0f437F0000, %f43, %p15;
	selp.f32 	%f45, 0f00000000, %f44, %p14;
	cvt.rzi.u32.f32 	%r35, %f45;
	mul.lo.s32 	%r36, %r2, %r4;
	cvt.s64.s32 	%rd13, %r36;
	add.s64 	%rd14, %rd4, %rd13;
	cvta.to.global.u64 	%rd15, %rd2;
	add.s64 	%rd16, %rd15, %rd14;
	cvt.u16.u32 	%rs7, %r33;
	cvt.u16.u32 	%rs8, %r24;
	st.global.v2.u8 	[%rd16], {%rs8, %rs7};
	mul.lo.s32 	%r37, %r5, %r4;
	cvt.s64.s32 	%rd17, %r37;
	add.s64 	%rd18, %rd16, %rd17;
	cvt.u16.u32 	%rs9, %r34;
	cvt.u16.u32 	%rs10, %r25;
	st.global.v2.u8 	[%rd18], {%rs10, %rs9};
	add.s64 	%rd19, %rd18, %rd17;
	cvt.u16.u32 	%rs11, %r35;
	cvt.u16.u32 	%rs12, %r26;
	st.global.v2.u8 	[%rd19], {%rs12, %rs11};

$L__BB22_2:
	ret;

}
.entry _Z23Yuv444ToRgbPlanarKernelI7ushort26BGRA326uchar2EvPhiS3_iii(
	.param .u64 _Z23Yuv444ToRgbPlanarKernelI7ushort26BGRA326uchar2EvPhiS3_iii_param_0,
	.param .u32 _Z23Yuv444ToRgbPlanarKernelI7ushort26BGRA326uchar2EvPhiS3_iii_param_1,
	.param .u64 _Z23Yuv444ToRgbPlanarKernelI7ushort26BGRA326uchar2EvPhiS3_iii_param_2,
	.param .u32 _Z23Yuv444ToRgbPlanarKernelI7ushort26BGRA326uchar2EvPhiS3_iii_param_3,
	.param .u32 _Z23Yuv444ToRgbPlanarKernelI7ushort26BGRA326uchar2EvPhiS3_iii_param_4,
	.param .u32 _Z23Yuv444ToRgbPlanarKernelI7ushort26BGRA326uchar2EvPhiS3_iii_param_5
)
{
	.reg .pred 	%p<16>;
	.reg .b16 	%rs<19>;
	.reg .f32 	%f<46>;
	.reg .b32 	%r<44>;
	.reg .b64 	%rd<22>;


	ld.param.u64 	%rd1, [_Z23Yuv444ToRgbPlanarKernelI7ushort26BGRA326uchar2EvPhiS3_iii_param_0];
	ld.param.u32 	%r3, [_Z23Yuv444ToRgbPlanarKernelI7ushort26BGRA326uchar2EvPhiS3_iii_param_1];
	ld.param.u64 	%rd2, [_Z23Yuv444ToRgbPlanarKernelI7ushort26BGRA326uchar2EvPhiS3_iii_param_2];
	ld.param.u32 	%r4, [_Z23Yuv444ToRgbPlanarKernelI7ushort26BGRA326uchar2EvPhiS3_iii_param_3];
	ld.param.u32 	%r6, [_Z23Yuv444ToRgbPlanarKernelI7ushort26BGRA326uchar2EvPhiS3_iii_param_4];
	ld.param.u32 	%r5, [_Z23Yuv444ToRgbPlanarKernelI7ushort26BGRA326uchar2EvPhiS3_iii_param_5];
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r8, %ctaid.x;
	mov.u32 	%r9, %tid.x;
	mad.lo.s32 	%r10, %r8, %r7, %r9;
	shl.b32 	%r1, %r10, 1;
	mov.u32 	%r11, %ntid.y;
	mov.u32 	%r12, %ctaid.y;
	mov.u32 	%r13, %tid.y;
	mad.lo.s32 	%r2, %r12, %r11, %r13;
	or.b32  	%r14, %r1, 1;
	setp.ge.s32 	%p1, %r14, %r6;
	setp.ge.s32 	%p2, %r2, %r5;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	$L__BB23_2;

	cvt.s64.s32 	%rd3, %r1;
	mul.wide.s32 	%rd4, %r1, 2;
	and.b64  	%rd5, %rd4, 9223372036854775804;
	mul.lo.s32 	%r15, %r2, %r3;
	cvt.s64.s32 	%rd6, %r15;
	add.s64 	%rd7, %rd5, %rd6;
	cvta.to.global.u64 	%rd8, %rd1;
	add.s64 	%rd9, %rd8, %rd7;
	ld.global.v2.u16 	{%rs1, %rs2}, [%rd9];
	mul.lo.s32 	%r16, %r5, %r3;
	cvt.s64.s32 	%rd10, %r16;
	add.s64 	%rd11, %rd9, %rd10;
	ld.global.v2.u16 	{%rs5, %rs6}, [%rd11];
	shl.b32 	%r17, %r16, 1;
	cvt.s64.s32 	%rd12, %r17;
	add.s64 	%rd13, %rd9, %rd12;
	ld.global.v2.u16 	{%rs9, %rs10}, [%rd13];
	cvt.u32.u16 	%r18, %rs1;
	add.s32 	%r19, %r18, -4096;
	cvt.rn.f32.s32 	%f1, %r19;
	cvt.u32.u16 	%r20, %rs5;
	add.s32 	%r21, %r20, -32768;
	cvt.rn.f32.s32 	%f2, %r21;
	cvt.u32.u16 	%r22, %rs9;
	add.s32 	%r23, %r22, -32768;
	cvt.rn.f32.s32 	%f3, %r23;
	ld.const.f32 	%f4, [matYuv2Rgb];
	ld.const.f32 	%f5, [matYuv2Rgb+4];
	mul.f32 	%f6, %f5, %f2;
	fma.rn.f32 	%f7, %f4, %f1, %f6;
	ld.const.f32 	%f8, [matYuv2Rgb+8];
	fma.rn.f32 	%f9, %f8, %f3, %f7;
	setp.lt.f32 	%p4, %f9, 0f00000000;
	setp.gt.f32 	%p5, %f9, 0f477FFF00;
	selp.f32 	%f10, 0f477FFF00, %f9, %p5;
	selp.f32 	%f11, 0f00000000, %f10, %p4;
	cvt.rzi.u32.f32 	%r24, %f11;
	ld.const.f32 	%f12, [matYuv2Rgb+12];
	ld.const.f32 	%f13, [matYuv2Rgb+16];
	mul.f32 	%f14, %f13, %f2;
	fma.rn.f32 	%f15, %f12, %f1, %f14;
	ld.const.f32 	%f16, [matYuv2Rgb+20];
	fma.rn.f32 	%f17, %f16, %f3, %f15;
	setp.lt.f32 	%p6, %f17, 0f00000000;
	setp.gt.f32 	%p7, %f17, 0f477FFF00;
	selp.f32 	%f18, 0f477FFF00, %f17, %p7;
	selp.f32 	%f19, 0f00000000, %f18, %p6;
	cvt.rzi.u32.f32 	%r25, %f19;
	ld.const.f32 	%f20, [matYuv2Rgb+24];
	ld.const.f32 	%f21, [matYuv2Rgb+28];
	mul.f32 	%f22, %f21, %f2;
	fma.rn.f32 	%f23, %f20, %f1, %f22;
	ld.const.f32 	%f24, [matYuv2Rgb+32];
	fma.rn.f32 	%f25, %f24, %f3, %f23;
	setp.lt.f32 	%p8, %f25, 0f00000000;
	setp.gt.f32 	%p9, %f25, 0f477FFF00;
	selp.f32 	%f26, 0f477FFF00, %f25, %p9;
	selp.f32 	%f27, 0f00000000, %f26, %p8;
	cvt.rzi.u32.f32 	%r26, %f27;
	shr.u32 	%r27, %r26, 8;
	shr.u32 	%r28, %r25, 8;
	shr.u32 	%r29, %r24, 8;
	cvt.u32.u16 	%r30, %rs2;
	add.s32 	%r31, %r30, -4096;
	cvt.rn.f32.s32 	%f28, %r31;
	cvt.u32.u16 	%r32, %rs6;
	add.s32 	%r33, %r32, -32768;
	cvt.rn.f32.s32 	%f29, %r33;
	cvt.u32.u16 	%r34, %rs10;
	add.s32 	%r35, %r34, -32768;
	cvt.rn.f32.s32 	%f30, %r35;
	mul.f32 	%f31, %f5, %f29;
	fma.rn.f32 	%f32, %f4, %f28, %f31;
	fma.rn.f32 	%f33, %f8, %f30, %f32;
	setp.lt.f32 	%p10, %f33, 0f00000000;
	setp.gt.f32 	%p11, %f33, 0f477FFF00;
	selp.f32 	%f34, 0f477FFF00, %f33, %p11;
	selp.f32 	%f35, 0f00000000, %f34, %p10;
	cvt.rzi.u32.f32 	%r36, %f35;
	mul.f32 	%f36, %f13, %f29;
	fma.rn.f32 	%f37, %f12, %f28, %f36;
	fma.rn.f32 	%f38, %f16, %f30, %f37;
	setp.lt.f32 	%p12, %f38, 0f00000000;
	setp.gt.f32 	%p13, %f38, 0f477FFF00;
	selp.f32 	%f39, 0f477FFF00, %f38, %p13;
	selp.f32 	%f40, 0f00000000, %f39, %p12;
	cvt.rzi.u32.f32 	%r37, %f40;
	mul.f32 	%f41, %f21, %f29;
	fma.rn.f32 	%f42, %f20, %f28, %f41;
	fma.rn.f32 	%f43, %f24, %f30, %f42;
	setp.lt.f32 	%p14, %f43, 0f00000000;
	setp.gt.f32 	%p15, %f43, 0f477FFF00;
	selp.f32 	%f44, 0f477FFF00, %f43, %p15;
	selp.f32 	%f45, 0f00000000, %f44, %p14;
	cvt.rzi.u32.f32 	%r38, %f45;
	shr.u32 	%r39, %r38, 8;
	shr.u32 	%r40, %r37, 8;
	shr.u32 	%r41, %r36, 8;
	and.b64  	%rd14, %rd3, 9223372036854775806;
	mul.lo.s32 	%r42, %r2, %r4;
	cvt.s64.s32 	%rd15, %r42;
	add.s64 	%rd16, %rd14, %rd15;
	cvta.to.global.u64 	%rd17, %rd2;
	add.s64 	%rd18, %rd17, %rd16;
	cvt.u16.u32 	%rs13, %r39;
	cvt.u16.u32 	%rs14, %r27;
	st.global.v2.u8 	[%rd18], {%rs14, %rs13};
	mul.lo.s32 	%r43, %r5, %r4;
	cvt.s64.s32 	%rd19, %r43;
	add.s64 	%rd20, %rd18, %rd19;
	cvt.u16.u32 	%rs15, %r40;
	cvt.u16.u32 	%rs16, %r28;
	st.global.v2.u8 	[%rd20], {%rs16, %rs15};
	add.s64 	%rd21, %rd20, %rd19;
	cvt.u16.u32 	%rs17, %r41;
	cvt.u16.u32 	%rs18, %r29;
	st.global.v2.u8 	[%rd21], {%rs18, %rs17};

$L__BB23_2:
	ret;

}
.entry _Z23Yuv444ToRgbPlanarKernelI7ushort26RGBA326uchar2EvPhiS3_iii(
	.param .u64 _Z23Yuv444ToRgbPlanarKernelI7ushort26RGBA326uchar2EvPhiS3_iii_param_0,
	.param .u32 _Z23Yuv444ToRgbPlanarKernelI7ushort26RGBA326uchar2EvPhiS3_iii_param_1,
	.param .u64 _Z23Yuv444ToRgbPlanarKernelI7ushort26RGBA326uchar2EvPhiS3_iii_param_2,
	.param .u32 _Z23Yuv444ToRgbPlanarKernelI7ushort26RGBA326uchar2EvPhiS3_iii_param_3,
	.param .u32 _Z23Yuv444ToRgbPlanarKernelI7ushort26RGBA326uchar2EvPhiS3_iii_param_4,
	.param .u32 _Z23Yuv444ToRgbPlanarKernelI7ushort26RGBA326uchar2EvPhiS3_iii_param_5
)
{
	.reg .pred 	%p<16>;
	.reg .b16 	%rs<19>;
	.reg .f32 	%f<46>;
	.reg .b32 	%r<44>;
	.reg .b64 	%rd<22>;


	ld.param.u64 	%rd1, [_Z23Yuv444ToRgbPlanarKernelI7ushort26RGBA326uchar2EvPhiS3_iii_param_0];
	ld.param.u32 	%r3, [_Z23Yuv444ToRgbPlanarKernelI7ushort26RGBA326uchar2EvPhiS3_iii_param_1];
	ld.param.u64 	%rd2, [_Z23Yuv444ToRgbPlanarKernelI7ushort26RGBA326uchar2EvPhiS3_iii_param_2];
	ld.param.u32 	%r4, [_Z23Yuv444ToRgbPlanarKernelI7ushort26RGBA326uchar2EvPhiS3_iii_param_3];
	ld.param.u32 	%r6, [_Z23Yuv444ToRgbPlanarKernelI7ushort26RGBA326uchar2EvPhiS3_iii_param_4];
	ld.param.u32 	%r5, [_Z23Yuv444ToRgbPlanarKernelI7ushort26RGBA326uchar2EvPhiS3_iii_param_5];
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r8, %ctaid.x;
	mov.u32 	%r9, %tid.x;
	mad.lo.s32 	%r10, %r8, %r7, %r9;
	shl.b32 	%r1, %r10, 1;
	mov.u32 	%r11, %ntid.y;
	mov.u32 	%r12, %ctaid.y;
	mov.u32 	%r13, %tid.y;
	mad.lo.s32 	%r2, %r12, %r11, %r13;
	or.b32  	%r14, %r1, 1;
	setp.ge.s32 	%p1, %r14, %r6;
	setp.ge.s32 	%p2, %r2, %r5;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	$L__BB24_2;

	cvt.s64.s32 	%rd3, %r1;
	mul.wide.s32 	%rd4, %r1, 2;
	and.b64  	%rd5, %rd4, 9223372036854775804;
	mul.lo.s32 	%r15, %r2, %r3;
	cvt.s64.s32 	%rd6, %r15;
	add.s64 	%rd7, %rd5, %rd6;
	cvta.to.global.u64 	%rd8, %rd1;
	add.s64 	%rd9, %rd8, %rd7;
	ld.global.v2.u16 	{%rs1, %rs2}, [%rd9];
	mul.lo.s32 	%r16, %r5, %r3;
	cvt.s64.s32 	%rd10, %r16;
	add.s64 	%rd11, %rd9, %rd10;
	ld.global.v2.u16 	{%rs5, %rs6}, [%rd11];
	shl.b32 	%r17, %r16, 1;
	cvt.s64.s32 	%rd12, %r17;
	add.s64 	%rd13, %rd9, %rd12;
	ld.global.v2.u16 	{%rs9, %rs10}, [%rd13];
	cvt.u32.u16 	%r18, %rs1;
	add.s32 	%r19, %r18, -4096;
	cvt.rn.f32.s32 	%f1, %r19;
	cvt.u32.u16 	%r20, %rs5;
	add.s32 	%r21, %r20, -32768;
	cvt.rn.f32.s32 	%f2, %r21;
	cvt.u32.u16 	%r22, %rs9;
	add.s32 	%r23, %r22, -32768;
	cvt.rn.f32.s32 	%f3, %r23;
	ld.const.f32 	%f4, [matYuv2Rgb];
	ld.const.f32 	%f5, [matYuv2Rgb+4];
	mul.f32 	%f6, %f5, %f2;
	fma.rn.f32 	%f7, %f4, %f1, %f6;
	ld.const.f32 	%f8, [matYuv2Rgb+8];
	fma.rn.f32 	%f9, %f8, %f3, %f7;
	setp.lt.f32 	%p4, %f9, 0f00000000;
	setp.gt.f32 	%p5, %f9, 0f477FFF00;
	selp.f32 	%f10, 0f477FFF00, %f9, %p5;
	selp.f32 	%f11, 0f00000000, %f10, %p4;
	cvt.rzi.u32.f32 	%r24, %f11;
	ld.const.f32 	%f12, [matYuv2Rgb+12];
	ld.const.f32 	%f13, [matYuv2Rgb+16];
	mul.f32 	%f14, %f13, %f2;
	fma.rn.f32 	%f15, %f12, %f1, %f14;
	ld.const.f32 	%f16, [matYuv2Rgb+20];
	fma.rn.f32 	%f17, %f16, %f3, %f15;
	setp.lt.f32 	%p6, %f17, 0f00000000;
	setp.gt.f32 	%p7, %f17, 0f477FFF00;
	selp.f32 	%f18, 0f477FFF00, %f17, %p7;
	selp.f32 	%f19, 0f00000000, %f18, %p6;
	cvt.rzi.u32.f32 	%r25, %f19;
	ld.const.f32 	%f20, [matYuv2Rgb+24];
	ld.const.f32 	%f21, [matYuv2Rgb+28];
	mul.f32 	%f22, %f21, %f2;
	fma.rn.f32 	%f23, %f20, %f1, %f22;
	ld.const.f32 	%f24, [matYuv2Rgb+32];
	fma.rn.f32 	%f25, %f24, %f3, %f23;
	setp.lt.f32 	%p8, %f25, 0f00000000;
	setp.gt.f32 	%p9, %f25, 0f477FFF00;
	selp.f32 	%f26, 0f477FFF00, %f25, %p9;
	selp.f32 	%f27, 0f00000000, %f26, %p8;
	cvt.rzi.u32.f32 	%r26, %f27;
	shr.u32 	%r27, %r24, 8;
	shr.u32 	%r28, %r25, 8;
	shr.u32 	%r29, %r26, 8;
	cvt.u32.u16 	%r30, %rs2;
	add.s32 	%r31, %r30, -4096;
	cvt.rn.f32.s32 	%f28, %r31;
	cvt.u32.u16 	%r32, %rs6;
	add.s32 	%r33, %r32, -32768;
	cvt.rn.f32.s32 	%f29, %r33;
	cvt.u32.u16 	%r34, %rs10;
	add.s32 	%r35, %r34, -32768;
	cvt.rn.f32.s32 	%f30, %r35;
	mul.f32 	%f31, %f5, %f29;
	fma.rn.f32 	%f32, %f4, %f28, %f31;
	fma.rn.f32 	%f33, %f8, %f30, %f32;
	setp.lt.f32 	%p10, %f33, 0f00000000;
	setp.gt.f32 	%p11, %f33, 0f477FFF00;
	selp.f32 	%f34, 0f477FFF00, %f33, %p11;
	selp.f32 	%f35, 0f00000000, %f34, %p10;
	cvt.rzi.u32.f32 	%r36, %f35;
	mul.f32 	%f36, %f13, %f29;
	fma.rn.f32 	%f37, %f12, %f28, %f36;
	fma.rn.f32 	%f38, %f16, %f30, %f37;
	setp.lt.f32 	%p12, %f38, 0f00000000;
	setp.gt.f32 	%p13, %f38, 0f477FFF00;
	selp.f32 	%f39, 0f477FFF00, %f38, %p13;
	selp.f32 	%f40, 0f00000000, %f39, %p12;
	cvt.rzi.u32.f32 	%r37, %f40;
	mul.f32 	%f41, %f21, %f29;
	fma.rn.f32 	%f42, %f20, %f28, %f41;
	fma.rn.f32 	%f43, %f24, %f30, %f42;
	setp.lt.f32 	%p14, %f43, 0f00000000;
	setp.gt.f32 	%p15, %f43, 0f477FFF00;
	selp.f32 	%f44, 0f477FFF00, %f43, %p15;
	selp.f32 	%f45, 0f00000000, %f44, %p14;
	cvt.rzi.u32.f32 	%r38, %f45;
	shr.u32 	%r39, %r36, 8;
	shr.u32 	%r40, %r37, 8;
	shr.u32 	%r41, %r38, 8;
	and.b64  	%rd14, %rd3, 9223372036854775806;
	mul.lo.s32 	%r42, %r2, %r4;
	cvt.s64.s32 	%rd15, %r42;
	add.s64 	%rd16, %rd14, %rd15;
	cvta.to.global.u64 	%rd17, %rd2;
	add.s64 	%rd18, %rd17, %rd16;
	cvt.u16.u32 	%rs13, %r39;
	cvt.u16.u32 	%rs14, %r27;
	st.global.v2.u8 	[%rd18], {%rs14, %rs13};
	mul.lo.s32 	%r43, %r5, %r4;
	cvt.s64.s32 	%rd19, %r43;
	add.s64 	%rd20, %rd18, %rd19;
	cvt.u16.u32 	%rs15, %r40;
	cvt.u16.u32 	%rs16, %r28;
	st.global.v2.u8 	[%rd20], {%rs16, %rs15};
	add.s64 	%rd21, %rd20, %rd19;
	cvt.u16.u32 	%rs17, %r41;
	cvt.u16.u32 	%rs18, %r29;
	st.global.v2.u8 	[%rd21], {%rs18, %rs17};

$L__BB24_2:
	ret;

}

